{
  "skills": [
    {
      "id": "accessibility",
      "name": "accessibility",
      "description": "Audit and improve web accessibility following WCAG 2.1 guidelines. Use when asked to \"improve accessibility\", \"a11y audit\", \"WCAG compliance\", \"screen reader support\", \"keyboard navigation\", or \"make accessible\".",
      "category": "quality",
      "path": "skills/(quality)/web-accessibility/SKILL.md",
      "content": "# Accessibility (a11y)\n\nComprehensive accessibility guidelines based on WCAG 2.1 and Lighthouse accessibility audits. Goal: make content usable by everyone, including people with disabilities.\n\n## WCAG Principles: POUR\n\n| Principle          | Description                                       |\n| ------------------ | ------------------------------------------------- |\n| **P**erceivable    | Content can be perceived through different senses |\n| **O**perable       | Interface can be operated by all users            |\n| **U**nderstandable | Content and interface are understandable          |\n| **R**obust         | Content works with assistive technologies         |\n\n## Conformance levels\n\n| Level   | Requirement            | Target                                                |\n| ------- | ---------------------- | ----------------------------------------------------- |\n| **A**   | Minimum accessibility  | Must pass                                             |\n| **AA**  | Standard compliance    | Should pass (legal requirement in many jurisdictions) |\n| **AAA** | Enhanced accessibility | Nice to have                                          |\n\n---\n\n## Perceivable\n\n### Text alternatives (1.1)\n\n**Images require alt text:**\n\n```html\n<!-- ❌ Missing alt -->\n<img src=\"chart.png\" />\n\n<!-- ✅ Descriptive alt -->\n<img src=\"chart.png\" alt=\"Bar chart showing 40% increase in Q3 sales\" />\n\n<!-- ✅ Decorative image (empty alt) -->\n<img src=\"decorative-border.png\" alt=\"\" role=\"presentation\" />\n\n<!-- ✅ Complex image with longer description -->\n<figure>\n  <img src=\"infographic.png\" alt=\"2024 market trends infographic\" aria-describedby=\"infographic-desc\" />\n  <figcaption id=\"infographic-desc\">\n    <!-- Detailed description -->\n  </figcaption>\n</figure>\n```\n\n**Icon buttons need accessible names:**\n\n```html\n<!-- ❌ No accessible name -->\n<button>\n  <svg><!-- menu icon --></svg>\n</button>\n\n<!-- ✅ Using aria-label -->\n<button aria-label=\"Open menu\">\n  <svg aria-hidden=\"true\"><!-- menu icon --></svg>\n</button>\n\n<!-- ✅ Using visually hidden text -->\n<button>\n  <svg aria-hidden=\"true\"><!-- menu icon --></svg>\n  <span class=\"visually-hidden\">Open menu</span>\n</button>\n```\n\n**Visually hidden class:**\n\n```css\n.visually-hidden {\n  position: absolute;\n  width: 1px;\n  height: 1px;\n  padding: 0;\n  margin: -1px;\n  overflow: hidden;\n  clip: rect(0, 0, 0, 0);\n  white-space: nowrap;\n  border: 0;\n}\n```\n\n### Color contrast (1.4.3, 1.4.6)\n\n| Text Size                          | AA minimum | AAA enhanced |\n| ---------------------------------- | ---------- | ------------ |\n| Normal text (< 18px / < 14px bold) | 4.5:1      | 7:1          |\n| Large text (≥ 18px / ≥ 14px bold)  | 3:1        | 4.5:1        |\n| UI components & graphics           | 3:1        | 3:1          |\n\n```css\n/* ❌ Low contrast (2.5:1) */\n.low-contrast {\n  color: #999;\n  background: #fff;\n}\n\n/* ✅ Sufficient contrast (7:1) */\n.high-contrast {\n  color: #333;\n  background: #fff;\n}\n\n/* ✅ Focus states need contrast too */\n:focus-visible {\n  outline: 2px solid #005fcc;\n  outline-offset: 2px;\n}\n```\n\n**Don't rely on color alone:**\n\n```html\n<!-- ❌ Only color indicates error -->\n<input class=\"error-border\" />\n<style>\n  .error-border {\n    border-color: red;\n  }\n</style>\n\n<!-- ✅ Color + icon + text -->\n<div class=\"field-error\">\n  <input aria-invalid=\"true\" aria-describedby=\"email-error\" />\n  <span id=\"email-error\" class=\"error-message\">\n    <svg aria-hidden=\"true\"><!-- error icon --></svg>\n    Please enter a valid email address\n  </span>\n</div>\n```\n\n### Media alternatives (1.2)\n\n```html\n<!-- Video with captions -->\n<video controls>\n  <source src=\"video.mp4\" type=\"video/mp4\" />\n  <track kind=\"captions\" src=\"captions.vtt\" srclang=\"en\" label=\"English\" default />\n  <track kind=\"descriptions\" src=\"descriptions.vtt\" srclang=\"en\" label=\"Descriptions\" />\n</video>\n\n<!-- Audio with transcript -->\n<audio controls>\n  <source src=\"podcast.mp3\" type=\"audio/mp3\" />\n</audio>\n<details>\n  <summary>Transcript</summary>\n  <p>Full transcript text...</p>\n</details>\n```\n\n---\n\n## Operable\n\n### Keyboard accessible (2.1)\n\n**All functionality must be keyboard accessible:**\n\n```javascript\n// ❌ Only handles click\nelement.addEventListener('click', handleAction)\n\n// ✅ Handles both click and keyboard\nelement.addEventListener('click', handleAction)\nelement.addEventListener('keydown', (e) => {\n  if (e.key === 'Enter' || e.key === ' ') {\n    e.preventDefault()\n    handleAction()\n  }\n})\n```\n\n**No keyboard traps:**\n\n```javascript\n// Modal focus management\nfunction openModal(modal) {\n  const focusableElements = modal.querySelectorAll(\n    'button, [href], input, select, textarea, [tabindex]:not([tabindex=\"-1\"])',\n  )\n  const firstElement = focusableElements[0]\n  const lastElement = focusableElements[focusableElements.length - 1]\n\n  // Trap focus within modal\n  modal.addEventListener('keydown', (e) => {\n    if (e.key === 'Tab') {\n      if (e.shiftKey && document.activeElement === firstElement) {\n        e.preventDefault()\n        lastElement.focus()\n      } else if (!e.shiftKey && document.activeElement === lastElement) {\n        e.preventDefault()\n        firstElement.focus()\n      }\n    }\n    if (e.key === 'Escape') {\n      closeModal()\n    }\n  })\n\n  firstElement.focus()\n}\n```\n\n### Focus visible (2.4.7)\n\n```css\n/* ❌ Never remove focus outlines */\n*:focus {\n  outline: none;\n}\n\n/* ✅ Use :focus-visible for keyboard-only focus */\n:focus {\n  outline: none;\n}\n\n:focus-visible {\n  outline: 2px solid #005fcc;\n  outline-offset: 2px;\n}\n\n/* ✅ Or custom focus styles */\nbutton:focus-visible {\n  box-shadow: 0 0 0 3px rgba(0, 95, 204, 0.5);\n}\n```\n\n### Skip links (2.4.1)\n\n```html\n<body>\n  <a href=\"#main-content\" class=\"skip-link\">Skip to main content</a>\n  <header><!-- navigation --></header>\n  <main id=\"main-content\" tabindex=\"-1\">\n    <!-- main content -->\n  </main>\n</body>\n```\n\n```css\n.skip-link {\n  position: absolute;\n  top: -40px;\n  left: 0;\n  background: #000;\n  color: #fff;\n  padding: 8px 16px;\n  z-index: 100;\n}\n\n.skip-link:focus {\n  top: 0;\n}\n```\n\n### Timing (2.2)\n\n```javascript\n// Allow users to extend time limits\nfunction showSessionWarning() {\n  const modal = createModal({\n    title: 'Session Expiring',\n    content: 'Your session will expire in 2 minutes.',\n    actions: [\n      { label: 'Extend session', action: extendSession },\n      { label: 'Log out', action: logout },\n    ],\n    timeout: 120000, // 2 minutes to respond\n  })\n}\n```\n\n### Motion (2.3)\n\n```css\n/* Respect reduced motion preference */\n@media (prefers-reduced-motion: reduce) {\n  *,\n  *::before,\n  *::after {\n    animation-duration: 0.01ms !important;\n    animation-iteration-count: 1 !important;\n    transition-duration: 0.01ms !important;\n    scroll-behavior: auto !important;\n  }\n}\n```\n\n---\n\n## Understandable\n\n### Page language (3.1.1)\n\n```html\n<!-- ❌ No language specified -->\n<html>\n  <!-- ✅ Language specified -->\n  <html lang=\"en\">\n    <!-- ✅ Language changes within page -->\n    <p>The French word for hello is <span lang=\"fr\">bonjour</span>.</p>\n  </html>\n</html>\n```\n\n### Consistent navigation (3.2.3)\n\n```html\n<!-- Navigation should be consistent across pages -->\n<nav aria-label=\"Main\">\n  <ul>\n    <li><a href=\"/\" aria-current=\"page\">Home</a></li>\n    <li><a href=\"/products\">Products</a></li>\n    <li><a href=\"/about\">About</a></li>\n  </ul>\n</nav>\n```\n\n### Form labels (3.3.2)\n\n```html\n<!-- ❌ No label association -->\n<input type=\"email\" placeholder=\"Email\" />\n\n<!-- ✅ Explicit label -->\n<label for=\"email\">Email address</label>\n<input type=\"email\" id=\"email\" name=\"email\" autocomplete=\"email\" required />\n\n<!-- ✅ Implicit label -->\n<label>\n  Email address\n  <input type=\"email\" name=\"email\" autocomplete=\"email\" required />\n</label>\n\n<!-- ✅ With instructions -->\n<label for=\"password\">Password</label>\n<input type=\"password\" id=\"password\" aria-describedby=\"password-requirements\" />\n<p id=\"password-requirements\">Must be at least 8 characters with one number.</p>\n```\n\n### Error handling (3.3.1, 3.3.3)\n\n```html\n<!-- Announce errors to screen readers -->\n<form novalidate>\n  <div class=\"field\" aria-live=\"polite\">\n    <label for=\"email\">Email</label>\n    <input type=\"email\" id=\"email\" aria-invalid=\"true\" aria-describedby=\"email-error\" />\n    <p id=\"email-error\" class=\"error\" role=\"alert\">Please enter a valid email address (e.g., name@example.com)</p>\n  </div>\n</form>\n```\n\n```javascript\n// Focus first error on submit\nform.addEventListener('submit', (e) => {\n  const firstError = form.querySelector('[aria-invalid=\"true\"]')\n  if (firstError) {\n    e.preventDefault()\n    firstError.focus()\n\n    // Announce error summary\n    const errorSummary = document.getElementById('error-summary')\n    errorSummary.textContent = `${errors.length} errors found. Please fix them and try again.`\n    errorSummary.focus()\n  }\n})\n```\n\n---\n\n## Robust\n\n### Valid HTML (4.1.1)\n\n```html\n<!-- ❌ Duplicate IDs -->\n<div id=\"content\">...</div>\n<div id=\"content\">...</div>\n\n<!-- ❌ Invalid nesting -->\n<a href=\"/\"><button>Click</button></a>\n\n<!-- ✅ Unique IDs -->\n<div id=\"main-content\">...</div>\n<div id=\"sidebar-content\">...</div>\n\n<!-- ✅ Proper nesting -->\n<a href=\"/\" class=\"button-link\">Click</a>\n```\n\n### ARIA usage (4.1.2)\n\n**Prefer native elements:**\n\n```html\n<!-- ❌ ARIA role on div -->\n<div role=\"button\" tabindex=\"0\">Click me</div>\n\n<!-- ✅ Native button -->\n<button>Click me</button>\n\n<!-- ❌ ARIA checkbox -->\n<div role=\"checkbox\" aria-checked=\"false\">Option</div>\n\n<!-- ✅ Native checkbox -->\n<label><input type=\"checkbox\" /> Option</label>\n```\n\n**When ARIA is needed:**\n\n```html\n<!-- Custom tabs component -->\n<div role=\"tablist\" aria-label=\"Product information\">\n  <button role=\"tab\" id=\"tab-1\" aria-selected=\"true\" aria-controls=\"panel-1\">Description</button>\n  <button role=\"tab\" id=\"tab-2\" aria-selected=\"false\" aria-controls=\"panel-2\" tabindex=\"-1\">Reviews</button>\n</div>\n<div role=\"tabpanel\" id=\"panel-1\" aria-labelledby=\"tab-1\">\n  <!-- Panel content -->\n</div>\n<div role=\"tabpanel\" id=\"panel-2\" aria-labelledby=\"tab-2\" hidden>\n  <!-- Panel content -->\n</div>\n```\n\n### Live regions (4.1.3)\n\n```html\n<!-- Status updates -->\n<div aria-live=\"polite\" aria-atomic=\"true\" class=\"status\">\n  <!-- Content updates announced to screen readers -->\n</div>\n\n<!-- Urgent alerts -->\n<div role=\"alert\" aria-live=\"assertive\">\n  <!-- Interrupts current announcement -->\n</div>\n```\n\n```javascript\n// Announce dynamic content changes\nfunction showNotification(message, type = 'polite') {\n  const container = document.getElementById(`${type}-announcer`)\n  container.textContent = '' // Clear first\n  requestAnimationFrame(() => {\n    container.textContent = message\n  })\n}\n```\n\n---\n\n## Testing checklist\n\n### Automated testing\n\n```bash\n# Lighthouse accessibility audit\nnpx lighthouse https://example.com --only-categories=accessibility\n\n# axe-core\nnpm install @axe-core/cli -g\naxe https://example.com\n```\n\n### Manual testing\n\n- [ ] **Keyboard navigation:** Tab through entire page, use Enter/Space to activate\n- [ ] **Screen reader:** Test with VoiceOver (Mac), NVDA (Windows), or TalkBack (Android)\n- [ ] **Zoom:** Content usable at 200% zoom\n- [ ] **High contrast:** Test with Windows High Contrast Mode\n- [ ] **Reduced motion:** Test with `prefers-reduced-motion: reduce`\n- [ ] **Focus order:** Logical and follows visual order\n\n### Screen reader commands\n\n| Action        | VoiceOver (Mac)     | NVDA (Windows) |\n| ------------- | ------------------- | -------------- |\n| Start/Stop    | ⌘ + F5              | Ctrl + Alt + N |\n| Next item     | VO + →              | ↓              |\n| Previous item | VO + ←              | ↑              |\n| Activate      | VO + Space          | Enter          |\n| Headings list | VO + U, then arrows | H / Shift + H  |\n| Links list    | VO + U              | K / Shift + K  |\n\n---\n\n## Common issues by impact\n\n### Critical (fix immediately)\n\n1. Missing form labels\n2. Missing image alt text\n3. Insufficient color contrast\n4. Keyboard traps\n5. No focus indicators\n\n### Serious (fix before launch)\n\n1. Missing page language\n2. Missing heading structure\n3. Non-descriptive link text\n4. Auto-playing media\n5. Missing skip links\n\n### Moderate (fix soon)\n\n1. Missing ARIA labels on icons\n2. Inconsistent navigation\n3. Missing error identification\n4. Timing without controls\n5. Missing landmark regions\n\n## References\n\n- [WCAG 2.1 Quick Reference](https://www.w3.org/WAI/WCAG21/quickref/)\n- [WAI-ARIA Authoring Practices](https://www.w3.org/WAI/ARIA/apg/)\n- [Deque axe Rules](https://dequeuniversity.com/rules/axe/)\n- [Web Quality Audit](../web-quality-audit/SKILL.md)",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "WCAG.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "aws-advisor",
      "name": "aws-advisor",
      "description": "Expert AWS Cloud Advisor for architecture design, security review, and implementation guidance. Leverages AWS MCP tools for accurate, documentation-backed answers. Use when user asks about AWS architecture, security, service selection, migrations, troubleshooting, or learning AWS. Triggers on AWS, Lambda, S3, EC2, ECS, EKS, DynamoDB, RDS, CloudFormation, CDK, Terraform, Serverless, SAM, IAM, VPC, API Gateway, or any AWS service.",
      "category": "cloud",
      "path": "skills/(cloud)/aws-advisor/SKILL.md",
      "content": "# AWS Advisor\n\nExpert AWS consulting with accuracy-first approach using MCP tools.\n\n## Core Principles\n\n1. **Search Before Answer**: Always use MCP tools to verify information\n2. **No Guessing**: Uncertain? Search documentation first\n3. **Context-Aware**: Adapt recommendations to user's stack, preferences, and constraints\n4. **Security by Default**: Every recommendation considers security\n5. **No Lock-in**: Present multiple options with trade-offs, let user decide\n\n## Adaptive Behavior\n\n**Before recommending tools/frameworks**, understand the context:\n\n- What's the user's current stack? (ask if unclear)\n- What's the team's expertise?\n- Is there an existing IaC in the project?\n- Speed vs control trade-off preference?\n\n**IaC Selection** - Don't default to one, guide by context:\n\n| Context                           | Recommended                    | Why                           |\n| --------------------------------- | ------------------------------ | ----------------------------- |\n| Quick MVP, serverless-heavy       | Serverless Framework, SST, SAM | Fast iteration, conventions   |\n| Multi-cloud or existing Terraform | Terraform                      | Portability, team familiarity |\n| Complex AWS, TypeScript team      | CDK                            | Type safety, constructs       |\n| Simple Lambda + API               | SAM                            | AWS-native, minimal config    |\n| Full control, learning            | CloudFormation                 | Foundational understanding    |\n\n**Language/Runtime** - Match user's preference:\n\n- Ask or detect from conversation context\n- Don't assume TypeScript/JavaScript\n- Provide examples in user's preferred language\n\n## MCP Tools Available\n\n### AWS Knowledge MCP\n\n| Tool                              | Use For                              |\n| --------------------------------- | ------------------------------------ |\n| `aws___search_documentation`      | Any AWS question - search first!     |\n| `aws___read_documentation`        | Read full page content               |\n| `aws___recommend`                 | Find related documentation           |\n| `aws___get_regional_availability` | Check service availability by region |\n| `aws___list_regions`              | Get all AWS regions                  |\n\n### AWS Marketplace MCP\n\n| Tool                           | Use For                        |\n| ------------------------------ | ------------------------------ |\n| `ask_aws_marketplace`          | Evaluate third-party solutions |\n| `get_aws_marketplace_solution` | Detailed solution info         |\n\n## Search Topic Selection\n\n**Critical**: Choose the right topic for efficient searches.\n\n| Query Type           | Topic                         | Keywords                         |\n| -------------------- | ----------------------------- | -------------------------------- |\n| SDK/CLI code         | `reference_documentation`     | \"SDK\", \"API\", \"CLI\", \"boto3\"     |\n| New features         | `current_awareness`           | \"new\", \"latest\", \"announced\"     |\n| Errors               | `troubleshooting`             | \"error\", \"failed\", \"not working\" |\n| CDK                  | `cdk_docs` / `cdk_constructs` | \"CDK\", \"construct\"               |\n| Terraform            | `general` + web search        | \"Terraform\", \"provider\"          |\n| Serverless Framework | `general` + web search        | \"Serverless\", \"sls\"              |\n| SAM                  | `cloudformation`              | \"SAM\", \"template\"                |\n| CloudFormation       | `cloudformation`              | \"CFN\", \"template\"                |\n| Architecture         | `general`                     | \"best practices\", \"pattern\"      |\n\n## Workflows\n\n### Standard Question Flow\n\n```\n1. Parse question → Identify AWS services involved\n2. Search documentation → aws___search_documentation with right topic\n3. Read if needed → aws___read_documentation for details\n4. Verify regional → aws___get_regional_availability if relevant\n5. Respond with code examples\n```\n\n### Architecture Review Flow\n\n```\n1. Gather requirements (functional, non-functional, constraints)\n2. Search relevant patterns → topic: general\n3. Run: scripts/well_architected_review.py → generates review questions\n4. Discuss trade-offs with user\n5. Run: scripts/generate_diagram.py → visualize architecture\n```\n\n### Security Review Flow\n\n```\n1. Understand architecture scope\n2. Run: scripts/security_review.py → generates checklist\n3. Search security docs → topic: general, query: \"[service] security\"\n4. Provide specific recommendations with IAM policies, SG rules\n```\n\n## Reference Files\n\nLoad only when needed:\n\n| File                                              | Load When                             |\n| ------------------------------------------------- | ------------------------------------- |\n| [mcp-guide.md](references/mcp-guide.md)           | Optimizing MCP usage, complex queries |\n| [decision-trees.md](references/decision-trees.md) | Service selection questions           |\n| [checklists.md](references/checklists.md)         | Reviews, validations, discovery       |\n\n## Scripts\n\nRun scripts for structured outputs (code never enters context):\n\n| Script                               | Purpose                              |\n| ------------------------------------ | ------------------------------------ |\n| `scripts/well_architected_review.py` | Generate W-A review questions        |\n| `scripts/security_review.py`         | Generate security checklist          |\n| `scripts/generate_diagram.py`        | Create Mermaid architecture diagrams |\n| `scripts/architecture_validator.py`  | Validate architecture description    |\n| `scripts/cost_considerations.py`     | List cost factors to evaluate        |\n\n## Code Examples\n\n**Always ask or detect user's preference before providing code:**\n\n1. **Language**: Python, TypeScript, JavaScript, Go, Java, etc.\n2. **IaC Tool**: Terraform, CDK, Serverless Framework, SAM, Pulumi, CloudFormation\n3. **Framework**: If applicable (Express, FastAPI, NestJS, etc.)\n\n**When preference is unknown**, ask:\n\n> \"What's your preferred language and IaC tool? (e.g., Python + Terraform, TypeScript + CDK, Node + Serverless Framework)\"\n\n**When user has stated preference** (in conversation or memory), use it consistently.\n\n### Quick Reference for IaC Examples\n\n**Terraform** - Search web for latest provider syntax:\n\n```hcl\nresource \"aws_lambda_function\" \"example\" {\n  filename         = \"lambda.zip\"\n  function_name    = \"example\"\n  role            = aws_iam_role.lambda.arn\n  handler         = \"index.handler\"\n  runtime         = \"nodejs20.x\"\n}\n```\n\n**Serverless Framework** - Great for rapid serverless development:\n\n```yaml\nservice: my-service\nprovider:\n  name: aws\n  runtime: nodejs20.x\nfunctions:\n  hello:\n    handler: handler.hello\n    events:\n      - httpApi:\n          path: /hello\n          method: get\n```\n\n**SAM** - AWS native, good for Lambda-focused apps:\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nResources:\n  HelloFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: index.handler\n      Runtime: nodejs20.x\n      Events:\n        Api:\n          Type: HttpApi\n```\n\n**CDK** - Best for complex infra with programming language benefits:\n\n```typescript\nnew lambda.Function(this, 'Handler', {\n  runtime: lambda.Runtime.NODEJS_20_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset('lambda'),\n})\n```\n\n## Response Style\n\n1. **Direct answer first**, explanation after\n2. **Working code** over pseudocode\n3. **Trade-offs** for architectural decisions\n4. **Cost awareness** - mention pricing implications\n5. **Security callouts** when relevant",
      "metadata": {
        "hasScripts": true,
        "hasReferences": true,
        "referenceFiles": [
          "checklists.md",
          "decision-trees.md",
          "mcp-guide.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "best-practices",
      "name": "best-practices",
      "description": "Apply modern web development best practices for security, compatibility, and code quality. Use when asked to \"apply best practices\", \"security audit\", \"modernize code\", \"code quality review\", or \"check for vulnerabilities\".",
      "category": "quality",
      "path": "skills/(quality)/web-best-practices/SKILL.md",
      "content": "# Best practices\n\nModern web development standards based on Lighthouse best practices audits. Covers security, browser compatibility, and code quality patterns.\n\n## Security\n\n### HTTPS everywhere\n\n**Enforce HTTPS:**\n\n```html\n<!-- ❌ Mixed content -->\n<img src=\"http://example.com/image.jpg\" />\n<script src=\"http://cdn.example.com/script.js\"></script>\n\n<!-- ✅ HTTPS only -->\n<img src=\"https://example.com/image.jpg\" />\n<script src=\"https://cdn.example.com/script.js\"></script>\n\n<!-- ✅ Protocol-relative (will use page's protocol) -->\n<img src=\"//example.com/image.jpg\" />\n```\n\n**HSTS Header:**\n\n```\nStrict-Transport-Security: max-age=31536000; includeSubDomains; preload\n```\n\n### Content Security Policy (CSP)\n\n```html\n<!-- Basic CSP via meta tag -->\n<meta\n  http-equiv=\"Content-Security-Policy\"\n  content=\"default-src 'self'; \n               script-src 'self' https://trusted-cdn.com; \n               style-src 'self' 'unsafe-inline';\n               img-src 'self' data: https:;\n               connect-src 'self' https://api.example.com;\"\n/>\n\n<!-- Better: HTTP header -->\n```\n\n**CSP Header (recommended):**\n\n```\nContent-Security-Policy:\n  default-src 'self';\n  script-src 'self' 'nonce-abc123' https://trusted.com;\n  style-src 'self' 'nonce-abc123';\n  img-src 'self' data: https:;\n  connect-src 'self' https://api.example.com;\n  frame-ancestors 'self';\n  base-uri 'self';\n  form-action 'self';\n```\n\n**Using nonces for inline scripts:**\n\n```html\n<script nonce=\"abc123\">\n  // This inline script is allowed\n</script>\n```\n\n### Security headers\n\n```\n# Prevent clickjacking\nX-Frame-Options: DENY\n\n# Prevent MIME type sniffing\nX-Content-Type-Options: nosniff\n\n# Enable XSS filter (legacy browsers)\nX-XSS-Protection: 1; mode=block\n\n# Control referrer information\nReferrer-Policy: strict-origin-when-cross-origin\n\n# Permissions policy (formerly Feature-Policy)\nPermissions-Policy: geolocation=(), microphone=(), camera=()\n```\n\n### No vulnerable libraries\n\n```bash\n# Check for vulnerabilities\nnpm audit\nyarn audit\n\n# Auto-fix when possible\nnpm audit fix\n\n# Check specific package\nnpm ls lodash\n```\n\n**Keep dependencies updated:**\n\n```json\n// package.json\n{\n  \"scripts\": {\n    \"audit\": \"npm audit --audit-level=moderate\",\n    \"update\": \"npm update && npm audit fix\"\n  }\n}\n```\n\n**Known vulnerable patterns to avoid:**\n\n```javascript\n// ❌ Prototype pollution vulnerable patterns\nObject.assign(target, userInput)\n_.merge(target, userInput)\n\n// ✅ Safer alternatives\nconst safeData = JSON.parse(JSON.stringify(userInput))\n```\n\n### Input sanitization\n\n```javascript\n// ❌ XSS vulnerable\nelement.innerHTML = userInput\ndocument.write(userInput)\n\n// ✅ Safe text content\nelement.textContent = userInput\n\n// ✅ If HTML needed, sanitize\nimport DOMPurify from 'dompurify'\nelement.innerHTML = DOMPurify.sanitize(userInput)\n```\n\n### Secure cookies\n\n```javascript\n// ❌ Insecure cookie\ndocument.cookie = \"session=abc123\";\n\n// ✅ Secure cookie (server-side)\nSet-Cookie: session=abc123; Secure; HttpOnly; SameSite=Strict; Path=/\n```\n\n---\n\n## Browser compatibility\n\n### Doctype declaration\n\n```html\n<!-- ❌ Missing or invalid doctype -->\n<html>\n  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n\n  <!-- ✅ HTML5 doctype -->\n  <!DOCTYPE html>\n  <html lang=\"en\"></html>\n</html>\n```\n\n### Character encoding\n\n```html\n<!-- ❌ Missing or late charset -->\n<html>\n  <head>\n    <title>Page</title>\n    <meta charset=\"UTF-8\" />\n  </head>\n\n  <!-- ✅ Charset as first element in head -->\n  <html>\n    <head>\n      <meta charset=\"UTF-8\" />\n      <title>Page</title>\n    </head>\n  </html>\n</html>\n```\n\n### Viewport meta tag\n\n```html\n<!-- ❌ Missing viewport -->\n<head>\n  <title>Page</title>\n</head>\n\n<!-- ✅ Responsive viewport -->\n<head>\n  <meta charset=\"UTF-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n  <title>Page</title>\n</head>\n```\n\n### Feature detection\n\n```javascript\n// ❌ Browser detection (brittle)\nif (navigator.userAgent.includes('Chrome')) {\n  // Chrome-specific code\n}\n\n// ✅ Feature detection\nif ('IntersectionObserver' in window) {\n  // Use IntersectionObserver\n} else {\n  // Fallback\n}\n\n// ✅ Using @supports in CSS\n@supports (display: grid) {\n  .container {\n    display: grid;\n  }\n}\n\n@supports not (display: grid) {\n  .container {\n    display: flex;\n  }\n}\n```\n\n### Polyfills (when needed)\n\n```html\n<!-- Load polyfills conditionally -->\n<script>\n  if (!('fetch' in window)) {\n    document.write('<script src=\"/polyfills/fetch.js\"><\\/script>')\n  }\n</script>\n\n<!-- Or use polyfill.io -->\n<script src=\"https://polyfill.io/v3/polyfill.min.js?features=fetch,IntersectionObserver\"></script>\n```\n\n---\n\n## Deprecated APIs\n\n### Avoid these\n\n```javascript\n// ❌ document.write (blocks parsing)\ndocument.write('<script src=\"...\"></script>');\n\n// ✅ Dynamic script loading\nconst script = document.createElement('script');\nscript.src = '...';\ndocument.head.appendChild(script);\n\n// ❌ Synchronous XHR (blocks main thread)\nconst xhr = new XMLHttpRequest();\nxhr.open('GET', url, false); // false = synchronous\n\n// ✅ Async fetch\nconst response = await fetch(url);\n\n// ❌ Application Cache (deprecated)\n<html manifest=\"cache.manifest\">\n\n// ✅ Service Workers\nif ('serviceWorker' in navigator) {\n  navigator.serviceWorker.register('/sw.js');\n}\n```\n\n### Event listener passive\n\n```javascript\n// ❌ Non-passive touch/wheel (may block scrolling)\nelement.addEventListener('touchstart', handler)\nelement.addEventListener('wheel', handler)\n\n// ✅ Passive listeners (allows smooth scrolling)\nelement.addEventListener('touchstart', handler, { passive: true })\nelement.addEventListener('wheel', handler, { passive: true })\n\n// ✅ If you need preventDefault, be explicit\nelement.addEventListener('touchstart', handler, { passive: false })\n```\n\n---\n\n## Console & errors\n\n### No console errors\n\n```javascript\n// ❌ Errors in production\nconsole.log('Debug info') // Remove in production\nthrow new Error('Unhandled') // Catch all errors\n\n// ✅ Proper error handling\ntry {\n  riskyOperation()\n} catch (error) {\n  // Log to error tracking service\n  errorTracker.captureException(error)\n  // Show user-friendly message\n  showErrorMessage('Something went wrong. Please try again.')\n}\n```\n\n### Error boundaries (React)\n\n```jsx\nclass ErrorBoundary extends React.Component {\n  state = { hasError: false }\n\n  static getDerivedStateFromError(error) {\n    return { hasError: true }\n  }\n\n  componentDidCatch(error, info) {\n    errorTracker.captureException(error, { extra: info })\n  }\n\n  render() {\n    if (this.state.hasError) {\n      return <FallbackUI />\n    }\n    return this.props.children\n  }\n}\n\n// Usage\n;<ErrorBoundary>\n  <App />\n</ErrorBoundary>\n```\n\n### Global error handler\n\n```javascript\n// Catch unhandled errors\nwindow.addEventListener('error', (event) => {\n  errorTracker.captureException(event.error)\n})\n\n// Catch unhandled promise rejections\nwindow.addEventListener('unhandledrejection', (event) => {\n  errorTracker.captureException(event.reason)\n})\n```\n\n---\n\n## Source maps\n\n### Production configuration\n\n```javascript\n// ❌ Source maps exposed in production\n// webpack.config.js\nmodule.exports = {\n  devtool: 'source-map', // Exposes source code\n}\n\n// ✅ Hidden source maps (uploaded to error tracker)\nmodule.exports = {\n  devtool: 'hidden-source-map',\n}\n\n// ✅ Or no source maps in production\nmodule.exports = {\n  devtool: process.env.NODE_ENV === 'production' ? false : 'source-map',\n}\n```\n\n---\n\n## Performance best practices\n\n### Avoid blocking patterns\n\n```javascript\n// ❌ Blocking script\n<script src=\"heavy-library.js\"></script>\n\n// ✅ Deferred script\n<script defer src=\"heavy-library.js\"></script>\n\n// ❌ Blocking CSS import\n@import url('other-styles.css');\n\n// ✅ Link tags (parallel loading)\n<link rel=\"stylesheet\" href=\"styles.css\">\n<link rel=\"stylesheet\" href=\"other-styles.css\">\n```\n\n### Efficient event handlers\n\n```javascript\n// ❌ Handler on every element\nitems.forEach((item) => {\n  item.addEventListener('click', handleClick)\n})\n\n// ✅ Event delegation\ncontainer.addEventListener('click', (e) => {\n  if (e.target.matches('.item')) {\n    handleClick(e)\n  }\n})\n```\n\n### Memory management\n\n```javascript\n// ❌ Memory leak (never removed)\nconst handler = () => {\n  /* ... */\n}\nwindow.addEventListener('resize', handler)\n\n// ✅ Cleanup when done\nconst handler = () => {\n  /* ... */\n}\nwindow.addEventListener('resize', handler)\n\n// Later, when component unmounts:\nwindow.removeEventListener('resize', handler)\n\n// ✅ Using AbortController\nconst controller = new AbortController()\nwindow.addEventListener('resize', handler, { signal: controller.signal })\n\n// Cleanup:\ncontroller.abort()\n```\n\n---\n\n## Code quality\n\n### Valid HTML\n\n```html\n<!-- ❌ Invalid HTML -->\n<div id=\"header\">\n  <div id=\"header\">\n    <!-- Duplicate ID -->\n\n    <ul>\n      <div>Item</div>\n      <!-- Invalid child -->\n    </ul>\n\n    <a href=\"/\"><button>Click</button></a>\n    <!-- Invalid nesting -->\n\n    <!-- ✅ Valid HTML -->\n    <header id=\"site-header\"></header>\n\n    <ul>\n      <li>Item</li>\n    </ul>\n\n    <a href=\"/\" class=\"button\">Click</a>\n  </div>\n</div>\n```\n\n### Semantic HTML\n\n```html\n<!-- ❌ Non-semantic -->\n<div class=\"header\">\n  <div class=\"nav\">\n    <div class=\"nav-item\">Home</div>\n  </div>\n</div>\n<div class=\"main\">\n  <div class=\"article\">\n    <div class=\"title\">Headline</div>\n  </div>\n</div>\n\n<!-- ✅ Semantic HTML5 -->\n<header>\n  <nav>\n    <a href=\"/\">Home</a>\n  </nav>\n</header>\n<main>\n  <article>\n    <h1>Headline</h1>\n  </article>\n</main>\n```\n\n### Image aspect ratios\n\n```html\n<!-- ❌ Distorted images -->\n<img src=\"photo.jpg\" width=\"300\" height=\"100\" />\n<!-- If actual ratio is 4:3, this squishes the image -->\n\n<!-- ✅ Preserve aspect ratio -->\n<img src=\"photo.jpg\" width=\"300\" height=\"225\" />\n<!-- Actual 4:3 dimensions -->\n\n<!-- ✅ CSS object-fit for flexibility -->\n<img src=\"photo.jpg\" style=\"width: 300px; height: 200px; object-fit: cover;\" />\n```\n\n---\n\n## Permissions & privacy\n\n### Request permissions properly\n\n```javascript\n// ❌ Request on page load (bad UX, often denied)\nnavigator.geolocation.getCurrentPosition(success, error)\n\n// ✅ Request in context, after user action\nfindNearbyButton.addEventListener('click', async () => {\n  // Explain why you need it\n  if (await showPermissionExplanation()) {\n    navigator.geolocation.getCurrentPosition(success, error)\n  }\n})\n```\n\n### Permissions policy\n\n```html\n<!-- Restrict powerful features -->\n<meta http-equiv=\"Permissions-Policy\" content=\"geolocation=(), camera=(), microphone=()\" />\n\n<!-- Or allow for specific origins -->\n<meta http-equiv=\"Permissions-Policy\" content=\"geolocation=(self 'https://maps.example.com')\" />\n```\n\n---\n\n## Audit checklist\n\n### Security (critical)\n\n- [ ] HTTPS enabled, no mixed content\n- [ ] No vulnerable dependencies (`npm audit`)\n- [ ] CSP headers configured\n- [ ] Security headers present\n- [ ] No exposed source maps\n\n### Compatibility\n\n- [ ] Valid HTML5 doctype\n- [ ] Charset declared first in head\n- [ ] Viewport meta tag present\n- [ ] No deprecated APIs used\n- [ ] Passive event listeners for scroll/touch\n\n### Code quality\n\n- [ ] No console errors\n- [ ] Valid HTML (no duplicate IDs)\n- [ ] Semantic HTML elements used\n- [ ] Proper error handling\n- [ ] Memory cleanup in components\n\n### UX\n\n- [ ] No intrusive interstitials\n- [ ] Permission requests in context\n- [ ] Clear error messages\n- [ ] Appropriate image aspect ratios\n\n## Tools\n\n| Tool                                               | Purpose                    |\n| -------------------------------------------------- | -------------------------- |\n| `npm audit`                                        | Dependency vulnerabilities |\n| [SecurityHeaders.com](https://securityheaders.com) | Header analysis            |\n| [W3C Validator](https://validator.w3.org)          | HTML validation            |\n| Lighthouse                                         | Best practices audit       |\n| [Observatory](https://observatory.mozilla.org)     | Security scan              |\n\n## References\n\n- [MDN Web Security](https://developer.mozilla.org/en-US/docs/Web/Security)\n- [OWASP Top 10](https://owasp.org/www-project-top-ten/)\n- [Web Quality Audit](../web-quality-audit/SKILL.md)",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "cloudflare-deploy",
      "name": "cloudflare-deploy",
      "description": "Deploy applications and infrastructure to Cloudflare using Workers, Pages, and related platform services. Use when the user asks to deploy, host, publish, or set up a project on Cloudflare.",
      "category": "cloud",
      "path": "skills/(cloud)/cloudflare-deploy/SKILL.md",
      "content": "# Cloudflare Deploy\n\nConsolidated skill for building on the Cloudflare platform. Use decision trees below to find the right product, then load detailed references.\n\n## Prerequisites\n\n- When sandboxing blocks the deployment network calls, rerun with `sandbox_permissions=require_escalated`.\n- The deployment might take a few minutes. Use appropriate timeout values.\n\n## Authentication (Required Before Deploy)\n\nVerify auth before `wrangler deploy`, `wrangler pages deploy`, or `npm run deploy`:\n\n```bash\nnpx wrangler whoami    # Shows account if authenticated\n```\n\nNot authenticated? → `references/wrangler/auth.md`\n\n- Interactive/local: `wrangler login` (one-time OAuth)\n- CI/CD: Set `CLOUDFLARE_API_TOKEN` env var\n\n## Quick Decision Trees\n\n### \"I need to run code\"\n\n```\nNeed to run code?\n├─ Serverless functions at the edge → workers/\n├─ Full-stack web app with Git deploys → pages/\n├─ Stateful coordination/real-time → durable-objects/\n├─ Long-running multi-step jobs → workflows/\n├─ Run containers → containers/\n├─ Multi-tenant (customers deploy code) → workers-for-platforms/\n├─ Scheduled tasks (cron) → cron-triggers/\n├─ Lightweight edge logic (modify HTTP) → snippets/\n├─ Process Worker execution events (logs/observability) → tail-workers/\n└─ Optimize latency to backend infrastructure → smart-placement/\n```\n\n### \"I need to store data\"\n\n```\nNeed storage?\n├─ Key-value (config, sessions, cache) → kv/\n├─ Relational SQL → d1/ (SQLite) or hyperdrive/ (existing Postgres/MySQL)\n├─ Object/file storage (S3-compatible) → r2/\n├─ Message queue (async processing) → queues/\n├─ Vector embeddings (AI/semantic search) → vectorize/\n├─ Strongly-consistent per-entity state → durable-objects/ (DO storage)\n├─ Secrets management → secrets-store/\n├─ Streaming ETL to R2 → pipelines/\n└─ Persistent cache (long-term retention) → cache-reserve/\n```\n\n### \"I need AI/ML\"\n\n```\nNeed AI?\n├─ Run inference (LLMs, embeddings, images) → workers-ai/\n├─ Vector database for RAG/search → vectorize/\n├─ Build stateful AI agents → agents-sdk/\n├─ Gateway for any AI provider (caching, routing) → ai-gateway/\n└─ AI-powered search widget → ai-search/\n```\n\n### \"I need networking/connectivity\"\n\n```\nNeed networking?\n├─ Expose local service to internet → tunnel/\n├─ TCP/UDP proxy (non-HTTP) → spectrum/\n├─ WebRTC TURN server → turn/\n├─ Private network connectivity → network-interconnect/\n├─ Optimize routing → argo-smart-routing/\n├─ Optimize latency to backend (not user) → smart-placement/\n└─ Real-time video/audio → realtimekit/ or realtime-sfu/\n```\n\n### \"I need security\"\n\n```\nNeed security?\n├─ Web Application Firewall → waf/\n├─ DDoS protection → ddos/\n├─ Bot detection/management → bot-management/\n├─ API protection → api-shield/\n├─ CAPTCHA alternative → turnstile/\n└─ Credential leak detection → waf/ (managed ruleset)\n```\n\n### \"I need media/content\"\n\n```\nNeed media?\n├─ Image optimization/transformation → images/\n├─ Video streaming/encoding → stream/\n├─ Browser automation/screenshots → browser-rendering/\n└─ Third-party script management → zaraz/\n```\n\n### \"I need infrastructure-as-code\"\n\n```\nNeed IaC? → pulumi/ (Pulumi), terraform/ (Terraform), or api/ (REST API)\n```\n\n## Product Index\n\n### Compute & Runtime\n\n| Product               | Reference                           |\n| --------------------- | ----------------------------------- |\n| Workers               | `references/workers/`               |\n| Pages                 | `references/pages/`                 |\n| Pages Functions       | `references/pages-functions/`       |\n| Durable Objects       | `references/durable-objects/`       |\n| Workflows             | `references/workflows/`             |\n| Containers            | `references/containers/`            |\n| Workers for Platforms | `references/workers-for-platforms/` |\n| Cron Triggers         | `references/cron-triggers/`         |\n| Tail Workers          | `references/tail-workers/`          |\n| Snippets              | `references/snippets/`              |\n| Smart Placement       | `references/smart-placement/`       |\n\n### Storage & Data\n\n| Product         | Reference                     |\n| --------------- | ----------------------------- |\n| KV              | `references/kv/`              |\n| D1              | `references/d1/`              |\n| R2              | `references/r2/`              |\n| Queues          | `references/queues/`          |\n| Hyperdrive      | `references/hyperdrive/`      |\n| DO Storage      | `references/do-storage/`      |\n| Secrets Store   | `references/secrets-store/`   |\n| Pipelines       | `references/pipelines/`       |\n| R2 Data Catalog | `references/r2-data-catalog/` |\n| R2 SQL          | `references/r2-sql/`          |\n\n### AI & Machine Learning\n\n| Product    | Reference                |\n| ---------- | ------------------------ |\n| Workers AI | `references/workers-ai/` |\n| Vectorize  | `references/vectorize/`  |\n| Agents SDK | `references/agents-sdk/` |\n| AI Gateway | `references/ai-gateway/` |\n| AI Search  | `references/ai-search/`  |\n\n### Networking & Connectivity\n\n| Product              | Reference                          |\n| -------------------- | ---------------------------------- |\n| Tunnel               | `references/tunnel/`               |\n| Spectrum             | `references/spectrum/`             |\n| TURN                 | `references/turn/`                 |\n| Network Interconnect | `references/network-interconnect/` |\n| Argo Smart Routing   | `references/argo-smart-routing/`   |\n| Workers VPC          | `references/workers-vpc/`          |\n\n### Security\n\n| Product         | Reference                    |\n| --------------- | ---------------------------- |\n| WAF             | `references/waf/`            |\n| DDoS Protection | `references/ddos/`           |\n| Bot Management  | `references/bot-management/` |\n| API Shield      | `references/api-shield/`     |\n| Turnstile       | `references/turnstile/`      |\n\n### Media & Content\n\n| Product           | Reference                       |\n| ----------------- | ------------------------------- |\n| Images            | `references/images/`            |\n| Stream            | `references/stream/`            |\n| Browser Rendering | `references/browser-rendering/` |\n| Zaraz             | `references/zaraz/`             |\n\n### Real-Time Communication\n\n| Product      | Reference                  |\n| ------------ | -------------------------- |\n| RealtimeKit  | `references/realtimekit/`  |\n| Realtime SFU | `references/realtime-sfu/` |\n\n### Developer Tools\n\n| Product            | Reference                        |\n| ------------------ | -------------------------------- |\n| Wrangler           | `references/wrangler/`           |\n| Miniflare          | `references/miniflare/`          |\n| C3                 | `references/c3/`                 |\n| Observability      | `references/observability/`      |\n| Analytics Engine   | `references/analytics-engine/`   |\n| Web Analytics      | `references/web-analytics/`      |\n| Sandbox            | `references/sandbox/`            |\n| Workerd            | `references/workerd/`            |\n| Workers Playground | `references/workers-playground/` |\n\n### Infrastructure as Code\n\n| Product   | Reference               |\n| --------- | ----------------------- |\n| Pulumi    | `references/pulumi/`    |\n| Terraform | `references/terraform/` |\n| API       | `references/api/`       |\n\n### Other Services\n\n| Product       | Reference                   |\n| ------------- | --------------------------- |\n| Email Routing | `references/email-routing/` |\n| Email Workers | `references/email-workers/` |\n| Static Assets | `references/static-assets/` |\n| Bindings      | `references/bindings/`      |\n| Cache Reserve | `references/cache-reserve/` |\n\n## Troubleshooting\n\n### Escalated Network Access\n\nIf deployment fails due to network issues (timeouts, DNS errors, connection resets), rerun the deploy with escalated permissions (use `sandbox_permissions=require_escalated`). The deploy requires escalated network access when sandbox networking blocks outbound requests.\n\nExample guidance to the user:\n\n```\nThe deploy needs escalated network access to deploy to Cloudflare. I can rerun the command with escalated permissions—want me to proceed?\n```",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "configuration.md",
          "dynamic-routing.md",
          "features.md",
          "sdk-integration.md",
          "troubleshooting.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "testing.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api-live.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "networking.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "configuration.md",
          "gotchas.md",
          "integration.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "frameworks.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "README.md",
          "api.md",
          "auth.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md",
          "IMPLEMENTATION_SUMMARY.md",
          "README.md",
          "api.md",
          "configuration.md",
          "gotchas.md",
          "patterns.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "coding-guidelines",
      "name": "coding-guidelines",
      "description": "Apply when writing, modifying, or reviewing code. Behavioral guidelines to reduce common LLM coding mistakes. Triggers on implementation tasks, code changes, refactoring, bug fixes, or feature development.",
      "category": "development",
      "path": "skills/(development)/coding-guidelines/SKILL.md",
      "content": "# Coding Guidelines\n\nBehavioral guidelines to reduce common LLM coding mistakes. These principles bias toward caution over speed—for trivial tasks, use judgment.\n\n## 1. Think Before Coding\n\n**Don't assume. Don't hide confusion. Surface tradeoffs.**\n\nBefore implementing:\n\n- State assumptions explicitly. If uncertain, ask.\n- If multiple interpretations exist, present them—don't pick silently.\n- If a simpler approach exists, say so. Push back when warranted.\n- If something is unclear, stop. Name what's confusing. Ask.\n- Disagree honestly. If the user's approach seems wrong, say so—don't be sycophantic.\n\n## 2. Simplicity First\n\n**Minimum code that solves the problem. Nothing speculative.**\n\n- No features beyond what was asked.\n- No abstractions for single-use code.\n- No \"flexibility\" or \"configurability\" that wasn't requested.\n- No error handling for impossible scenarios.\n- If you write 200 lines and it could be 50, rewrite it.\n\nAsk yourself: \"Would a senior engineer say this is overcomplicated?\" If yes, simplify.\n\n## 3. Surgical Changes\n\n**Touch only what you must. Clean up only your own mess.**\n\nWhen editing existing code:\n\n- Don't \"improve\" adjacent code, comments, or formatting.\n- Don't refactor things that aren't broken.\n- Match existing style, even if you'd do it differently.\n- If you notice unrelated dead code, mention it—don't delete it.\n\nWhen your changes create orphans:\n\n- Remove imports/variables/functions that YOUR changes made unused.\n- Don't remove pre-existing dead code unless asked.\n\n**The test:** Every changed line should trace directly to the user's request.\n\n## 4. Goal-Driven Execution\n\n**Define success criteria. Loop until verified.**\n\nTransform tasks into verifiable goals:\n\n- \"Add validation\" → \"Write tests for invalid inputs, then make them pass\"\n- \"Fix the bug\" → \"Write a test that reproduces it, then make it pass\"\n- \"Refactor X\" → \"Ensure tests pass before and after\"\n\nFor multi-step tasks, state a brief plan:\n\n```\n1. [Step] → verify: [check]\n2. [Step] → verify: [check]\n3. [Step] → verify: [check]\n```\n\nStrong success criteria let you loop independently. Weak criteria (\"make it work\") require constant clarification.",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "confluence-assistant",
      "name": "confluence-assistant",
      "description": "Expert in Confluence operations using Atlassian MCP - automatically detects workspace Confluence configuration or prompts for site details. Use for searching, creating, updating pages, managing spaces, and adding comments with proper Markdown formatting.",
      "category": "development",
      "path": "skills/(development)/confluence-assistant/SKILL.md",
      "content": "# ConfluenceAssistant\n\nExpert in TODO: describe expertise.\n\n## Process\n\n1. TODO: Step 1\n2. TODO: Step 2\n3. TODO: Step 3\n\n## Examples\n\nTODO: Add concrete input → output examples.",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "core-web-vitals",
      "name": "core-web-vitals",
      "description": "Optimize Core Web Vitals (LCP, INP, CLS) for better page experience and search ranking. Use when asked to \"improve Core Web Vitals\", \"fix LCP\", \"reduce CLS\", \"optimize INP\", \"page experience optimization\", or \"fix layout shifts\".",
      "category": "performance",
      "path": "skills/(performance)/core-web-vitals/SKILL.md",
      "content": "# Core Web Vitals optimization\n\nTargeted optimization for the three Core Web Vitals metrics that affect Google Search ranking and user experience.\n\n## The three metrics\n\n| Metric  | Measures         | Good    | Needs work    | Poor    |\n| ------- | ---------------- | ------- | ------------- | ------- |\n| **LCP** | Loading          | ≤ 2.5s  | 2.5s – 4s     | > 4s    |\n| **INP** | Interactivity    | ≤ 200ms | 200ms – 500ms | > 500ms |\n| **CLS** | Visual Stability | ≤ 0.1   | 0.1 – 0.25    | > 0.25  |\n\nGoogle measures at the **75th percentile** — 75% of page visits must meet \"Good\" thresholds.\n\n---\n\n## LCP: Largest Contentful Paint\n\nLCP measures when the largest visible content element renders. Usually this is:\n\n- Hero image or video\n- Large text block\n- Background image\n- `<svg>` element\n\n### Common LCP issues\n\n**1. Slow server response (TTFB > 800ms)**\n\n```\nFix: CDN, caching, optimized backend, edge rendering\n```\n\n**2. Render-blocking resources**\n\n```html\n<!-- ❌ Blocks rendering -->\n<link rel=\"stylesheet\" href=\"/all-styles.css\" />\n\n<!-- ✅ Critical CSS inlined, rest deferred -->\n<style>\n  /* Critical above-fold CSS */\n</style>\n<link rel=\"preload\" href=\"/styles.css\" as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" />\n```\n\n**3. Slow resource load times**\n\n```html\n<!-- ❌ No hints, discovered late -->\n<img src=\"/hero.jpg\" alt=\"Hero\" />\n\n<!-- ✅ Preloaded with high priority -->\n<link rel=\"preload\" href=\"/hero.webp\" as=\"image\" fetchpriority=\"high\" />\n<img src=\"/hero.webp\" alt=\"Hero\" fetchpriority=\"high\" />\n```\n\n**4. Client-side rendering delays**\n\n```javascript\n// ❌ Content loads after JavaScript\nuseEffect(() => {\n  fetch('/api/hero-text')\n    .then((r) => r.json())\n    .then(setHeroText)\n}, [])\n\n// ✅ Server-side or static rendering\n// Use SSR, SSG, or streaming to send HTML with content\nexport async function getServerSideProps() {\n  const heroText = await fetchHeroText()\n  return { props: { heroText } }\n}\n```\n\n### LCP optimization checklist\n\n```markdown\n- [ ] TTFB < 800ms (use CDN, edge caching)\n- [ ] LCP image preloaded with fetchpriority=\"high\"\n- [ ] LCP image optimized (WebP/AVIF, correct size)\n- [ ] Critical CSS inlined (< 14KB)\n- [ ] No render-blocking JavaScript in <head>\n- [ ] Fonts don't block text rendering (font-display: swap)\n- [ ] LCP element in initial HTML (not JS-rendered)\n```\n\n### LCP element identification\n\n```javascript\n// Find your LCP element\nnew PerformanceObserver((list) => {\n  const entries = list.getEntries()\n  const lastEntry = entries[entries.length - 1]\n  console.log('LCP element:', lastEntry.element)\n  console.log('LCP time:', lastEntry.startTime)\n}).observe({ type: 'largest-contentful-paint', buffered: true })\n```\n\n---\n\n## INP: Interaction to Next Paint\n\nINP measures responsiveness across ALL interactions (clicks, taps, key presses) during a page visit. It reports the worst interaction (at 98th percentile for high-traffic pages).\n\n### INP breakdown\n\nTotal INP = **Input Delay** + **Processing Time** + **Presentation Delay**\n\n| Phase        | Target  | Optimization                |\n| ------------ | ------- | --------------------------- |\n| Input Delay  | < 50ms  | Reduce main thread blocking |\n| Processing   | < 100ms | Optimize event handlers     |\n| Presentation | < 50ms  | Minimize rendering work     |\n\n### Common INP issues\n\n**1. Long tasks blocking main thread**\n\n```javascript\n// ❌ Long synchronous task\nfunction processLargeArray(items) {\n  items.forEach((item) => expensiveOperation(item))\n}\n\n// ✅ Break into chunks with yielding\nasync function processLargeArray(items) {\n  const CHUNK_SIZE = 100\n  for (let i = 0; i < items.length; i += CHUNK_SIZE) {\n    const chunk = items.slice(i, i + CHUNK_SIZE)\n    chunk.forEach((item) => expensiveOperation(item))\n\n    // Yield to main thread\n    await new Promise((r) => setTimeout(r, 0))\n    // Or use scheduler.yield() when available\n  }\n}\n```\n\n**2. Heavy event handlers**\n\n```javascript\n// ❌ All work in handler\nbutton.addEventListener('click', () => {\n  // Heavy computation\n  const result = calculateComplexThing()\n  // DOM updates\n  updateUI(result)\n  // Analytics\n  trackEvent('click')\n})\n\n// ✅ Prioritize visual feedback\nbutton.addEventListener('click', () => {\n  // Immediate visual feedback\n  button.classList.add('loading')\n\n  // Defer non-critical work\n  requestAnimationFrame(() => {\n    const result = calculateComplexThing()\n    updateUI(result)\n  })\n\n  // Use requestIdleCallback for analytics\n  requestIdleCallback(() => trackEvent('click'))\n})\n```\n\n**3. Third-party scripts**\n\n```javascript\n// ❌ Eagerly loaded, blocks interactions\n;<script src=\"https://heavy-widget.com/widget.js\"></script>\n\n// ✅ Lazy loaded on interaction or visibility\nconst loadWidget = () => {\n  import('https://heavy-widget.com/widget.js').then((widget) => widget.init())\n}\nbutton.addEventListener('click', loadWidget, { once: true })\n```\n\n**4. Excessive re-renders (React/Vue)**\n\n```javascript\n// ❌ Re-renders entire tree\nfunction App() {\n  const [count, setCount] = useState(0)\n  return (\n    <div>\n      <Counter count={count} />\n      <ExpensiveComponent /> {/* Re-renders on every count change */}\n    </div>\n  )\n}\n\n// ✅ Memoized expensive components\nconst MemoizedExpensive = React.memo(ExpensiveComponent)\n\nfunction App() {\n  const [count, setCount] = useState(0)\n  return (\n    <div>\n      <Counter count={count} />\n      <MemoizedExpensive />\n    </div>\n  )\n}\n```\n\n### INP optimization checklist\n\n```markdown\n- [ ] No tasks > 50ms on main thread\n- [ ] Event handlers complete quickly (< 100ms)\n- [ ] Visual feedback provided immediately\n- [ ] Heavy work deferred with requestIdleCallback\n- [ ] Third-party scripts don't block interactions\n- [ ] Debounced input handlers where appropriate\n- [ ] Web Workers for CPU-intensive operations\n```\n\n### INP debugging\n\n```javascript\n// Identify slow interactions\nnew PerformanceObserver((list) => {\n  for (const entry of list.getEntries()) {\n    if (entry.duration > 200) {\n      console.warn('Slow interaction:', {\n        type: entry.name,\n        duration: entry.duration,\n        processingStart: entry.processingStart,\n        processingEnd: entry.processingEnd,\n        target: entry.target,\n      })\n    }\n  }\n}).observe({ type: 'event', buffered: true, durationThreshold: 16 })\n```\n\n---\n\n## CLS: Cumulative Layout Shift\n\nCLS measures unexpected layout shifts. A shift occurs when a visible element changes position between frames without user interaction.\n\n**CLS Formula:** `impact fraction × distance fraction`\n\n### Common CLS causes\n\n**1. Images without dimensions**\n\n```html\n<!-- ❌ Causes layout shift when loaded -->\n<img src=\"photo.jpg\" alt=\"Photo\" />\n\n<!-- ✅ Space reserved -->\n<img src=\"photo.jpg\" alt=\"Photo\" width=\"800\" height=\"600\" />\n\n<!-- ✅ Or use aspect-ratio -->\n<img src=\"photo.jpg\" alt=\"Photo\" style=\"aspect-ratio: 4/3; width: 100%;\" />\n```\n\n**2. Ads, embeds, and iframes**\n\n```html\n<!-- ❌ Unknown size until loaded -->\n<iframe src=\"https://ad-network.com/ad\"></iframe>\n\n<!-- ✅ Reserve space with min-height -->\n<div style=\"min-height: 250px;\">\n  <iframe src=\"https://ad-network.com/ad\" height=\"250\"></iframe>\n</div>\n\n<!-- ✅ Or use aspect-ratio container -->\n<div style=\"aspect-ratio: 16/9;\">\n  <iframe src=\"https://youtube.com/embed/...\" style=\"width: 100%; height: 100%;\"></iframe>\n</div>\n```\n\n**3. Dynamically injected content**\n\n```javascript\n// ❌ Inserts content above viewport\nnotifications.prepend(newNotification)\n\n// ✅ Insert below viewport or use transform\nconst insertBelow = viewport.bottom < newNotification.top\nif (insertBelow) {\n  notifications.prepend(newNotification)\n} else {\n  // Animate in without shifting\n  newNotification.style.transform = 'translateY(-100%)'\n  notifications.prepend(newNotification)\n  requestAnimationFrame(() => {\n    newNotification.style.transform = ''\n  })\n}\n```\n\n**4. Web fonts causing FOUT**\n\n```css\n/* ❌ Font swap shifts text */\n@font-face {\n  font-family: 'Custom';\n  src: url('custom.woff2') format('woff2');\n}\n\n/* ✅ Optional font (no shift if slow) */\n@font-face {\n  font-family: 'Custom';\n  src: url('custom.woff2') format('woff2');\n  font-display: optional;\n}\n\n/* ✅ Or match fallback metrics */\n@font-face {\n  font-family: 'Custom';\n  src: url('custom.woff2') format('woff2');\n  font-display: swap;\n  size-adjust: 105%; /* Match fallback size */\n  ascent-override: 95%;\n  descent-override: 20%;\n}\n```\n\n**5. Animations triggering layout**\n\n```css\n/* ❌ Animates layout properties */\n.animate {\n  transition:\n    height 0.3s,\n    width 0.3s;\n}\n\n/* ✅ Use transform instead */\n.animate {\n  transition: transform 0.3s;\n}\n.animate.expanded {\n  transform: scale(1.2);\n}\n```\n\n### CLS optimization checklist\n\n```markdown\n- [ ] All images have width/height or aspect-ratio\n- [ ] All videos/embeds have reserved space\n- [ ] Ads have min-height containers\n- [ ] Fonts use font-display: optional or matched metrics\n- [ ] Dynamic content inserted below viewport\n- [ ] Animations use transform/opacity only\n- [ ] No content injected above existing content\n```\n\n### CLS debugging\n\n```javascript\n// Track layout shifts\nnew PerformanceObserver((list) => {\n  for (const entry of list.getEntries()) {\n    if (!entry.hadRecentInput) {\n      console.log('Layout shift:', entry.value)\n      entry.sources?.forEach((source) => {\n        console.log('  Shifted element:', source.node)\n        console.log('  Previous rect:', source.previousRect)\n        console.log('  Current rect:', source.currentRect)\n      })\n    }\n  }\n}).observe({ type: 'layout-shift', buffered: true })\n```\n\n---\n\n## Measurement tools\n\n### Lab testing\n\n- **Chrome DevTools** → Performance panel, Lighthouse\n- **WebPageTest** → Detailed waterfall, filmstrip\n- **Lighthouse CLI** → `npx lighthouse <url>`\n\n### Field data (real users)\n\n- **Chrome User Experience Report (CrUX)** → BigQuery or API\n- **Search Console** → Core Web Vitals report\n- **web-vitals library** → Send to your analytics\n\n```javascript\nimport { onLCP, onINP, onCLS } from 'web-vitals'\n\nfunction sendToAnalytics({ name, value, rating }) {\n  gtag('event', name, {\n    event_category: 'Web Vitals',\n    value: Math.round(name === 'CLS' ? value * 1000 : value),\n    event_label: rating,\n  })\n}\n\nonLCP(sendToAnalytics)\nonINP(sendToAnalytics)\nonCLS(sendToAnalytics)\n```\n\n---\n\n## Framework quick fixes\n\n### Next.js\n\n```jsx\n// LCP: Use next/image with priority\nimport Image from 'next/image'\n;<Image src=\"/hero.jpg\" priority fill alt=\"Hero\" />\n\n// INP: Use dynamic imports\nconst HeavyComponent = dynamic(() => import('./Heavy'), { ssr: false })\n\n// CLS: Image component handles dimensions automatically\n```\n\n### React\n\n```jsx\n// LCP: Preload in head\n;<link rel=\"preload\" href=\"/hero.jpg\" as=\"image\" fetchpriority=\"high\" />\n\n// INP: Memoize and useTransition\nconst [isPending, startTransition] = useTransition()\nstartTransition(() => setExpensiveState(newValue))\n\n// CLS: Always specify dimensions in img tags\n```\n\n### Vue/Nuxt\n\n```vue\n<!-- LCP: Use nuxt/image with preload -->\n<NuxtImg src=\"/hero.jpg\" preload loading=\"eager\" />\n\n<!-- INP: Use async components -->\n<component :is=\"() => import('./Heavy.vue')\" />\n\n<!-- CLS: Use aspect-ratio CSS -->\n<img :style=\"{ aspectRatio: '16/9' }\" />\n```\n\n## References\n\n- [web.dev LCP](https://web.dev/articles/lcp)\n- [web.dev INP](https://web.dev/articles/inp)\n- [web.dev CLS](https://web.dev/articles/cls)\n- [Performance skill](../performance/SKILL.md)",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "LCP.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "cursor-skill-creator",
      "name": "cursor-skill-creator",
      "description": "Creates Cursor-specific AI agent skills with SKILL.md format. Use when creating skills for Cursor editor specifically, following Cursor's patterns and directories (.cursor/skills/). Triggers on \"cursor skill\", \"create cursor skill\".",
      "category": "creation",
      "path": "skills/(creation)/cursor-skill-creator/SKILL.md",
      "content": "# Cursor Skill Creator\n\nYou are an expert in creating Agent Skills following Cursor's pattern.\n\n## When to Use This Skill\n\nUse this skill when the user asks to:\n\n- Create a new skill\n- Package domain-specific knowledge\n- Create reusable capabilities for the agent\n- Transform a repetitive process into a skill\n- Create quick, one-off actions (not complex tasks with multiple steps)\n\n**DO NOT use for complex tasks that require multiple steps** - for those, use subagents.\n\n## Skill Structure\n\nA skill is a `SKILL.md` file inside a folder in `.cursor/skills/` (project) or `~/.cursor/skills/` (user).\n\n### File Format\n\n```markdown\n---\ndescription: Short and objective description of what the skill does and when to use it (appears in menus). This description is used by the agent to decide when to apply the skill.\nname: Readable Skill Name (optional - if omitted, uses folder name)\n---\n\n# Skill Title\n\nDetailed instructions for the agent on how to use this skill.\n\n## When to Use\n\n- Use this skill when...\n- This skill is useful for...\n- Apply in situations where...\n\n## Step-by-Step Instructions\n\n1. First do this...\n2. Then do that...\n3. Finish with...\n\n## Conventions and Best Practices\n\n- Always do X\n- Never do Y\n- Prefer Z when...\n\n## Examples (optional)\n\n### Example 1: Example Title\n\nInput:\n```\n\nexample input\n\n```\n\nExpected output:\n```\n\nexample output\n\n```\n\n## Important Notes\n\n- Important note 1\n- Important note 2\n```\n\n## Skill Creation Process\n\nWhen creating a skill, follow these steps:\n\n### 1. Understand the Purpose\n\n- What specific problem does the skill solve?\n- When should the agent use this skill?\n- Is it a one-off/quick task (skill) or complex/multi-step (subagent)?\n- Who will use it (specific project or all projects)?\n\n### 2. Choose the Location\n\n- **Project**: `.cursor/skills/skill-name/SKILL.md` - only for the current project\n- **User**: `~/.cursor/skills/skill-name/SKILL.md` - available in all projects\n\n**Naming convention:**\n\n- Use kebab-case (words-separated-by-hyphens)\n- Be descriptive but concise\n- Examples: `format-imports`, `generate-tests`, `review-security`\n\n### 3. Write the Description\n\nThe description is CRITICAL - it determines when the agent uses the skill.\n\n**Good descriptions:**\n\n- \"Formats TypeScript imports in alphabetical order and removes duplicates\"\n- \"Generates Jest unit tests for React components following project patterns\"\n- \"Reviews code for common security vulnerabilities (SQL injection, XSS, CSRF)\"\n\n**Bad descriptions (avoid):**\n\n- \"Helps with code\" (too vague)\n- \"Does useful things\" (not specific)\n- \"General skill\" (no context of when to use)\n\n**Formula for good descriptions:**\n\n```\n[Specific action] + [in which context] + [following which criteria/patterns]\n```\n\n### 4. Structure the Instructions\n\nThe instructions should be:\n\n- **Specific**: Clear and unambiguous steps\n- **Actionable**: The agent can execute directly\n- **Focused**: One clear responsibility\n- **Complete**: Include all necessary details\n\n**Organize into sections:**\n\n1. **When to Use**: Clear triggers for application\n2. **Main Instructions**: Detailed step-by-step\n3. **Conventions**: Domain-specific rules and patterns\n4. **Examples**: Concrete use cases (optional but useful)\n5. **Notes**: Warnings, limitations, special cases\n\n### 5. Be Concise but Complete\n\n- Avoid long, rambling prompts (dilute focus)\n- Be direct and specific\n- Use lists and clear structure\n- Include concrete examples when useful\n\n### 6. Test and Refine\n\nAfter creating the skill:\n\n1. Test by making a prompt that should trigger the skill\n2. Verify that the agent uses the skill correctly\n3. Refine the description if the skill isn't triggered when expected\n4. Adjust instructions if behavior isn't as expected\n\n## Best Practices\n\n### ✅ DO\n\n- **Be specific in scope**: One skill = one clear responsibility\n- **Invest in the description**: It's how the agent decides to use the skill\n- **Use clear structure**: Headers, lists, examples\n- **Add to version control**: Share with the team\n- **Start simple**: Add complexity as needed\n- **Use concrete examples**: Demonstrate expected behavior\n\n### ❌ AVOID\n\n- **Generic skills**: \"Helps with general tasks\" is not useful\n- **Long prompts**: 2000 words don't make the skill smarter\n- **Duplicating slash commands**: If it's single-purpose, maybe a command is better\n- **Too many skills**: Start with 2-3 focused ones, add when needed\n- **Vague descriptions**: \"Use for general tasks\" gives no signal to the agent\n- **Complex tasks**: If it requires multiple steps and isolated context, use subagent\n\n## Skills vs Subagents vs Slash Commands\n\nUse this decision tree:\n\n```\nIs task single-purpose and instant?\n├─ YES → Is it a custom command?\n│         ├─ YES → Use slash command\n│         └─ NO → Use skill\n│\n└─ NO → Does it require multiple steps and isolated context?\n          ├─ YES → Use subagent\n          └─ NO → Use skill\n```\n\n**Examples:**\n\n- **Skill**: \"Generate a changelog based on commits since last tag\"\n- **Skill**: \"Format all imports following the style guide\"\n- **Subagent**: \"Implement complete OAuth authentication with tests\"\n- **Subagent**: \"Investigate and fix all failing tests\"\n- **Slash Command**: `/fix` to fix linter errors\n\n## Quick Template\n\nUse this template when creating a skill:\n\n```markdown\n---\ndescription: [Specific action] for [context] following [pattern/criteria]\n---\n\n# [Skill Name]\n\nYou are an expert in [specific domain].\n\n## When to Use\n\nUse this skill when:\n\n- [Trigger 1]\n- [Trigger 2]\n- [Trigger 3]\n\n## Process\n\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\n## Criteria and Conventions\n\n- [Rule 1]\n- [Rule 2]\n- [Rule 3]\n\n## Output Format (if applicable)\n\n[Describe the expected output format]\n```\n\n## Well-Structured Skill Examples\n\n### Example 1: Import Formatter\n\n````markdown\n---\ndescription: Organizes and formats JavaScript/TypeScript imports in alphabetical order, groups by type (external, internal, types) and removes duplicates.\n---\n\n# Import Formatter\n\n## When to Use\n\n- When finishing a file with disorganized imports\n- When asked to \"organize imports\"\n- Before commits to maintain consistency\n\n## Process\n\n1. Identify all import statements\n2. Classify into groups:\n   - External (node_modules)\n   - Internal (relative paths and aliases)\n   - Types (import type)\n3. Sort alphabetically within each group\n4. Remove duplicates\n5. Add blank line between groups\n\n## Expected Format\n\n```typescript\n// External\nimport { useState } from \"react\";\nimport axios from \"axios\";\n\n// Internal\nimport { Button } from \"@/components/Button\";\nimport { utils } from \"../utils\";\n\n// Types\nimport type { User } from \"@/types\";\n```\n````\n\n````\n\n### Example 2: Changelog Generator\n\n```markdown\n---\ndescription: Generates formatted changelog based on Git commits since last tag, categorizing by type (feat, fix, docs, etc.) following Conventional Commits.\n---\n\n# Changelog Generator\n\n## When to Use\n\n- When preparing a release\n- When asked to \"generate changelog\"\n- To document changes between versions\n\n## Process\n\n1. Fetch commits since last git tag\n2. Parse messages following Conventional Commits\n3. Categorize by type:\n   - ✨ Features (feat:)\n   - 🐛 Fixes (fix:)\n   - 📚 Docs (docs:)\n   - 🔧 Chore (chore:)\n   - ♻️ Refactor (refactor:)\n4. Format in markdown with bullet points\n5. Include breaking changes in separate section\n\n## Output Format\n\n```markdown\n## [Version] - [Date]\n\n### ✨ Features\n- feat(auth): add OAuth login\n- feat(api): endpoint for file upload\n\n### 🐛 Fixes\n- fix(ui): fix responsive menu\n- fix(db): resolve race condition in transactions\n\n### 📚 Documentation\n- docs: update README with new endpoints\n\n### ⚠️ BREAKING CHANGES\n- feat(api)!: remove endpoint /v1/legacy\n````\n\n```\n\n## Creation Outputs\n\nWhen creating a skill, you should:\n\n1. **Create the directory**: `.cursor/skills/[skill-name]/`\n2. **Create the file**: `SKILL.md` inside the directory\n3. **Confirm location**: Inform where the skill was created\n4. **Explain usage**: How to test/use the skill\n5. **Suggest improvements**: If relevant, suggest refinements\n\n## Quality Checklist\n\nBefore finalizing a skill, verify:\n\n- [ ] Description is specific and clear about when to use\n- [ ] Folder name uses kebab-case\n- [ ] Instructions are actionable and unambiguous\n- [ ] Scope is focused (one responsibility)\n- [ ] Concrete examples are included (if applicable)\n- [ ] Sections are well organized\n- [ ] It's not a complex task (that should be a subagent)\n- [ ] Output format is clear (if applicable)\n\n## Output Messages\n\nWhen creating a skill, inform the user:\n\n```\n\n✅ Skill created successfully!\n\n📁 Location: .cursor/skills/[name]/SKILL.md\n🎯 Purpose: [brief description]\n🔧 How to test: [example prompt that should trigger the skill]\n\n💡 Tip: The agent will use this skill automatically when it detects [context].\nYou can also mention it explicitly in prompts.\n\n```\n\n---\n\n## Remember\n\nSkills are for **reusable knowledge and one-off actions**. For complex tasks with multiple steps, delegation, and isolated context, use **subagents** instead of skills.\n```",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "cursor-subagent-creator",
      "name": "cursor-subagent-creator",
      "description": "Creates Cursor-specific AI subagents with isolated context for complex multi-step workflows. Use when creating subagents for Cursor editor specifically, following Cursor's patterns and directories (.cursor/agents/). Triggers on \"cursor subagent\", \"cursor agent\".",
      "category": "creation",
      "path": "skills/(creation)/cursor-subagent-creator/SKILL.md",
      "content": "# Cursor Subagent Creator\n\nYou are an expert in creating Subagents following Cursor's best practices.\n\n## When to Use This Skill\n\nUse this skill when the user asks to:\n- Create a new subagent/agent\n- Create a specialized assistant\n- Implement a complex workflow with multiple steps\n- Create verifiers, auditors, or domain experts\n- Tasks that require isolated context and multiple steps\n\n**DO NOT use for simple, one-off tasks** - for those, use skills.\n\n## What are Subagents?\n\nSubagents are specialized assistants that Cursor's Agent can delegate tasks to. Characteristics:\n\n- **Isolated context**: Each subagent has its own context window\n- **Parallel execution**: Multiple subagents can run simultaneously\n- **Specialization**: Configured with specific prompts and expertise\n- **Reusable**: Defined once, used in multiple contexts\n\n### Foreground vs Background\n\n| Mode | Behavior | Best for |\n|------|----------|----------|\n| **Foreground** | Blocks until complete, returns result immediately | Sequential tasks where you need the output |\n| **Background** | Returns immediately, works independently | Long-running tasks or parallel workstreams |\n\n## Subagent Structure\n\nA subagent is a markdown file in `.cursor/agents/` (project) or `~/.cursor/agents/` (user).\n\n### File Format\n\n```markdown\n---\nname: agent-name\ndescription: Description of when to use this subagent. The Agent reads this to decide delegation.\nmodel: inherit  # or fast, or specific model ID\nreadonly: false  # true to restrict write permissions\nis_background: false  # true to execute in background\n---\n\nYou are an [expert in X].\n\nWhen invoked:\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\n[Detailed instructions about expected behavior]\n\nReport [type of expected result]:\n- [Output format]\n- [Metrics or specific information]\n```\n\n## Subagent Creation Process\n\n### 1. Define the Purpose\n\n- What specific responsibility does the subagent have?\n- Why does it need isolated context?\n- Does it involve multiple complex steps?\n- Does it require deep specialization?\n\n### 2. Choose the Location\n\n- **Project**: `.cursor/agents/agent-name.md` - project-specific\n- **User**: `~/.cursor/agents/agent-name.md` - all projects\n\n**Naming convention:**\n- Use kebab-case (words-separated-by-hyphens)\n- Be descriptive of the specialization\n- Examples: `security-auditor`, `test-runner`, `debugger`, `verifier`\n\n### 3. Configure the Frontmatter\n\n#### name (optional)\n\nUnique identifier. If omitted, uses the filename.\n\n```yaml\nname: security-auditor\n```\n\n#### description (optional but recommended)\n\nCRITICAL for automatic delegation. Explains when the Agent should use this subagent.\n\n**Good descriptions:**\n- \"Security specialist. Use when implementing auth, payments, or handling sensitive data.\"\n- \"Debugging specialist for errors and test failures. Use when encountering issues.\"\n- \"Validates completed work. Use after tasks are marked done to confirm implementations are functional.\"\n\n**Phrases that encourage automatic delegation:**\n- \"Use proactively when...\"\n- \"Always use for...\"\n- \"Automatically delegate when...\"\n\n**Avoid:**\n- Vague descriptions: \"Helps with general tasks\"\n- No context of when to use\n\n#### model (optional)\n\n```yaml\nmodel: inherit  # Uses the same model as parent agent (default)\nmodel: fast     # Uses fast model\nmodel: claude-3-5-sonnet-20250219  # Specific model\n```\n\n**When to use each model:**\n- `inherit`: Default, maintains consistency\n- `fast`: For quick checks, formatting, simple tasks\n- Specific model: When you need specific capabilities\n\n#### readonly (optional)\n\n```yaml\nreadonly: true  # Restricts write permissions\n```\n\nUse when the subagent should only read/analyze, not modify.\n\n#### is_background (optional)\n\n```yaml\nis_background: true  # Executes in background\n```\n\nUse for:\n- Long-running tasks\n- Continuous monitoring\n- When you don't need the result immediately\n\n### 4. Write the Subagent Prompt\n\nThe prompt should define:\n\n1. **Identity**: \"You are an [expert]...\"\n2. **When invoked**: Context of use\n3. **Process**: Specific steps to follow\n4. **Expected output**: Format and content of the result\n5. **Behavior**: Approach and philosophy\n\n**Recommended structure:**\n\n```markdown\nYou are an [expert in X] specialized in [Y].\n\nWhen invoked:\n1. [First action]\n2. [Second action]\n3. [Third action]\n\n[Detailed instructions about approach]\n\nReport [type of result]:\n- [Specific format]\n- [Information to include]\n- [Metrics or criteria]\n\n[Philosophy or principles to follow]\n```\n\n### 5. Be Focused and Specific\n\n- **One clear responsibility**: Each subagent has one purpose\n- **Concise prompts**: Don't write 2000 words\n- **Actionable instructions**: Clear and testable steps\n- **Structured output**: Well-defined response format\n\n## Field Configuration\n\n| Field | Required | Default | Description |\n|-------|----------|---------|-------------|\n| `name` | No | Filename | Unique identifier (lowercase + hyphens) |\n| `description` | No | - | When to use this subagent (read by Agent) |\n| `model` | No | `inherit` | Model to use (`fast`, `inherit`, or specific ID) |\n| `readonly` | No | `false` | If true, write permissions restricted |\n| `is_background` | No | `false` | If true, executes in background |\n\n## Common Subagent Patterns\n\n### 1. Verification Agent\n\n**Purpose**: Independently validates that work declared as complete actually works.\n\n```markdown\n---\nname: verifier\ndescription: Validates completed work. Use after tasks are marked done to confirm implementations are functional.\nmodel: fast\n---\n\nYou are a skeptical validator. Your job is to verify that work declared complete actually works.\n\nWhen invoked:\n1. Identify what was declared as complete\n2. Verify that the implementation exists and is functional\n3. Execute tests or relevant verification steps\n4. Look for edge cases that may have been missed\n\nBe thorough and skeptical. Report:\n- What was verified and passed\n- What was declared but is incomplete or broken\n- Specific issues that need to be addressed\n\nDon't accept statements at face value. Test everything.\n```\n\n**Use for:**\n- Validating features work end-to-end\n- Catching partially implemented functionality\n- Ensuring tests actually pass\n\n### 2. Debugger\n\n**Purpose**: Expert in root cause analysis and error correction.\n\n```markdown\n---\nname: debugger\ndescription: Debugging specialist for errors and test failures. Use when encountering issues.\n---\n\nYou are a debugging expert specialized in root cause analysis.\n\nWhen invoked:\n1. Capture the error message and stack trace\n2. Identify reproduction steps\n3. Isolate the failure location\n4. Implement minimal fix\n5. Verify that the solution works\n\nFor each issue, provide:\n- Root cause explanation\n- Evidence supporting the diagnosis\n- Specific code fix\n- Testing approach\n\nFocus on fixing the underlying issue, not symptoms.\n```\n\n**Use for:**\n- Complex or obscure errors\n- Test failures that need investigation\n- Performance issues\n\n### 3. Security Auditor\n\n**Purpose**: Security expert auditing code.\n\n```markdown\n---\nname: security-auditor\ndescription: Security specialist. Use when implementing auth, payments, or handling sensitive data.\nmodel: inherit\n---\n\nYou are a security expert auditing code for vulnerabilities.\n\nWhen invoked:\n1. Identify security-sensitive code paths\n2. Check for common vulnerabilities (injection, XSS, auth bypass)\n3. Confirm that secrets are not hardcoded\n4. Review input validation and sanitization\n\nReport findings by severity:\n- **Critical** (must fix before deploy)\n- **High** (fix soon)\n- **Medium** (address when possible)\n- **Low** (suggested improvements)\n\nFor each finding, include:\n- Vulnerability description\n- Location in code\n- Potential impact\n- Fix recommendation\n```\n\n**Use for:**\n- Authentication/authorization implementations\n- Code handling payments\n- User inputs\n- External API integrations\n\n### 4. Test Runner\n\n**Purpose**: Expert in test automation.\n\n```markdown\n---\nname: test-runner\ndescription: Test automation expert. Use proactively to run tests and fix failures.\nis_background: false\n---\n\nYou are a test automation expert.\n\nWhen you see code changes, proactively execute the appropriate tests.\n\nIf tests fail:\n1. Analyze the failure output\n2. Identify the root cause\n3. Fix the issue preserving test intent\n4. Re-run to verify\n\nReport test results with:\n- Number of tests passed/failed\n- Summary of any failures\n- Changes made to fix issues\n\nNever break existing tests without clear justification.\n```\n\n**Use for:**\n- Running tests automatically after changes\n- Fixing test failures\n- Maintaining a healthy test suite\n\n### 5. Documentation Writer\n\n**Purpose**: Expert in creating clear documentation.\n\n```markdown\n---\nname: doc-writer\ndescription: Documentation specialist. Use when creating READMEs, API docs, or user guides.\nmodel: fast\n---\n\nYou are a technical documentation expert.\n\nWhen invoked:\n1. Analyze the code/feature to document\n2. Identify audience (developers, end users, etc.)\n3. Structure documentation logically\n4. Write with clarity and practical examples\n5. Include code examples when relevant\n\nDocumentation should include:\n- Purpose overview\n- How to install/configure (if applicable)\n- How to use with examples\n- Available parameters/options\n- Common use cases\n- Troubleshooting (if applicable)\n\nUse formatted markdown, clear language, and concrete examples.\n```\n\n### 6. Orchestrator\n\n**Purpose**: Coordinates multiple subagents in sequence.\n\n```markdown\n---\nname: orchestrator\ndescription: Coordinates complex workflows across multiple specialists. Use for multi-phase projects.\n---\n\nYou are a complex workflow orchestrator.\n\nWhen invoked:\n1. Analyze complete requirements\n2. Break into logical phases\n3. Delegate each phase to appropriate subagent\n4. Collect and integrate results\n5. Verify consistency across phases\n\nStandard workflow:\n1. **Planner**: Analyzes requirements and creates technical plan\n2. **Implementer**: Builds the feature based on plan\n3. **Verifier**: Confirms implementation matches requirements\n\nFor each handoff, include:\n- Structured output from previous phase\n- Context needed for next phase\n- Clear success criteria\n```\n\n## Using Subagents\n\n### Automatic Delegation\n\nThe Agent delegates automatically based on:\n- Task complexity and scope\n- Custom subagent descriptions\n- Current context and available tools\n\n**Encourage automatic delegation** using phrases in the description:\n- \"Use proactively when...\"\n- \"Always use for...\"\n- \"Automatically apply when...\"\n\n### Explicit Invocation\n\n`/name` syntax:\n\n```\n> /verifier confirm that the auth flow is complete\n> /debugger investigate this error\n> /security-auditor review the payment module\n```\n\nOr natural mention:\n\n```\n> Use the verifier subagent to confirm the auth flow is complete\n> Ask the debugger subagent to investigate this error\n> Run the security-auditor subagent on the payment module\n```\n\n### Parallel Execution\n\nLaunch multiple subagents simultaneously:\n\n```\n> Review the API changes and update documentation in parallel\n```\n\nThe Agent sends multiple Task tool calls in a single message.\n\n## Resuming Subagents\n\nSubagents can be resumed to continue previous conversations.\n\nEach execution returns an agent ID. Pass this ID to resume with preserved context:\n\n```\n> Resume agent abc123 and analyze remaining test failures\n```\n\nBackground subagents write their state while executing in `~/.cursor/subagents/`.\n\n## Best Practices\n\n### ✅ DO\n\n- **Write focused subagents**: One clear responsibility\n- **Invest in the description**: Determines when the Agent delegates\n- **Keep prompts concise**: Direct and specific\n- **Add to version control**: Share `.cursor/agents/` with the team\n- **Start with Agent-generated**: Let the Agent create the initial draft\n- **Use hooks for file output**: For consistent structured output\n- **Test the description**: Make prompts and see if the correct subagent is triggered\n\n### ❌ AVOID\n\n- **Dozens of generic subagents**: 50+ vague subagents are ineffective\n- **Vague descriptions**: \"Use for general tasks\" gives no signal\n- **Prompts too long**: 2000 words don't make the subagent smarter\n- **Duplicating slash commands**: Use skill if it's single-purpose without context isolation\n- **Too many subagents**: Start with 2-3 focused ones, add as needed\n\n### Anti-Patterns to Avoid\n\n⚠️ **Vague descriptions**: \"Use for general tasks\" → Be specific: \"Use when implementing authentication flows with OAuth providers.\"\n\n⚠️ **Prompts too long**: A 2000-word prompt is slower and harder to maintain.\n\n⚠️ **Duplicating slash commands**: If it's single-purpose without context isolation, use skill.\n\n⚠️ **Too many subagents**: Start with 2-3 focused ones. Add only with distinct use cases.\n\n## Skills vs Subagents vs Commands\n\nUse this decision tree:\n\n```\nIs the task complex with multiple steps?\n├─ YES → Does it require isolated context?\n│         ├─ YES → Use SUBAGENT\n│         └─ NO → Use SKILL\n│\n└─ NO → Is it a single, one-off action?\n          ├─ YES → Is it a custom command?\n│                 ├─ YES → Use slash command\n│                 └─ NO → Use SKILL\n          └─ NO → Use SUBAGENT\n```\n\n**Examples:**\n\n- **Subagent**: \"Implement complete OAuth authentication with tests and documentation\"\n- **Subagent**: \"Investigate all failing tests and fix them\"\n- **Subagent**: \"Perform complete security audit of the payments module\"\n- **Skill**: \"Generate changelog based on commits\"\n- **Skill**: \"Format file imports\"\n- **Command**: `/fix` to fix linter errors\n\n## Performance and Cost\n\nSubagents have trade-offs:\n\n| Benefit | Trade-off |\n|---------|-----------|\n| Context isolation | Startup overhead (each subagent collects its own context) |\n| Parallel execution | Higher token usage (multiple contexts simultaneously) |\n| Specialized focus | Latency (can be slower than main agent for simple tasks) |\n\n### Token and Cost Considerations\n\n- **Subagents consume tokens independently**: Each has its own context window\n- **Parallel execution multiplies tokens**: 5 subagents = ~5x the tokens of a single agent\n- **Evaluate the overhead**: For quick/simple tasks, the main agent is more efficient\n- **Subagents can be slower**: The benefit is isolation, not speed\n\n## Quick Template\n\n```markdown\n---\nname: [agent-name]\ndescription: [Expert in X]. Use when [specific context of when to delegate].\nmodel: inherit\n---\n\nYou are an [expert in X] specialized in [Y].\n\nWhen invoked:\n1. [First step]\n2. [Second step]\n3. [Third step]\n\n[Detailed instructions about approach and behavior]\n\nReport [type of result]:\n- [Specific format]\n- [Information to include]\n- [Success criteria]\n\n[Principles or philosophy to follow]\n```\n\n## Quality Checklist\n\nBefore finalizing a subagent:\n\n- [ ] Description is specific about when the Agent should delegate\n- [ ] Filename uses kebab-case\n- [ ] One clear responsibility (not generic)\n- [ ] Prompt is concise but complete\n- [ ] Instructions are actionable\n- [ ] Output format is well defined\n- [ ] Model configuration appropriate (inherit/fast/specific)\n- [ ] readonly defined correctly (if only reads/analyzes)\n- [ ] is_background defined correctly (if long-running)\n\n## Creation Outputs\n\nWhen creating a subagent, you should:\n\n1. **Create the file**: `.cursor/agents/[agent-name].md`\n2. **Confirm location**: Inform where it was created\n3. **Explain usage**: How to invoke/test the subagent\n4. **Show syntax**: Invocation examples\n5. **Suggest improvements**: If relevant, refinements\n\n## Output Messages\n\nWhen creating a subagent, inform:\n\n```\n✅ Subagent created successfully!\n\n📁 Location: .cursor/agents/[name].md\n🎯 Purpose: [brief description]\n🔧 How to invoke:\n   - Automatic: The Agent will delegate when it detects [context]\n   - Explicit: /[name] [your instruction]\n   - Natural: \"Use the [name] subagent to [task]\"\n\n💡 Tip: Include keywords in the description like \"use proactively\" \nto encourage automatic delegation.\n```\n\n## Complete Examples\n\n### Example 1: Code Reviewer\n\n```markdown\n---\nname: code-reviewer\ndescription: Code review specialist. Use proactively when code changes are ready for review or user asks for code review.\nmodel: inherit\n---\n\nYou are a code review expert with focus on quality, maintainability, and best practices.\n\nWhen invoked:\n1. Analyze the code changes\n2. Check:\n   - Readability and clarity\n   - Performance and efficiency\n   - Project patterns and conventions\n   - Error handling\n   - Edge cases\n   - Tests (coverage and quality)\n3. Identify code smells and potential bugs\n4. Suggest specific improvements\n\nReport in structured format:\n\n**✅ Approved / ⚠️ Approved with caveats / ❌ Changes needed**\n\n**Positive Points:**\n- [List of well-implemented aspects]\n\n**Issues Found:**\n- **[Severity]** [Location]: [Issue description]\n  - Suggestion: [How to fix]\n\n**Improvement Suggestions:**\n- [Optional but recommended improvements]\n\nBe constructive, specific, and focus on real impact.\n```\n\n### Example 2: Performance Optimizer\n\n```markdown\n---\nname: performance-optimizer\ndescription: Performance optimization specialist. Use when code has performance issues or user requests optimization.\nmodel: inherit\n---\n\nYou are a performance optimization expert.\n\nWhen invoked:\n1. Profile the code to identify bottlenecks\n2. Analyze:\n   - Algorithm complexity\n   - Memory usage\n   - I/O operations\n   - Database queries (N+1, indexes)\n   - Unnecessary renders (frontend)\n3. Identify quick wins vs complex optimizations\n4. Implement improvements maintaining readability\n\nReport each optimization:\n\n**Performance Analysis**\n\n**Bottlenecks Identified:**\n1. [Location]: [Issue]\n   - Impact: [Metric before]\n   - Cause: [Technical explanation]\n\n**Optimizations Implemented:**\n1. [Optimization name]\n   - Before: [Metric]\n   - After: [Metric]\n   - Change: [% improvement]\n   - Technique: [What was done]\n\n**Next Steps:**\n- [Possible additional optimizations]\n\nAlways measure real impact. Don't optimize prematurely.\n```\n\n---\n\n## Remember\n\nSubagents are for **complex tasks with multiple steps that benefit from isolated context**. For quick, one-off actions, use **skills**.\n\nThe power of subagents lies in:\n- Context isolation for long explorations\n- Parallel execution of workstreams\n- Deep specialization in specific domains\n- Independent verification of work",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "docs-writer",
      "name": "docs-writer",
      "description": "Use this skill for writing, reviewing, and editing documentation (`/docs` directory or any .md file).",
      "category": "development",
      "path": "skills/(development)/docs-writer/SKILL.md",
      "content": "# `docs-writer` skill instructions\n\nAs an expert technical writer and editor, your goal is to produce and refine documentation that is accurate, clear, consistent, and easy for users to understand. You must adhere to the documentation contribution process outlined in `CONTRIBUTING.md`.\n\n## Step 1: Understand the goal and create a plan\n\n1. **Clarify the request:** Fully understand the user's documentation request. Identify the core feature, command, or concept that needs work.\n2. **Differentiate the task:** Determine if the request is primarily for **writing** new content or **editing** existing content. If the request is ambiguous (e.g., \"fix the docs\"), ask the user for clarification.\n3. **Formulate a plan:** Create a clear, step-by-step plan for the required changes.\n\n## Step 2: Investigate and gather information\n\n1. **Read the code:** Thoroughly examine the relevant codebase, primarily within the `packages/` directory, to ensure your work is backed by the implementation and to identify any gaps.\n2. **Identify files:** Locate the specific documentation files in the `docs/` directory that need to be modified. Always read the latest version of a file before you begin work.\n3. **Check for connections:** Consider related documentation. If you change a command's behavior, check for other pages that reference it. If you add a new page, check if `docs/sidebar.json` needs to be updated. Make sure all links are up to date.\n\n## Step 3: Write or edit the documentation\n\n1. **Follow the style guide:** Adhere to the rules in `references/style-guide.md`. Read this file to understand the project's documentation standards.\n2. Ensure the new documentation accurately reflects the features in the code.\n3. **Use `replace` and `write_file`:** Use file system tools to apply your planned changes. For small edits, `replace` is preferred. For new files or large rewrites, `write_file` is more appropriate.\n\n### Sub-step: Editing existing documentation (as clarified in Step 1)\n\n- **Gaps:** Identify areas where the documentation is incomplete or no longer reflects existing code.\n- **Tone:** Ensure the tone is active and engaging, not passive.\n- **Clarity:** Correct awkward wording, spelling, and grammar. Rephrase sentences to make them easier for users to understand.\n- **Consistency:** Check for consistent terminology and style across all edited documents.\n\n## Step 4: Verify and finalize\n\n1. **Review your work:** After making changes, re-read the files to ensure the documentation is well-formatted, and the content is correct based on existing code.\n2. **Link verification:** Verify the validity of all links in the new content. Verify the validity of existing links leading to the page with the new content or deleted content.\n3. **Offer to run npm format:** Once all changes are complete, offer to run the project's formatting script to ensure consistency by proposing the command: `npm run format`",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "style-guide.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "figma",
      "name": "figma",
      "description": "Use the Figma MCP server to fetch design context, screenshots, variables, and assets from Figma, and to translate Figma nodes into production code. Trigger when a task involves Figma URLs, node IDs, design-to-code implementation, or Figma MCP setup and troubleshooting.",
      "category": "design",
      "path": "skills/(design)/figma/SKILL.md",
      "content": "# Figma MCP\n\nUse the Figma MCP server for Figma-driven implementation. For setup and debugging details (env vars, config, verification), see `references/figma-mcp-config.md`.\n\n## Figma MCP Integration Rules\n\nThese rules define how to translate Figma inputs into code for this project and must be followed for every Figma-driven change.\n\n### Required flow (do not skip)\n\n1. Run get_design_context first to fetch the structured representation for the exact node(s).\n2. If the response is too large or truncated, run get_metadata to get the high-level node map and then re-fetch only the required node(s) with get_design_context.\n3. Run get_screenshot for a visual reference of the node variant being implemented.\n4. Only after you have both get_design_context and get_screenshot, download any assets needed and start implementation.\n5. Translate the output (usually React + Tailwind) into this project's conventions, styles and framework. Reuse the project's color tokens, components, and typography wherever possible.\n6. Validate against Figma for 1:1 look and behavior before marking complete.\n\n### Implementation rules\n\n- Treat the Figma MCP output (React + Tailwind) as a representation of design and behavior, not as final code style.\n- Replace Tailwind utility classes with the project's preferred utilities/design-system tokens when applicable.\n- Reuse existing components (e.g., buttons, inputs, typography, icon wrappers) instead of duplicating functionality.\n- Use the project's color system, typography scale, and spacing tokens consistently.\n- Respect existing routing, state management, and data-fetch patterns already adopted in the repo.\n- Strive for 1:1 visual parity with the Figma design. When conflicts arise, prefer design-system tokens and adjust spacing or sizes minimally to match visuals.\n- Validate the final UI against the Figma screenshot for both look and behavior.\n\n### Asset handling\n\n- The Figma MCP Server provides an assets endpoint which can serve image and SVG assets.\n- IMPORTANT: If the Figma MCP Server returns a localhost source for an image or an SVG, use that image or SVG source directly.\n- IMPORTANT: DO NOT import/add new icon packages, all the assets should be in the Figma payload.\n- IMPORTANT: do NOT use or create placeholders if a localhost source is provided.\n\n### Link-based prompting\n\n- The server is link-based: copy the Figma frame/layer link and give that URL to the MCP client when asking for implementation help.\n- The client cannot browse the URL but extracts the node ID from the link; always ensure the link points to the exact node/variant you want.\n\n## References\n\n- `references/figma-mcp-config.md` — setup, verification, troubleshooting, and link-based usage reminders.\n- `references/figma-tools-and-prompts.md` — tool catalog and prompt patterns for selecting frameworks/components and fetching metadata.",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "figma-mcp-config.md",
          "figma-tools-and-prompts.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "figma-implement-design",
      "name": "figma-implement-design",
      "description": "Translate Figma nodes into production-ready code with 1:1 visual fidelity using the Figma MCP workflow (design context, screenshots, assets, and project-convention translation). Trigger when the user provides Figma URLs or node IDs, or asks to implement designs or components that must match Figma specs. Requires a working Figma MCP server connection.",
      "category": "design",
      "path": "skills/(design)/figma-implement-design/SKILL.md",
      "content": "# Implement Design\n\n## Overview\n\nThis skill provides a structured workflow for translating Figma designs into production-ready code with pixel-perfect accuracy. It ensures consistent integration with the Figma MCP server, proper use of design tokens, and 1:1 visual parity with designs.\n\n## Prerequisites\n\n- Figma MCP server must be connected and accessible\n- User must provide a Figma URL in the format: `https://figma.com/design/:fileKey/:fileName?node-id=1-2`\n  - `:fileKey` is the file key\n  - `1-2` is the node ID (the specific component or frame to implement)\n- **OR** when using `figma-desktop` MCP: User can select a node directly in the Figma desktop app (no URL required)\n- Project should have an established design system or component library (preferred)\n\n## Required Workflow\n\n**Follow these steps in order. Do not skip steps.**\n\n### Step 0: Set up Figma MCP (if not already configured)\n\nIf any MCP call fails because Figma MCP is not connected, pause and set it up:\n\n1. Add the Figma MCP server to your agent's MCP configuration:\n   - URL: `https://mcp.figma.com/mcp`\n2. Enable remote MCP client if required by your agent.\n3. Log in with OAuth following your agent's authentication flow.\n\nAfter successful login, the user will have to restart their agent. You should finish your answer and tell them so when they try again they can continue with Step 1.\n\n### Step 1: Get Node ID\n\n#### Option A: Parse from Figma URL\n\nWhen the user provides a Figma URL, extract the file key and node ID to pass as arguments to MCP tools.\n\n**URL format:** `https://figma.com/design/:fileKey/:fileName?node-id=1-2`\n\n**Extract:**\n\n- **File key:** `:fileKey` (the segment after `/design/`)\n- **Node ID:** `1-2` (the value of the `node-id` query parameter)\n\n**Note:** When using the local desktop MCP (`figma-desktop`), `fileKey` is not passed as a parameter to tool calls. The server automatically uses the currently open file, so only `nodeId` is needed.\n\n**Example:**\n\n- URL: `https://figma.com/design/kL9xQn2VwM8pYrTb4ZcHjF/DesignSystem?node-id=42-15`\n- File key: `kL9xQn2VwM8pYrTb4ZcHjF`\n- Node ID: `42-15`\n\n#### Option B: Use Current Selection from Figma Desktop App (figma-desktop MCP only)\n\nWhen using the `figma-desktop` MCP and the user has NOT provided a URL, the tools automatically use the currently selected node from the open Figma file in the desktop app.\n\n**Note:** Selection-based prompting only works with the `figma-desktop` MCP server. The remote server requires a link to a frame or layer to extract context. The user must have the Figma desktop app open with a node selected.\n\n### Step 2: Fetch Design Context\n\nRun `get_design_context` with the extracted file key and node ID.\n\n```\nget_design_context(fileKey=\":fileKey\", nodeId=\"1-2\")\n```\n\nThis provides the structured data including:\n\n- Layout properties (Auto Layout, constraints, sizing)\n- Typography specifications\n- Color values and design tokens\n- Component structure and variants\n- Spacing and padding values\n\n**If the response is too large or truncated:**\n\n1. Run `get_metadata(fileKey=\":fileKey\", nodeId=\"1-2\")` to get the high-level node map\n2. Identify the specific child nodes needed from the metadata\n3. Fetch individual child nodes with `get_design_context(fileKey=\":fileKey\", nodeId=\":childNodeId\")`\n\n### Step 3: Capture Visual Reference\n\nRun `get_screenshot` with the same file key and node ID for a visual reference.\n\n```\nget_screenshot(fileKey=\":fileKey\", nodeId=\"1-2\")\n```\n\nThis screenshot serves as the source of truth for visual validation. Keep it accessible throughout implementation.\n\n### Step 4: Download Required Assets\n\nDownload any assets (images, icons, SVGs) returned by the Figma MCP server.\n\n**IMPORTANT:** Follow these asset rules:\n\n- If the Figma MCP server returns a `localhost` source for an image or SVG, use that source directly\n- DO NOT import or add new icon packages - all assets should come from the Figma payload\n- DO NOT use or create placeholders if a `localhost` source is provided\n- Assets are served through the Figma MCP server's built-in assets endpoint\n\n### Step 5: Translate to Project Conventions\n\nTranslate the Figma output into this project's framework, styles, and conventions.\n\n**Key principles:**\n\n- Treat the Figma MCP output (typically React + Tailwind) as a representation of design and behavior, not as final code style\n- Replace Tailwind utility classes with the project's preferred utilities or design system tokens\n- Reuse existing components (buttons, inputs, typography, icon wrappers) instead of duplicating functionality\n- Use the project's color system, typography scale, and spacing tokens consistently\n- Respect existing routing, state management, and data-fetch patterns\n\n### Step 6: Achieve 1:1 Visual Parity\n\nStrive for pixel-perfect visual parity with the Figma design.\n\n**Guidelines:**\n\n- Prioritize Figma fidelity to match designs exactly\n- Avoid hardcoded values - use design tokens from Figma where available\n- When conflicts arise between design system tokens and Figma specs, prefer design system tokens but adjust spacing or sizes minimally to match visuals\n- Follow WCAG requirements for accessibility\n- Add component documentation as needed\n\n### Step 7: Validate Against Figma\n\nBefore marking complete, validate the final UI against the Figma screenshot.\n\n**Validation checklist:**\n\n- [ ] Layout matches (spacing, alignment, sizing)\n- [ ] Typography matches (font, size, weight, line height)\n- [ ] Colors match exactly\n- [ ] Interactive states work as designed (hover, active, disabled)\n- [ ] Responsive behavior follows Figma constraints\n- [ ] Assets render correctly\n- [ ] Accessibility standards met\n\n## Implementation Rules\n\n### Component Organization\n\n- Place UI components in the project's designated design system directory\n- Follow the project's component naming conventions\n- Avoid inline styles unless truly necessary for dynamic values\n\n### Design System Integration\n\n- ALWAYS use components from the project's design system when possible\n- Map Figma design tokens to project design tokens\n- When a matching component exists, extend it rather than creating a new one\n- Document any new components added to the design system\n\n### Code Quality\n\n- Avoid hardcoded values - extract to constants or design tokens\n- Keep components composable and reusable\n- Add TypeScript types for component props\n- Include JSDoc comments for exported components\n\n## Examples\n\n### Example 1: Implementing a Button Component\n\nUser says: \"Implement this Figma button component: https://figma.com/design/kL9xQn2VwM8pYrTb4ZcHjF/DesignSystem?node-id=42-15\"\n\n**Actions:**\n\n1. Parse URL to extract fileKey=`kL9xQn2VwM8pYrTb4ZcHjF` and nodeId=`42-15`\n2. Run `get_design_context(fileKey=\"kL9xQn2VwM8pYrTb4ZcHjF\", nodeId=\"42-15\")`\n3. Run `get_screenshot(fileKey=\"kL9xQn2VwM8pYrTb4ZcHjF\", nodeId=\"42-15\")` for visual reference\n4. Download any button icons from the assets endpoint\n5. Check if project has existing button component\n6. If yes, extend it with new variant; if no, create new component using project conventions\n7. Map Figma colors to project design tokens (e.g., `primary-500`, `primary-hover`)\n8. Validate against screenshot for padding, border radius, typography\n\n**Result:** Button component matching Figma design, integrated with project design system.\n\n### Example 2: Building a Dashboard Layout\n\nUser says: \"Build this dashboard: https://figma.com/design/pR8mNv5KqXzGwY2JtCfL4D/Dashboard?node-id=10-5\"\n\n**Actions:**\n\n1. Parse URL to extract fileKey=`pR8mNv5KqXzGwY2JtCfL4D` and nodeId=`10-5`\n2. Run `get_metadata(fileKey=\"pR8mNv5KqXzGwY2JtCfL4D\", nodeId=\"10-5\")` to understand the page structure\n3. Identify main sections from metadata (header, sidebar, content area, cards) and their child node IDs\n4. Run `get_design_context(fileKey=\"pR8mNv5KqXzGwY2JtCfL4D\", nodeId=\":childNodeId\")` for each major section\n5. Run `get_screenshot(fileKey=\"pR8mNv5KqXzGwY2JtCfL4D\", nodeId=\"10-5\")` for the full page\n6. Download all assets (logos, icons, charts)\n7. Build layout using project's layout primitives\n8. Implement each section using existing components where possible\n9. Validate responsive behavior against Figma constraints\n\n**Result:** Complete dashboard matching Figma design with responsive layout.\n\n## Best Practices\n\n### Always Start with Context\n\nNever implement based on assumptions. Always fetch `get_design_context` and `get_screenshot` first.\n\n### Incremental Validation\n\nValidate frequently during implementation, not just at the end. This catches issues early.\n\n### Document Deviations\n\nIf you must deviate from the Figma design (e.g., for accessibility or technical constraints), document why in code comments.\n\n### Reuse Over Recreation\n\nAlways check for existing components before creating new ones. Consistency across the codebase is more important than exact Figma replication.\n\n### Design System First\n\nWhen in doubt, prefer the project's design system patterns over literal Figma translation.\n\n## Common Issues and Solutions\n\n### Issue: Figma output is truncated\n\n**Cause:** The design is too complex or has too many nested layers to return in a single response.\n**Solution:** Use `get_metadata` to get the node structure, then fetch specific nodes individually with `get_design_context`.\n\n### Issue: Design doesn't match after implementation\n\n**Cause:** Visual discrepancies between the implemented code and the original Figma design.\n**Solution:** Compare side-by-side with the screenshot from Step 3. Check spacing, colors, and typography values in the design context data.\n\n### Issue: Assets not loading\n\n**Cause:** The Figma MCP server's assets endpoint is not accessible or the URLs are being modified.\n**Solution:** Verify the Figma MCP server's assets endpoint is accessible. The server serves assets at `localhost` URLs. Use these directly without modification.\n\n### Issue: Design token values differ from Figma\n\n**Cause:** The project's design system tokens have different values than those specified in the Figma design.\n**Solution:** When project tokens differ from Figma values, prefer project tokens for consistency but adjust spacing/sizing to maintain visual fidelity.\n\n## Understanding Design Implementation\n\nThe Figma implementation workflow establishes a reliable process for translating designs to code:\n\n**For designers:** Confidence that implementations will match their designs with pixel-perfect accuracy.\n**For developers:** A structured approach that eliminates guesswork and reduces back-and-forth revisions.\n**For teams:** Consistent, high-quality implementations that maintain design system integrity.\n\nBy following this workflow, you ensure that every Figma design is implemented with the same level of care and attention to detail.\n\n## Additional Resources\n\n- [Figma MCP Server Documentation](https://developers.figma.com/docs/figma-mcp-server/)\n- [Figma MCP Server Tools and Prompts](https://developers.figma.com/docs/figma-mcp-server/tools-and-prompts/)\n- [Figma Variables and Design Tokens](https://help.figma.com/hc/en-us/articles/15339657135383-Guide-to-variables-in-Figma)",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "gh-address-comments",
      "name": "gh-address-comments",
      "description": "Help address review/issue comments on the open GitHub PR for the current branch using gh CLI; verify gh auth first and prompt the user to authenticate if not logged in.",
      "category": "development",
      "path": "skills/(development)/gh-address-comments/SKILL.md",
      "content": "# PR Comment Handler\n\nGuide to find the open PR for the current branch and address its comments with gh CLI. Run all `gh` commands with elevated network access.\n\nPrereq: ensure `gh` is authenticated (for example, run `gh auth login` once), then run `gh auth status` with escalated permissions (include workflow/repo scopes) so `gh` commands succeed. If sandboxing blocks `gh auth status`, rerun it with `sandbox_permissions=require_escalated`.\n\n## 1) Inspect comments needing attention\n\n- Run scripts/fetch_comments.py which will print out all the comments and review threads on the PR\n\n## 2) Ask the user for clarification\n\n- Number all the review threads and comments and provide a short summary of what would be required to apply a fix for it\n- Ask the user which numbered comments should be addressed\n\n## 3) If user chooses comments\n\n- Apply fixes for the selected comments\n\nNotes:\n\n- If gh hits auth/rate issues mid-run, prompt the user to re-authenticate with `gh auth login`, then retry.",
      "metadata": {
        "hasScripts": true,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "gh-fix-ci",
      "name": "gh-fix-ci",
      "description": "Use when a user asks to debug or fix failing GitHub PR checks that run in GitHub Actions; use `gh` to inspect checks and logs, summarize failure context, draft a fix plan, and implement only after explicit approval. Treat external providers (for example Buildkite) as out of scope and report only the details URL.",
      "category": "tooling",
      "path": "skills/(tooling)/gh-fix-ci/SKILL.md",
      "content": "# Gh Pr Checks Plan Fix\n\n## Overview\n\nUse gh to locate failing PR checks, fetch GitHub Actions logs for actionable failures, summarize the failure snippet, then propose a fix plan and implement after explicit approval.\n\n- If a plan-oriented skill (for example `create-plan`) is available, use it; otherwise draft a concise plan inline and request approval before implementing.\n\nPrereq: authenticate with the standard GitHub CLI once (for example, run `gh auth login`), then confirm with `gh auth status` (repo + workflow scopes are typically required).\n\n## Inputs\n\n- `repo`: path inside the repo (default `.`)\n- `pr`: PR number or URL (optional; defaults to current branch PR)\n- `gh` authentication for the repo host\n\n## Quick start\n\n- `python \"<path-to-skill>/scripts/inspect_pr_checks.py\" --repo \".\" --pr \"<number-or-url>\"`\n- Add `--json` if you want machine-friendly output for summarization.\n\n## Workflow\n\n1. Verify gh authentication.\n   - Run `gh auth status` in the repo.\n   - If unauthenticated, ask the user to run `gh auth login` (ensuring repo + workflow scopes) before proceeding.\n2. Resolve the PR.\n   - Prefer the current branch PR: `gh pr view --json number,url`.\n   - If the user provides a PR number or URL, use that directly.\n3. Inspect failing checks (GitHub Actions only).\n   - Preferred: run the bundled script (handles gh field drift and job-log fallbacks):\n     - `python \"<path-to-skill>/scripts/inspect_pr_checks.py\" --repo \".\" --pr \"<number-or-url>\"`\n     - Add `--json` for machine-friendly output.\n   - Manual fallback:\n     - `gh pr checks <pr> --json name,state,bucket,link,startedAt,completedAt,workflow`\n       - If a field is rejected, rerun with the available fields reported by `gh`.\n     - For each failing check, extract the run id from `detailsUrl` and run:\n       - `gh run view <run_id> --json name,workflowName,conclusion,status,url,event,headBranch,headSha`\n       - `gh run view <run_id> --log`\n     - If the run log says it is still in progress, fetch job logs directly:\n       - `gh api \"/repos/<owner>/<repo>/actions/jobs/<job_id>/logs\" > \"<path>\"`\n4. Scope non-GitHub Actions checks.\n   - If `detailsUrl` is not a GitHub Actions run, label it as external and only report the URL.\n   - Do not attempt Buildkite or other providers; keep the workflow lean.\n5. Summarize failures for the user.\n   - Provide the failing check name, run URL (if any), and a concise log snippet.\n   - Call out missing logs explicitly.\n6. Create a plan.\n   - Use the `create-plan` skill to draft a concise plan and request approval.\n7. Implement after approval.\n   - Apply the approved plan, summarize diffs/tests, and ask about opening a PR.\n8. Recheck status.\n   - After changes, suggest re-running the relevant tests and `gh pr checks` to confirm.\n\n## Bundled Resources\n\n### scripts/inspect_pr_checks.py\n\nFetch failing PR checks, pull GitHub Actions logs, and extract a failure snippet. Exits non-zero when failures remain so it can be used in automation.\n\nUsage examples:\n\n- `python \"<path-to-skill>/scripts/inspect_pr_checks.py\" --repo \".\" --pr \"123\"`\n- `python \"<path-to-skill>/scripts/inspect_pr_checks.py\" --repo \".\" --pr \"https://github.com/org/repo/pull/123\" --json`\n- `python \"<path-to-skill>/scripts/inspect_pr_checks.py\" --repo \".\" --max-lines 200 --context 40`",
      "metadata": {
        "hasScripts": true,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "Jira Assistant",
      "name": "Jira Assistant",
      "description": "Expert in Jira operations using Atlassian MCP - automatically detects workspace Jira configuration or prompts for project details. Use for searching, creating, updating issues, managing status transitions, and handling tasks.",
      "category": "development",
      "path": "skills/(development)/jira-assistant/SKILL.md",
      "content": "# Jira Assistant\n\nYou are an expert in using Atlassian MCP tools to interact with Jira.\n\n## When to Use\n\nUse this skill when the user asks to:\n\n- Search for Jira issues or tasks\n- Create new Jira issues (Task, Epic, Subtask)\n- Update existing issues\n- Transition issue status (To Do → In Progress → Done, etc.)\n- Add comments to issues\n- Manage assignees\n- Query issues with specific criteria\n\n## Configuration\n\n**Project Detection Strategy (Automatic):**\n\n1. **Check workspace rules first**: Look for Jira configuration in `.cursor/rules/jira-config.mdc`\n2. **If not found**: Use MCP search tools to discover available projects\n3. **If still unclear**: Ask user to specify project key\n4. **Use detected values** for all Jira operations in this conversation\n\n### Configuration Detection Workflow\n\nWhen you activate this skill:\n\n1. Check if workspace has `.cursor/rules/jira-config.mdc` with Jira configuration\n2. If found, extract and use: Project Key, Cloud ID, URL, Board URL\n3. If not found:\n   - Use `search(\"jira projects I have access to\")` via MCP\n   - Present discovered projects to user\n   - Ask: \"Which Jira project should I use? (e.g., KAN, PROJ, DEV)\"\n4. Store the configuration for this conversation and proceed with operations\n\n**Note for skill users:** To configure this skill for your workspace, create `.cursor/rules/jira-config.mdc` with your project details.\n\n## Workflow\n\n### 1. Finding Issues (Always Start Here)\n\n**Use `search` (Rovo Search) first** for general queries:\n\n```\nsearch(\"issues in {PROJECT_KEY} project\")\nsearch(\"tasks assigned to me\")\nsearch(\"bugs in progress\")\n```\n\n- Natural language works better than JQL for general searches\n- Faster and more intuitive\n- Returns relevant results quickly\n- Replace `{PROJECT_KEY}` with the detected project key from configuration\n\n### 2. Searching with Specific Criteria\n\n**Use `searchJiraIssuesUsingJql`** when you need precise filters:\n\n**⚠️ ALWAYS include `project = {PROJECT_KEY}` in JQL queries**\n\nExamples (replace `{PROJECT_KEY}` with detected project key):\n\n```\nproject = {PROJECT_KEY} AND status = \"In Progress\"\nproject = {PROJECT_KEY} AND assignee = currentUser() AND created >= -7d\nproject = {PROJECT_KEY} AND type = \"Epic\" AND status != \"Done\"\nproject = {PROJECT_KEY} AND priority = \"High\"\n```\n\n### 3. Getting Issue Details\n\nDepending on what you have:\n\n- **If you have ARI**: `fetch(ari)`\n- **If you have issue key/id**: `getJiraIssue(cloudId, issueKey)`\n\n### 4. Creating Issues\n\n**ALWAYS use the detected `projectKey` and `cloudId` from configuration**\n\n#### Step-by-step process:\n\n```\na. View issue types:\n   getJiraProjectIssueTypesMetadata(\n     cloudId=\"{CLOUD_ID}\",\n     projectKey=\"{PROJECT_KEY}\"\n   )\n\nb. View required fields:\n   getJiraIssueTypeMetaWithFields(\n     cloudId=\"{CLOUD_ID}\",\n     projectKey=\"{PROJECT_KEY}\",\n     issueTypeId=\"from-step-a\"\n   )\n\nc. Create the issue:\n   createJiraIssue(\n     cloudId=\"{CLOUD_ID}\",\n     projectKey=\"{PROJECT_KEY}\",\n     issueTypeName=\"Task\",\n     summary=\"Brief task description\",\n     description=\"## Context\\n...\"\n   )\n```\n\n**Note:** Replace `{PROJECT_KEY}` and `{CLOUD_ID}` with values from detected configuration.\n\n**Available issue types:**\n\n- Task (default)\n- Epic\n- Subtask (requires `parent` field with parent issue key)\n\n### 5. Updating and Transitioning Issues\n\n#### Edit fields:\n\n```\neditJiraIssue(cloudId, issueKey, fields)\n```\n\n#### Change status:\n\n```\n1. Get available transitions:\n   getTransitionsForJiraIssue(cloudId, issueKey)\n\n2. Apply transition:\n   transitionJiraIssue(cloudId, issueKey, transitionId)\n```\n\n#### Add comment:\n\n```\naddCommentToJiraIssue(cloudId, issueKey, comment)\n```\n\n## Default Task Template\n\n**ALWAYS use this template** in the `description` field when creating issues:\n\n```markdown\n## Context\n\n[Brief explanation of the problem or need]\n\n## Objective\n\n[What needs to be accomplished]\n\n## Technical Requirements\n\n[This is high level, it doesn't mention which class or file, but the technical high level objective]\n\n- [ ] Requirement 1\n- [ ] Requirement 2\n- [ ] Requirement 3\n\n## Acceptance Criteria\n\n- [ ] Criteria 1\n- [ ] Criteria 2\n- [ ] Criteria 3\n\n## Technical Notes\n\n[Don't include file paths as they can change overtime]\n[Technical considerations, dependencies, relevant links]\n\n## Estimate\n\n[Time estimate or story points, if applicable]\n```\n\n## Best Practices\n\n### ✅ DO\n\n- **Always use the detected project key** in all operations\n- **Always use Markdown** in the `description` field\n- **Use `search` first** for natural language queries\n- **Use JQL** for precise filtering (but always include `project = {PROJECT_KEY}`)\n- **Follow the task template** for consistency\n- **Avoid file paths** in descriptions (they change over time)\n- **Keep summaries brief** and descriptions detailed\n\n### ⚠️ IMPORTANT\n\n- **Issue ID** is numeric (internal)\n- **Issue Key** is \"{PROJECT_KEY}-123\" format (user-facing)\n- **To create subtasks**: Use the `parent` field with parent issue key\n- **CloudId** can be URL or UUID - both work\n- **Use detected configuration values** from workspace rules or user input\n\n## Examples\n\n### Example 1: Create a Task\n\n```\nUser: \"Create a task to implement user authentication\"\n\ncreateJiraIssue(\n  cloudId=\"{CLOUD_ID}\",\n  projectKey=\"{PROJECT_KEY}\",\n  issueTypeName=\"Task\",\n  summary=\"Implement user authentication endpoint\",\n  description=\"## Context\nWe need to secure our API endpoints with user authentication.\n\n## Objective\nImplement JWT-based authentication for API access.\n\n## Technical Requirements\n- [ ] Create authentication middleware\n- [ ] Implement JWT token generation\n- [ ] Add token validation\n- [ ] Secure existing endpoints\n\n## Acceptance Criteria\n- [ ] Users can login with credentials\n- [ ] JWT tokens are generated on successful login\n- [ ] Protected endpoints validate tokens\n- [ ] Invalid tokens return 401\n\n## Technical Notes\nUse bcrypt for password hashing, JWT for tokens, and implement refresh token logic.\n\n## Estimate\n5 story points\"\n)\n```\n\n**Note:** Use actual values from detected configuration in place of placeholders.\n\n### Example 2: Search and Update Issue\n\n```\nUser: \"Find my in-progress tasks and update the first one\"\n\n1. searchJiraIssuesUsingJql(\n     cloudId=\"{CLOUD_ID}\",\n     jql=\"project = {PROJECT_KEY} AND assignee = currentUser() AND status = 'In Progress'\"\n   )\n\n2. editJiraIssue(\n     cloudId=\"{CLOUD_ID}\",\n     issueKey=\"{PROJECT_KEY}-123\",\n     fields={ \"description\": \"## Context\\nUpdated context...\" }\n   )\n```\n\n**Note:** Replace placeholders with detected configuration values.\n\n### Example 3: Transition Issue Status\n\n```\nUser: \"Move task {PROJECT_KEY}-456 to Done\"\n\n1. getTransitionsForJiraIssue(cloudId=\"{CLOUD_ID}\", issueKey=\"{PROJECT_KEY}-456\")\n\n2. transitionJiraIssue(\n     cloudId=\"{CLOUD_ID}\",\n     issueKey=\"{PROJECT_KEY}-456\",\n     transitionId=\"transition-id-for-done\"\n   )\n```\n\n**Note:** Replace placeholders with detected configuration values.\n\n### Example 4: Create Subtask\n\n```\nUser: \"Create a subtask for {PROJECT_KEY}-789\"\n\ncreateJiraIssue(\n  cloudId=\"{CLOUD_ID}\",\n  projectKey=\"{PROJECT_KEY}\",\n  issueTypeName=\"Subtask\",\n  parent=\"{PROJECT_KEY}-789\",\n  summary=\"Implement validation logic\",\n  description=\"## Context\\nSubtask for implementing input validation...\"\n)\n```\n\n**Note:** Replace placeholders with detected configuration values.\n\n## Common JQL Patterns\n\nAll queries **MUST** include `project = {PROJECT_KEY}` (use detected project key):\n\n```jql\n# My current work\nproject = {PROJECT_KEY} AND assignee = currentUser() AND status = \"In Progress\"\n\n# Recent issues\nproject = {PROJECT_KEY} AND created >= -7d\n\n# High priority bugs\nproject = {PROJECT_KEY} AND type = Bug AND priority = High\n\n# Epics without completion\nproject = {PROJECT_KEY} AND type = Epic AND status != Done\n\n# Unassigned tasks\nproject = {PROJECT_KEY} AND assignee is EMPTY AND status = \"To Do\"\n\n# Issues updated this week\nproject = {PROJECT_KEY} AND updated >= startOfWeek()\n```\n\n**Note:** Replace `{PROJECT_KEY}` with the actual project key from detected configuration.\n\n## Important Notes\n\n- **Project key is mandatory** - Always include `project = {PROJECT_KEY}` in JQL queries\n- **Use detected configuration** - Read from `.cursor/rules/jira-config.mdc` or ask user\n- **Use Markdown** in descriptions - Not HTML or plain text\n- **Follow the template** - Maintains consistency across issues\n- **Natural language search first** - Use JQL only when needed\n- **Avoid file paths** - They change and become outdated\n- **Keep technical notes high-level** - Focus on approach, not implementation details\n- **Story points are optional** - Include estimates when relevant",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "netlify-deploy",
      "name": "netlify-deploy",
      "description": "Deploy web projects to Netlify using the Netlify CLI (`npx netlify`). Use when the user asks to deploy, host, publish, or link a site/repo on Netlify, including preview and production deploys.",
      "category": "cloud",
      "path": "skills/(cloud)/netlify-deploy/SKILL.md",
      "content": "# Netlify Deployment Skill\n\nDeploy web projects to Netlify using the Netlify CLI with intelligent detection of project configuration and deployment context.\n\n## Overview\n\nThis skill automates Netlify deployments by:\n\n- Verifying Netlify CLI authentication\n- Detecting project configuration and framework\n- Linking to existing sites or creating new ones\n- Deploying to production or preview environments\n\n## Prerequisites\n\n- **Netlify CLI**: Installed via npx (no global install required)\n- **Authentication**: Netlify account with active login session\n- **Project**: Valid web project in current directory\n- When sandboxing blocks the deployment network calls, rerun with `sandbox_permissions=require_escalated`.\n- The deployment might take a few minutes. Use appropriate timeout values.\n\n## Authentication Pattern\n\nThe skill uses the **pre-authenticated Netlify CLI** approach:\n\n1. Check authentication status with `npx netlify status`\n2. If not authenticated, guide user through `npx netlify login`\n3. Fail gracefully if authentication cannot be established\n\nAuthentication uses either:\n\n- **Browser-based OAuth** (primary): `netlify login` opens browser for authentication\n- **API Key** (alternative): Set `NETLIFY_AUTH_TOKEN` environment variable\n\n## Workflow\n\n### 1. Verify Netlify CLI Authentication\n\nCheck if the user is logged into Netlify:\n\n```bash\nnpx netlify status\n```\n\n**Expected output patterns**:\n\n- ✅ Authenticated: Shows logged-in user email and site link status\n- ❌ Not authenticated: \"Not logged into any site\" or authentication error\n\n**If not authenticated**, guide the user:\n\n```bash\nnpx netlify login\n```\n\nThis opens a browser window for OAuth authentication. Wait for user to complete login, then verify with `netlify status` again.\n\n**Alternative: API Key authentication**\n\nIf browser authentication isn't available, users can set:\n\n```bash\nexport NETLIFY_AUTH_TOKEN=your_token_here\n```\n\nTokens can be generated at: https://app.netlify.com/user/applications#personal-access-tokens\n\n### 2. Detect Site Link Status\n\nFrom `netlify status` output, determine:\n\n- **Linked**: Site already connected to Netlify (shows site name/URL)\n- **Not linked**: Need to link or create site\n\n### 3. Link to Existing Site or Create New\n\n**If already linked** → Skip to step 4\n\n**If not linked**, attempt to link by Git remote:\n\n```bash\n# Check if project is Git-based\ngit remote show origin\n\n# If Git-based, extract remote URL\n# Format: https://github.com/username/repo or git@github.com:username/repo.git\n\n# Try to link by Git remote\nnpx netlify link --git-remote-url <REMOTE_URL>\n```\n\n**If link fails** (site doesn't exist on Netlify):\n\n```bash\n# Create new site interactively\nnpx netlify init\n```\n\nThis guides user through:\n\n1. Choosing team/account\n2. Setting site name\n3. Configuring build settings\n4. Creating netlify.toml if needed\n\n### 4. Verify Dependencies\n\nBefore deploying, ensure project dependencies are installed:\n\n```bash\n# For npm projects\nnpm install\n\n# For other package managers, detect and use appropriate command\n# yarn install, pnpm install, etc.\n```\n\n### 5. Deploy to Netlify\n\nChoose deployment type based on context:\n\n**Preview/Draft Deploy** (default for existing sites):\n\n```bash\nnpx netlify deploy\n```\n\nThis creates a deploy preview with a unique URL for testing.\n\n**Production Deploy** (for new sites or explicit production deployments):\n\n```bash\nnpx netlify deploy --prod\n```\n\nThis deploys to the live production URL.\n\n**Deployment process**:\n\n1. CLI detects build settings (from netlify.toml or prompts user)\n2. Builds the project locally\n3. Uploads built assets to Netlify\n4. Returns deployment URL\n\n### 6. Report Results\n\nAfter deployment, report to user:\n\n- **Deploy URL**: Unique URL for this deployment\n- **Site URL**: Production URL (if production deploy)\n- **Deploy logs**: Link to Netlify dashboard for logs\n- **Next steps**: Suggest `netlify open` to view site or dashboard\n\n## Handling netlify.toml\n\nIf a `netlify.toml` file exists, the CLI uses it automatically. If not, the CLI will prompt for:\n\n- **Build command**: e.g., `npm run build`, `next build`\n- **Publish directory**: e.g., `dist`, `build`, `.next`\n\nCommon framework defaults:\n\n- **Next.js**: build command `npm run build`, publish `.next`\n- **React (Vite)**: build command `npm run build`, publish `dist`\n- **Static HTML**: no build command, publish current directory\n\nThe skill should detect framework from `package.json` if possible and suggest appropriate settings.\n\n## Example Full Workflow\n\n```bash\n# 1. Check authentication\nnpx netlify status\n\n# If not authenticated:\nnpx netlify login\n\n# 2. Link site (if needed)\n# Try Git-based linking first\ngit remote show origin\nnpx netlify link --git-remote-url https://github.com/user/repo\n\n# If no site exists, create new one:\nnpx netlify init\n\n# 3. Install dependencies\nnpm install\n\n# 4. Deploy (preview for testing)\nnpx netlify deploy\n\n# 5. Deploy to production (when ready)\nnpx netlify deploy --prod\n```\n\n## Error Handling\n\nCommon issues and solutions:\n\n**\"Not logged in\"**\n→ Run `npx netlify login`\n\n**\"No site linked\"**\n→ Run `npx netlify link` or `npx netlify init`\n\n**\"Build failed\"**\n→ Check build command and publish directory in netlify.toml or CLI prompts\n→ Verify dependencies are installed\n→ Review build logs for specific errors\n\n**\"Publish directory not found\"**\n→ Verify build command ran successfully\n→ Check publish directory path is correct\n\n## Troubleshooting\n\n### Escalated Network Access\n\nIf deployment fails due to network issues (timeouts, DNS errors, connection resets), rerun the deploy with escalated permissions (use `sandbox_permissions=require_escalated`). The deploy requires escalated network access when sandbox networking blocks outbound requests.\n\nExample guidance to the user:\n\n```\nThe deploy needs escalated network access to deploy to Netlify. I can rerun the command with escalated permissions—want me to proceed?\n```\n\n## Environment Variables\n\nFor secrets and configuration:\n\n1. Never commit secrets to Git\n2. Set in Netlify dashboard: Site Settings → Environment Variables\n3. Access in builds via `process.env.VARIABLE_NAME`\n\n## Tips\n\n- Use `netlify deploy` (no `--prod`) first to test before production\n- Run `netlify open` to view site in Netlify dashboard\n- Run `netlify logs` to view function logs (if using Netlify Functions)\n- Use `netlify dev` for local development with Netlify Functions\n\n## Reference\n\n- Netlify CLI Docs: https://docs.netlify.com/cli/get-started/\n- netlify.toml Reference: https://docs.netlify.com/configure-builds/file-based-configuration/\n\n## Bundled References (Load As Needed)\n\n- [CLI commands](references/cli-commands.md)\n- [Deployment patterns](references/deployment-patterns.md)\n- [netlify.toml guide](references/netlify-toml.md)",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "cli-commands.md",
          "deployment-patterns.md",
          "netlify-toml.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "nx-ci-monitor",
      "name": "nx-ci-monitor",
      "description": "Monitor Nx Cloud CI pipeline and handle self-healing fixes automatically. Checks for Nx Cloud connection before starting.",
      "category": "tooling",
      "path": "skills/(tooling)/nx-ci-monitor/SKILL.md",
      "content": "# CI Monitor Command\n\nYou are the orchestrator for monitoring Nx Cloud CI pipeline executions and handling self-healing fixes. You spawn the `ci-watcher` subagent to poll CI status and make decisions based on the results.\n\n## Context\n\n- **Current Branch:** !`git branch --show-current`\n- **Current Commit:** !`git rev-parse --short HEAD`\n- **Remote Status:** !`git status -sb | head -1`\n\n## User Instructions\n\n$ARGUMENTS\n\n**Important:** If user provides specific instructions, respect them over default behaviors described below.\n\n## Configuration Defaults\n\n| Setting                   | Default       | Description                                                         |\n| ------------------------- | ------------- | ------------------------------------------------------------------- |\n| `--max-cycles`            | 10            | Maximum CIPE cycles before timeout                                  |\n| `--timeout`               | 120           | Maximum duration in minutes                                         |\n| `--verbosity`             | medium        | Output level: minimal, medium, verbose                              |\n| `--branch`                | (auto-detect) | Branch to monitor                                                   |\n| `--subagent-timeout`      | 60            | Subagent polling timeout in minutes                                 |\n| `--fresh`                 | false         | Ignore previous context, start fresh                                |\n| `--auto-fix-workflow`     | false         | Attempt common fixes for pre-CIPE failures (e.g., lockfile updates) |\n| `--new-cipe-timeout`      | 10            | Minutes to wait for new CIPE after action                           |\n| `--local-verify-attempts` | 3             | Max local verification + enhance cycles before pushing to CI        |\n\nParse any overrides from `$ARGUMENTS` and merge with defaults.\n\n## Nx Cloud Connection Check\n\n**CRITICAL**: Before starting the monitoring loop, verify the workspace is connected to Nx Cloud.\n\n### Step 0: Verify Nx Cloud Connection\n\n1. **Check `nx.json`** at workspace root for `nxCloudId` or `nxCloudAccessToken`\n2. **If `nx.json` missing OR neither property exists** → exit with:\n\n   ```\n   [ci-monitor] Nx Cloud not connected. Unlock 70% faster CI and auto-fix broken PRs with https://nx.dev/nx-cloud\n   ```\n\n3. **If connected** → continue to main loop\n\n## Session Context Behavior\n\n**Important:** Within a Claude Code session, conversation context persists. If you Ctrl+C to interrupt the monitor and re-run `/ci-monitor`, Claude remembers the previous state and may continue from where it left off.\n\n- **To continue monitoring:** Just re-run `/ci-monitor` (context is preserved)\n- **To start fresh:** Use `/ci-monitor --fresh` to ignore previous context\n- **For a completely clean slate:** Exit Claude Code and restart `claude`\n\n## Default Behaviors by Status\n\nThe subagent returns with one of the following statuses. This table defines the **default behavior** for each status. User instructions can override any of these.\n\n| Status              | Default Behavior                                                                                                                                                  |\n| ------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `ci_success`        | Exit with success. Log \"CI passed successfully!\"                                                                                                                  |\n| `fix_auto_applying` | Fix will be auto-applied by self-healing. Do NOT call MCP. Record `last_cipe_url`, spawn new subagent in wait mode to poll for new CIPE.                          |\n| `fix_available`     | Compare `failedTaskIds` vs `verifiedTaskIds` to determine verification state. See **Fix Available Decision Logic** section below.                                 |\n| `fix_failed`        | Self-healing failed to generate fix. Attempt local fix based on `taskOutputSummary`. If successful → commit, push, loop. If not → exit with failure.              |\n| `environment_issue` | Call MCP to request rerun: `update_self_healing_fix({ shortLink, action: \"RERUN_ENVIRONMENT_STATE\" })`. New CIPE spawns automatically. Loop to poll for new CIPE. |\n| `no_fix`            | CI failed, no fix available (self-healing disabled or not executable). Attempt local fix if possible. Otherwise exit with failure.                                |\n| `no_new_cipe`       | Expected CIPE never spawned (CI workflow likely failed before Nx tasks). Report to user, attempt common fixes if configured, or exit with guidance.               |\n| `polling_timeout`   | Subagent polling timeout reached. Exit with timeout.                                                                                                              |\n| `cipe_canceled`     | CIPE was canceled. Exit with canceled status.                                                                                                                     |\n| `cipe_timed_out`    | CIPE timed out. Exit with timeout status.                                                                                                                         |\n| `error`             | Increment `no_progress_count`. If >= 3 → exit with circuit breaker. Otherwise wait 60s and loop.                                                                  |\n\n### Fix Available Decision Logic\n\nWhen subagent returns `fix_available`, main agent compares `failedTaskIds` vs `verifiedTaskIds`:\n\n#### Step 1: Categorize Tasks\n\n1. **Verified tasks** = tasks in both `failedTaskIds` AND `verifiedTaskIds`\n2. **Unverified tasks** = tasks in `failedTaskIds` but NOT in `verifiedTaskIds`\n3. **E2E tasks** = unverified tasks where target contains \"e2e\" (task format: `<project>:<target>` or `<project>:<target>:<config>`)\n4. **Verifiable tasks** = unverified tasks that are NOT e2e\n\n#### Step 2: Determine Path\n\n| Condition                               | Path                                     |\n| --------------------------------------- | ---------------------------------------- |\n| No unverified tasks (all verified)      | Apply via MCP                            |\n| Unverified tasks exist, but ALL are e2e | Apply via MCP (treat as verified enough) |\n| Verifiable tasks exist                  | Local verification flow                  |\n\n#### Step 3a: Apply via MCP (fully/e2e-only verified)\n\n- Call `update_self_healing_fix({ shortLink, action: \"APPLY\" })`\n- Record `last_cipe_url`, spawn subagent in wait mode\n\n#### Step 3b: Local Verification Flow\n\nWhen verifiable (non-e2e) unverified tasks exist:\n\n1. **Detect package manager:**\n   - `pnpm-lock.yaml` exists → `pnpm nx`\n   - `yarn.lock` exists → `yarn nx`\n   - Otherwise → `npx nx`\n\n2. **Run verifiable tasks in parallel:**\n   - Spawn `general` subagents to run each task concurrently\n   - Each subagent runs: `<pm> nx run <taskId>`\n   - Collect pass/fail results from all subagents\n\n3. **Evaluate results:**\n\n| Result                    | Action                       |\n| ------------------------- | ---------------------------- |\n| ALL verifiable tasks pass | Apply via MCP                |\n| ANY verifiable task fails | Apply-locally + enhance flow |\n\n1. **Apply-locally + enhance flow:**\n   - Run `nx apply-locally <shortLink>`\n   - Enhance the code to fix failing tasks\n   - Run failing tasks again to verify fix\n   - If still failing → increment `local_verify_count`, loop back to enhance\n   - If passing → commit and push, record `expected_commit_sha`, spawn subagent in wait mode\n\n2. **Track attempts** (wraps step 4):\n   - Increment `local_verify_count` after each enhance cycle\n   - If `local_verify_count >= local_verify_attempts` (default: 3):\n     - Get code in commit-able state\n     - Commit and push with message indicating local verification failed\n     - Report to user:\n\n       ```\n       [ci-monitor] Local verification failed after <N> attempts. Pushed to CI for final validation. Failed: <taskIds>\n       ```\n\n     - Record `expected_commit_sha`, spawn subagent in wait mode (let CI be final judge)\n\n#### Commit Message Format\n\n```bash\ngit commit -m \"fix(<projects>): <brief description>\n\nFailed tasks: <taskId1>, <taskId2>\nLocal verification: passed|enhanced|failed-pushing-to-ci\"\n```\n\n### Unverified Fix Flow (No Verification Attempted)\n\nWhen `verificationStatus` is `FAILED`, `NOT_EXECUTABLE`, or fix has `couldAutoApplyTasks != true` with no verification:\n\n- Analyze fix content (`suggestedFix`, `suggestedFixReasoning`, `taskOutputSummary`)\n- If fix looks correct → apply via MCP\n- If fix needs enhancement → use Apply Locally + Enhance Flow above\n- If fix is wrong → reject via MCP, fix from scratch, commit, push\n\n### Auto-Apply Eligibility\n\nThe `couldAutoApplyTasks` field indicates whether the fix is eligible for automatic application:\n\n- **`true`**: Fix is eligible for auto-apply. Subagent keeps polling while verification is in progress. Returns `fix_auto_applying` when verified, or `fix_available` if verification fails.\n- **`false`** or **`null`**: Fix requires manual action (apply via MCP, apply locally, or reject)\n\n**Key point**: When subagent returns `fix_auto_applying`, do NOT call MCP to apply - self-healing handles it. Just spawn a new subagent in wait mode.\n\n### Apply vs Reject vs Apply Locally\n\n- **Apply via MCP**: Calls `update_self_healing_fix({ shortLink, action: \"APPLY\" })`. Self-healing agent applies the fix in CI and a new CIPE spawns automatically. No local git operations needed.\n- **Apply Locally**: Runs `nx apply-locally <shortLink>`. Applies the patch to your local working directory and sets state to `APPLIED_LOCALLY`. Use this when you want to enhance the fix before pushing.\n- **Reject via MCP**: Calls `update_self_healing_fix({ shortLink, action: \"REJECT\" })`. Marks fix as rejected. Use only when the fix is completely wrong and you'll fix from scratch.\n\n### Apply Locally + Enhance Flow\n\nWhen the fix needs enhancement (use `nx apply-locally`, NOT reject):\n\n1. Apply the patch locally: `nx apply-locally <shortLink>` (this also updates state to `APPLIED_LOCALLY`)\n2. Make additional changes as needed\n3. Commit and push:\n\n   ```bash\n   git add -A\n   git commit -m \"fix: resolve <failedTaskIds>\"\n   git push origin $(git branch --show-current)\n   ```\n\n4. Loop to poll for new CIPE\n\n### Reject + Fix From Scratch Flow\n\nWhen the fix is completely wrong:\n\n1. Call MCP to reject: `update_self_healing_fix({ shortLink, action: \"REJECT\" })`\n2. Fix the issue from scratch locally\n3. Commit and push:\n\n   ```bash\n   git add -A\n   git commit -m \"fix: resolve <failedTaskIds>\"\n   git push origin $(git branch --show-current)\n   ```\n\n4. Loop to poll for new CIPE\n\n### Environment Issue Handling\n\nWhen `failureClassification == 'ENVIRONMENT_STATE'`:\n\n1. Call MCP to request rerun: `update_self_healing_fix({ shortLink, action: \"RERUN_ENVIRONMENT_STATE\" })`\n2. New CIPE spawns automatically (no local git operations needed)\n3. Loop to poll for new CIPE with `previousCipeUrl` set\n\n### No-New-CIPE Handling\n\nWhen `status == 'no_new_cipe'`:\n\nThis means the expected CIPE was never created - CI likely failed before Nx tasks could run.\n\n1. **Report to user:**\n\n   ```\n   [ci-monitor] No CI attempt for <sha> after 10 min. Check CI provider for pre-Nx failures (install, checkout, auth). Last CI attempt: <previousCipeUrl>\n   ```\n\n2. **If user configured auto-fix attempts** (e.g., `--auto-fix-workflow`):\n   - Detect package manager: check for `pnpm-lock.yaml`, `yarn.lock`, `package-lock.json`\n   - Run install to update lockfile:\n\n     ```bash\n     pnpm install   # or npm install / yarn install\n     ```\n\n   - If lockfile changed:\n\n     ```bash\n     git add pnpm-lock.yaml  # or appropriate lockfile\n     git commit -m \"chore: update lockfile\"\n     git push origin $(git branch --show-current)\n     ```\n\n   - Record new commit SHA, loop to poll with `expectedCommitSha`\n\n3. **Otherwise:** Exit with `no_new_cipe` status, providing guidance for user to investigate\n\n## Exit Conditions\n\nExit the monitoring loop when ANY of these conditions are met:\n\n| Condition                                   | Exit Type        |\n| ------------------------------------------- | ---------------- |\n| CI passes (`cipeStatus == 'SUCCEEDED'`)     | Success          |\n| Max CIPE cycles reached                     | Timeout          |\n| Max duration reached                        | Timeout          |\n| 3 consecutive no-progress iterations        | Circuit breaker  |\n| No fix available and local fix not possible | Failure          |\n| No new CIPE and auto-fix not configured     | Pre-CIPE failure |\n| User cancels                                | Cancelled        |\n\n## Main Loop\n\n### Step 1: Initialize Tracking\n\n```\ncycle_count = 0\nstart_time = now()\nno_progress_count = 0\nlocal_verify_count = 0\nlast_state = null\nlast_cipe_url = null\nexpected_commit_sha = null\n```\n\n### Step 2: Spawn Subagent\n\nSpawn the `ci-watcher` subagent to poll CI status:\n\n**Fresh start (first spawn, no expected CIPE):**\n\n```\nTask(\n  agent: \"ci-watcher\",\n  prompt: \"Monitor CI for branch '<branch>'.\n           Subagent timeout: <subagent-timeout> minutes.\n           New-CIPE timeout: <new-cipe-timeout> minutes.\n           Verbosity: <verbosity>.\"\n)\n```\n\n**After action that triggers new CIPE (wait mode):**\n\n```\nTask(\n  agent: \"ci-watcher\",\n  prompt: \"Monitor CI for branch '<branch>'.\n           Subagent timeout: <subagent-timeout> minutes.\n           New-CIPE timeout: <new-cipe-timeout> minutes.\n           Verbosity: <verbosity>.\n\n           WAIT MODE: A new CIPE should spawn. Ignore old CIPE until new one appears.\n           Expected commit SHA: <expected_commit_sha>\n           Previous CIPE URL: <last_cipe_url>\"\n)\n```\n\n### Step 3: Handle Subagent Response\n\nWhen subagent returns:\n\n1. Check the returned status\n2. Look up default behavior in the table above\n3. Check if user instructions override the default\n4. Execute the appropriate action\n5. **If action expects new CIPE**, update tracking (see Step 3a)\n6. If action results in looping, go to Step 2\n\n### Step 3a: Track State for New-CIPE Detection\n\nAfter actions that should trigger a new CIPE, record state before looping:\n\n| Action                        | What to Track                                 | Subagent Mode |\n| ----------------------------- | --------------------------------------------- | ------------- |\n| Fix auto-applying             | `last_cipe_url = current cipeUrl`             | Wait mode     |\n| Apply via MCP                 | `last_cipe_url = current cipeUrl`             | Wait mode     |\n| Apply locally + push          | `expected_commit_sha = $(git rev-parse HEAD)` | Wait mode     |\n| Reject + fix + push           | `expected_commit_sha = $(git rev-parse HEAD)` | Wait mode     |\n| Fix failed + local fix + push | `expected_commit_sha = $(git rev-parse HEAD)` | Wait mode     |\n| No fix + local fix + push     | `expected_commit_sha = $(git rev-parse HEAD)` | Wait mode     |\n| Environment rerun             | `last_cipe_url = current cipeUrl`             | Wait mode     |\n| No-new-CIPE + auto-fix + push | `expected_commit_sha = $(git rev-parse HEAD)` | Wait mode     |\n\n**CRITICAL**: When passing `expectedCommitSha` or `last_cipe_url` to the subagent, it enters **wait mode**:\n\n- Subagent will **completely ignore** the old/stale CIPE\n- Subagent will only wait for new CIPE to appear\n- Subagent will NOT return to main agent with stale CIPE data\n- Once new CIPE detected, subagent switches to normal polling\n\n**Why wait mode matters for context preservation**: Stale CIPE data can be very large (task output summaries, suggested fix patches, reasoning). If subagent returns this to main agent, it pollutes main agent's context with useless data since we already processed that CIPE. Wait mode keeps stale data in the subagent, never sending it to main agent.\n\n### Step 4: Progress Tracking\n\nAfter each action:\n\n- If state changed significantly → reset `no_progress_count = 0`\n- If state unchanged → `no_progress_count++`\n- On new CI attempt detected → reset `local_verify_count = 0`\n\n## Status Reporting\n\nBased on verbosity level:\n\n| Level     | What to Report                                                             |\n| --------- | -------------------------------------------------------------------------- |\n| `minimal` | Only final result (success/failure/timeout)                                |\n| `medium`  | State changes + periodic updates (\"Cycle N \\| Elapsed: Xm \\| Status: ...\") |\n| `verbose` | All of medium + full subagent responses, git outputs, MCP responses        |\n\n## User Instruction Examples\n\nUsers can override default behaviors:\n\n| Instruction                                      | Effect                                        |\n| ------------------------------------------------ | --------------------------------------------- |\n| \"never auto-apply\"                               | Always prompt before applying any fix         |\n| \"always ask before git push\"                     | Prompt before each push                       |\n| \"reject any fix for e2e tasks\"                   | Auto-reject if `failedTaskIds` contains e2e   |\n| \"apply all fixes regardless of verification\"     | Skip verification check, apply everything     |\n| \"if confidence < 70, reject\"                     | Check confidence field before applying        |\n| \"run 'nx affected -t typecheck' before applying\" | Add local verification step                   |\n| \"auto-fix workflow failures\"                     | Attempt lockfile updates on pre-CIPE failures |\n| \"wait 45 min for new CIPE\"                       | Override new-CIPE timeout (default: 10 min)   |\n\n## Error Handling\n\n| Error                    | Action                                                                                |\n| ------------------------ | ------------------------------------------------------------------------------------- |\n| Git rebase conflict      | Report to user, exit                                                                  |\n| `nx apply-locally` fails | Report to user, attempt manual patch or exit                                          |\n| MCP tool error           | Retry once, if fails report to user                                                   |\n| Subagent spawn failure   | Retry once, if fails exit with error                                                  |\n| No new CIPE detected     | If `--auto-fix-workflow`, try lockfile update; otherwise report to user with guidance |\n| Lockfile auto-fix fails  | Report to user, exit with guidance to check CI logs                                   |\n\n## Example Session\n\n### Example 1: Normal Flow with Self-Healing (medium verbosity)\n\n```\n[ci-monitor] Starting CI monitor for branch 'feature/add-auth'\n[ci-monitor] Config: max-cycles=5, timeout=120m, verbosity=medium\n\n[ci-monitor] Spawning subagent to poll CI status...\n[CI Monitor] CI attempt: IN_PROGRESS | Self-Healing: NOT_STARTED | Elapsed: 1m\n[CI Monitor] CI attempt: FAILED | Self-Healing: IN_PROGRESS | Elapsed: 3m\n[CI Monitor] CI attempt: FAILED | Self-Healing: COMPLETED | Elapsed: 5m\n\n[ci-monitor] Fix available! Verification: COMPLETED\n[ci-monitor] Applying fix via MCP...\n[ci-monitor] Fix applied in CI. Waiting for new CI attempt...\n\n[ci-monitor] Spawning subagent to poll CI status...\n[CI Monitor] New CI attempt detected!\n[CI Monitor] CI attempt: SUCCEEDED | Elapsed: 8m\n\n[ci-monitor] CI passed successfully!\n\n[ci-monitor] Summary:\n  - Total cycles: 2\n  - Total time: 12m 34s\n  - Fixes applied: 1\n  - Result: SUCCESS\n```\n\n### Example 2: Pre-CI Failure (medium verbosity)\n\n```\n[ci-monitor] Starting CI monitor for branch 'feature/add-products'\n[ci-monitor] Config: max-cycles=5, timeout=120m, auto-fix-workflow=true\n\n[ci-monitor] Spawning subagent to poll CI status...\n[CI Monitor] CI attempt: FAILED | Self-Healing: COMPLETED | Elapsed: 2m\n\n[ci-monitor] Applying fix locally, enhancing, and pushing...\n[ci-monitor] Committed: abc1234\n\n[ci-monitor] Spawning subagent to poll CI status...\n[CI Monitor] Waiting for new CI attempt... (expected SHA: abc1234)\n[CI Monitor] ⚠️  CI attempt timeout (10 min). Returning no_new_cipe.\n\n[ci-monitor] Status: no_new_cipe\n[ci-monitor] --auto-fix-workflow enabled. Attempting lockfile update...\n[ci-monitor] Lockfile updated. Committed: def5678\n\n[ci-monitor] Spawning subagent to poll CI status...\n[CI Monitor] New CI attempt detected!\n[CI Monitor] CI attempt: SUCCEEDED | Elapsed: 18m\n\n[ci-monitor] CI passed successfully!\n\n[ci-monitor] Summary:\n  - Total cycles: 3\n  - Total time: 22m 15s\n  - Fixes applied: 1 (self-healing) + 1 (lockfile)\n  - Result: SUCCESS\n```",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "nx-generate",
      "name": "nx-generate",
      "description": "Generate code using nx generators. USE WHEN scaffolding code or transforming existing code - for example creating libraries or applications, or anything else that is boilerplate code or automates repetitive tasks. ALWAYS use this first when generating code with Nx instead of calling MCP tools or running nx generate immediately.",
      "category": "tooling",
      "path": "skills/(tooling)/nx-generate/SKILL.md",
      "content": "# Run Nx Generator\n\nNx generators are powerful tools that scaffold projects, make automated code migrations or automate repetitive tasks in a monorepo. They ensure consistency across the codebase and reduce boilerplate work.\n\nThis skill applies when the user wants to:\n\n- Create new projects like libraries or applications\n- Scaffold features or boilerplate code\n- Run workspace-specific or custom generators\n- Do anything else that an nx generator exists for\n\n## Generator Discovery Flow\n\n### Step 1: List Available Generators\n\nUse the Nx CLI to discover available generators:\n\n- List all generators for a plugin: `npx nx list @nx/react`\n- View available plugins: `npx nx list`\n\nThis includes:\n\n- Plugin generators (e.g., `@nx/react:library`, `@nx/js:library`)\n- Local workspace generators (defined in the repo's own plugins)\n\n### Step 2: Match Generator to User Request\n\nBased on the user's request, identify which generator(s) could fulfill their needs. Consider:\n\n- What artifact type they want to create (library, application, etc.)\n- Which framework or technology stack is relevant\n- Whether they mentioned specific generator names\n\n**IMPORTANT**: When both a local workspace generator and an external plugin generator could satisfy the request, **always prefer the local workspace generator**. Local generators are customized for the specific repo's patterns and conventions.\n\nIt's possible that the user request is something that no Nx generator exists for whatsoever. In this case, you can stop using this skill and try to help the user another way. HOWEVER, the burden of proof for this is high. Before aborting, carefully consider each and every generator that's available. Look into details for any that could be related in any way before making this decision.\n\n## Pre-Execution Checklist\n\nBefore running any generator, complete these steps:\n\n### 1. Fetch Generator Schema\n\nUse the `--help` flag to understand all available options:\n\n```bash\nnpx nx g @nx/react:library --help\n```\n\nPay attention to:\n\n- Required options that must be provided\n- Optional options that may be relevant to the user's request\n- Default values that might need to be overridden\n\n### 2. Read Generator Source Code\n\nUnderstanding what the generator actually does helps you:\n\n- Know what files will be created/modified\n- Understand any side effects (updating configs, installing deps, etc.)\n- Identify options that might not be obvious from the schema\n\nTo find generator source code:\n\n- For plugin generators: Use `node -e \"console.log(require.resolve('@nx/<plugin>/generators.json'));\"` to find the generators.json, then locate the source from there\n- If that fails, read directly from `node_modules/<plugin>/generators.json`\n- For local generators: They are typically in `tools/generators/` or a local plugin directory. You can search the repo for the generator name to find it.\n\n### 2.5 Reevaluate if the generator is right\n\nOnce you have built up an understanding of what the selected generator does, reconsider: Is this the right generator to service the user request?\nIf not, it's okay to go back to the Generator Discovery Flow and select a different generator before proceeding. If you do, make sure to go through the entire pre-execution checklist once more.\n\n### 3. Understand Repo Context\n\nBefore generating, examine the target area of the codebase:\n\n- Look at similar existing artifacts (other libraries, applications, etc.)\n- Identify patterns and conventions used in the repo\n- Note naming conventions, file structures, and configuration patterns\n- Try to match these patterns when configuring the generator\n\nFor example, if similar libraries are using a specific test runner, build tool or linter, try to match that if possible.\nIf projects or other artifacts are organized with a specific naming convention, try to match it.\n\n### 4. Validate Required Options\n\nEnsure all required options have values:\n\n- Map the user's request to generator options\n- Infer values from context where possible\n- Ask the user for any critical missing information\n\n## Execution\n\nKeep in mind that you might have to prefix things with npx/pnpx/yarn if the user doesn't have nx installed globally.\nMany generators will behave differently based on where they are executed. For example, first-party nx library generators use the cwd to determine the directory that the library should be placed in. This is highly important.\n\n### Consider Dry-Run (Optional)\n\nRunning with `--dry-run` first is strongly encouraged but not mandatory. Use your judgment:\n\n- For complex generators or unfamiliar territory: do a dry-run first\n- For simple, well-understood generators: may proceed directly\n- Dry-run shows file names and created/deleted/modified markers, but not content\n- There are cases where a generator does not support dry-run (for example if it had to install an npm package) - in that case --dry-run might fail. Don't be discouraged but simply move on to running the generator for real and iterating from there.\n\n### Running the Generator\n\nExecute the generator with:\n\n```bash\nnx generate <generator-name> <options> --no-interactive\n```\n\n**CRITICAL**: Always include `--no-interactive` to prevent prompts that would hang the execution.\n\nExample:\n\n```bash\nnx generate @nx/react:library --name=my-utils --no-interactive\n```\n\n### Handling Generator Failures\n\nIf the generator fails:\n\n1. **Diagnose the error** - Read the error message carefully\n2. **Identify the cause** - Missing options, invalid values, conflicts, etc.\n3. **Attempt automatic fix** - Adjust options or resolve conflicts\n4. **Retry** - Run the generator again with corrected options\n\nCommon failure reasons:\n\n- Missing required options\n- Invalid option values\n- Conflicting with existing files\n- Missing dependencies\n- Generator doesn't support certain flag combinations\n\n## Post-Generation\n\n### 1. Modify Generated Code (If Needed)\n\nGenerators provide a starting point, but the output may need adjustment to match the user's specific requirements:\n\n- Add or modify functionality as requested\n- Adjust imports, exports, or configurations\n- Integrate with existing code patterns in the repo\n\n### 2. Format Code\n\nRun formatting on all generated/modified files:\n\n```bash\nnx format --fix\n```\n\nLanguages other than javascript/typescript might need other formatting invocations too.\n\n### 3. Run Verification\n\nVerify that the generated code works correctly. What this looks like will vary depending on the type of generator and the targets available.\nIf the generator created a new project, run its targets directly\nUse your best judgement to determine what needs to be verified.\n\nExample:\n\n```bash\nnx lint <new-project>\nnx test <new-project>\nnx build <new-project>\n```\n\n### 4. Handle Verification Failures\n\nWhen verification fails:\n\n**If scope is manageable** (a few lint errors, minor type issues):\n\n- Fix the issues\n- Re-run verification to confirm\n\n**If issues are extensive** (many errors, complex problems):\n\n- Attempt simple, obvious fixes first\n- If still failing, escalate to the user with:\n  - Description of what was generated\n  - What verification is failing\n  - What you've attempted to fix\n  - Remaining issues that need user input\n\n## Error Handling\n\n### Generator Failures\n\n- Check the error message for specific causes\n- Verify all required options are provided\n- Check for conflicts with existing files\n- Ensure the generator name and options are correct\n\n### Missing Options\n\n- Consult the generator schema for required fields\n- Infer values from context when reasonable\n- Ask the user for values that cannot be inferred\n\n## Key Principles\n\n1. **Local generators first** - Always prefer workspace/local generators over external plugin generators when both could work\n\n2. **Understand before running** - Read both the schema AND the source code to fully understand what will happen\n\n3. **No prompts** - Always use `--no-interactive` to prevent hanging\n\n4. **Generators are starting points** - Modify the output as needed to fully satisfy the user's requirements\n\n5. **Verify changes work** - Don't just generate; ensure the code builds, lints, and tests pass\n\n6. **Be proactive about fixes** - Don't just report errors; attempt to resolve them automatically when possible\n\n7. **Match repo patterns** - Study existing similar code in the repo and match its conventions",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "nx-run-tasks",
      "name": "nx-run-tasks",
      "description": "Helps with running tasks in an Nx workspace. USE WHEN the user wants to execute build, test, lint, serve, or run any other tasks defined in the workspace.",
      "category": "tooling",
      "path": "skills/(tooling)/nx-run-tasks/SKILL.md",
      "content": "You can run tasks with Nx in the following way.\n\nKeep in mind that you might have to prefix things with npx/pnpx/yarn if the user doesn't have nx installed globally. Look at the package.json or lockfile to determine which package manager is in use.\n\nFor more details on any command, run it with `--help` (e.g. `nx run-many --help`, `nx affected --help`).\n\n## Understand which tasks can be run\n\nYou can check those via `nx show project <projectname> --json`, for example `nx show project myapp --json`. It contains a `targets` section which has information about targets that can be run. You can also just look at the `package.json` scripts or `project.json` targets, but you might miss out on inferred tasks by Nx plugins.\n\n## Run a single task\n\n```\nnx run <project>:<task>\n```\n\nwhere `project` is the project name defined in `package.json` or `project.json` (if present).\n\n## Run multiple tasks\n\n```\nnx run-many -t build test lint typecheck\n```\n\nYou can pass a `-p` flag to filter to specific projects, otherwise it runs on all projects. You can also use `--exclude` to exclude projects, and `--parallel` to control the number of parallel processes (default is 3).\n\nExamples:\n\n- `nx run-many -t test -p proj1 proj2` — test specific projects\n- `nx run-many -t test --projects=*-app --exclude=excluded-app` — test projects matching a pattern\n- `nx run-many -t test --projects=tag:api-*` — test projects by tag\n\n## Run tasks for affected projects\n\nUse `nx affected` to only run tasks on projects that have been changed and projects that depend on changed projects. This is especially useful in CI and for large workspaces.\n\n```\nnx affected -t build test lint\n```\n\nBy default it compares against the base branch. You can customize this:\n\n- `nx affected -t test --base=main --head=HEAD` — compare against a specific base and head\n- `nx affected -t test --files=libs/mylib/src/index.ts` — specify changed files directly\n\n## Useful flags\n\nThese flags work with `run`, `run-many`, and `affected`:\n\n- `--skipNxCache` — rerun tasks even when results are cached\n- `--verbose` — print additional information such as stack traces\n- `--nxBail` — stop execution after the first failed task\n- `--configuration=<name>` — use a specific configuration (e.g. `production`)",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "nx-workspace",
      "name": "nx-workspace",
      "description": "Configure, explore, and optimize Nx monorepo workspaces. Use when setting up Nx, exploring workspace structure, configuring project boundaries, running tasks, analyzing affected projects, optimizing build caching, or implementing CI/CD with affected commands. Keywords - nx, monorepo, workspace, projects, targets, affected, build, lint, test.",
      "category": "tooling",
      "path": "skills/(tooling)/nx-workspace/SKILL.md",
      "content": "# Nx Workspace Management\n\n## Quick Start\n\n**Exploring workspace**: `nx show projects` and `nx show project <name> --json`  \n**Running tasks**: `nx <target> <project>` (e.g., `nx build my-app`)  \n**Affected analysis**: `nx show projects --affected` or `nx affected -t <target>`\n\n> **Note**: Prefix commands with `npx`/`pnpx`/`yarn` if nx isn't installed globally.\n\n## Core Commands\n\n### List and Explore Projects\n\n```bash\n# List all projects\nnx show projects\n\n# Filter by type, pattern, or target\nnx show projects --type app\nnx show projects --projects \"apps/*\"\nnx show projects --withTarget build\n\n# Find affected projects\nnx show projects --affected --base=main\n```\n\n### Get Project Information\n\n**Critical**: Always use `nx show project <name> --json` for full resolved configuration. Do NOT read `project.json` directly - it contains only partial configuration.\n\n```bash\n# Get full configuration\nnx show project my-app --json\n\n# Extract targets\nnx show project my-app --json | jq '.targets | keys'\n```\n\nConfiguration schemas:\n\n- Workspace: `node_modules/nx/schemas/nx-schema.json`\n- Project: `node_modules/nx/schemas/project-schema.json`\n\n### Run Tasks\n\n```bash\n# Run specific project\nnx build web --configuration=production\n\n# Run affected\nnx affected -t test --base=main\n\n# View dependency graph\nnx graph\n```\n\n## Workspace Architecture\n\n```\nworkspace/\n├── apps/              # Deployable applications\n├── libs/              # Shared libraries\n│   ├── shared/        # Shared across scopes\n│   └── feature/       # Feature-specific\n├── nx.json            # Workspace configuration\n└── tools/             # Custom executors/generators\n```\n\n### Library Types\n\n| Type | Purpose | Example |\n|------|---------|---------|\n| **feature** | Business logic, smart components | `feature-auth` |\n| **ui** | Presentational components | `ui-buttons` |\n| **data-access** | API calls, state management | `data-access-users` |\n| **util** | Pure functions, helpers | `util-formatting` |\n\n## Detailed Resources\n\n**Configuration**: See [reference/configuration.md](reference/configuration.md) for:\n\n- nx.json templates and options\n- project.json structure\n- Module boundary rules\n- Remote caching setup\n\n**Commands**: See [reference/commands.md](reference/commands.md) for:\n\n- Complete command reference\n- Advanced filtering options\n- Common workflows\n\n**CI/CD**: See [reference/ci-cd.md](reference/ci-cd.md) for:\n\n- GitHub Actions configuration\n- GitLab CI setup\n- Jenkins, Azure Pipelines, CircleCI examples\n- Affected commands in pipelines\n\n**Best Practices**: See [reference/best-practices.md](reference/best-practices.md) for:\n\n- Do's and don'ts\n- Complete troubleshooting guide\n- Performance optimization\n- Migration guides\n\n## Common Workflows\n\n**\"What's in this workspace?\"**\n\n```bash\nnx show projects --type app  # List applications\nnx show projects --type lib  # List libraries\n```\n\n**\"How do I run project X?\"**\n\n```bash\nnx show project X --json | jq '.targets | keys'\n```\n\n**\"What changed?\"**\n\n```bash\nnx show projects --affected --base=main\n```\n\n## Quick Troubleshooting\n\n- **Targets not showing**: Use `nx show project <name> --json`, not project.json\n- **Affected not working**: Ensure git history available (`fetch-depth: 0` in CI)\n- **Cache issues**: Run `nx reset`\n\nFor detailed troubleshooting, see [reference/best-practices.md](reference/best-practices.md).",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "perf-astro",
      "name": "perf-astro",
      "description": "\"Astro-specific performance optimizations for 95+ Lighthouse scores. Covers critical CSS inlining, compression, font loading, and LCP optimization. Triggers on: astro performance, astro lighthouse, astro optimization, astro-critters.\"",
      "category": "performance",
      "path": "skills/(performance)/perf-astro/SKILL.md",
      "content": "# Astro Performance Playbook\n\nAstro-specific optimizations for 95+ Lighthouse scores.\n\n## Quick Setup\n\n```bash\nnpm install astro-critters @playform/compress\n```\n\n```js\n// astro.config.mjs\nimport { defineConfig } from 'astro/config';\nimport critters from 'astro-critters';\nimport compress from '@playform/compress';\n\nexport default defineConfig({\n  integrations: [\n    critters(),\n    compress({\n      CSS: true,\n      HTML: true,\n      JavaScript: true,\n      Image: false,\n      SVG: false,\n    }),\n  ],\n});\n```\n\n## Integrations\n\n### astro-critters\n\nAutomatically extracts and inlines critical CSS. No configuration needed.\n\nWhat it does:\n- Scans rendered HTML for above-the-fold elements\n- Inlines only the CSS those elements need\n- Lazy-loads the rest\n\nBuild output shows what it inlined:\n```\nInlined 40.70 kB (80% of original 50.50 kB) of _astro/index.xxx.css.\n```\n\n### @playform/compress\n\nMinifies HTML, CSS, and JavaScript in the final build.\n\nOptions:\n```js\ncompress({\n  CSS: true,      // Minify CSS\n  HTML: true,     // Minify HTML\n  JavaScript: true, // Minify JS\n  Image: false,   // Skip if using external image optimization\n  SVG: false,     // Skip if SVGs are already optimized\n})\n```\n\n## Layout Pattern\n\nStructure your `Layout.astro` for performance:\n\n```astro\n---\nimport '../styles/global.css'\n---\n\n<!doctype html>\n<html lang=\"pt-BR\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n\n    <!-- Font fallback (prevents FOIT) -->\n    <style>\n      @font-face {\n        font-family: 'Inter';\n        font-display: swap;\n        src: local('Inter');\n      }\n    </style>\n\n    <!-- Non-blocking Google Fonts -->\n    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n    <link\n      rel=\"stylesheet\"\n      href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap\"\n      media=\"print\"\n      onload=\"this.media='all'\"\n    />\n    <noscript>\n      <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap\">\n    </noscript>\n\n    <!-- Preload LCP images -->\n    <link rel=\"preload\" as=\"image\" href=\"/hero.png\" fetchpriority=\"high\">\n\n    <title>{title}</title>\n\n    <!-- Defer third-party scripts -->\n    <script>\n      let loaded = false;\n      function loadAnalytics() {\n        if (loaded) return;\n        loaded = true;\n        // Load GTM, analytics, etc.\n      }\n      ['scroll', 'click', 'touchstart'].forEach(e => {\n        document.addEventListener(e, loadAnalytics, { once: true, passive: true });\n      });\n      setTimeout(loadAnalytics, 5000);\n    </script>\n  </head>\n  <body>\n    <slot />\n  </body>\n</html>\n```\n\n## Measuring\n\n```bash\nnpx lighthouse https://your-site.com --preset=perf --form-factor=mobile\n```\n\nSee also:\n- **perf-lighthouse** - Running audits, reading reports, setting budgets\n- **perf-web-optimization** - Core Web Vitals, bundle size, caching strategies\n\n## Checklist\n\n- [ ] `astro-critters` installed and configured\n- [ ] `@playform/compress` installed and configured\n- [ ] Google Fonts use `media=\"print\" onload` pattern\n- [ ] Third-party scripts deferred to user interaction\n- [ ] LCP images preloaded in `<head>`",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "perf-lighthouse",
      "name": "perf-lighthouse",
      "description": "\"Run Lighthouse audits locally via CLI or Node API, parse and interpret reports, set performance budgets. Use when measuring site performance, understanding Lighthouse scores, setting up budgets, or integrating audits into CI. Triggers on: lighthouse, run lighthouse, lighthouse score, performance audit, performance budget.\"",
      "category": "performance",
      "path": "skills/(performance)/perf-lighthouse/SKILL.md",
      "content": "# Lighthouse Audits\n\n## CLI Quick Start\n\n```bash\n# Install\nnpm install -g lighthouse\n\n# Basic audit\nlighthouse https://example.com\n\n# Mobile performance only (faster)\nlighthouse https://example.com --preset=perf --form-factor=mobile\n\n# Output JSON for parsing\nlighthouse https://example.com --output=json --output-path=./report.json\n\n# Output HTML report\nlighthouse https://example.com --output=html --output-path=./report.html\n```\n\n## Common Flags\n\n```bash\n--preset=perf           # Performance only (skip accessibility, SEO, etc.)\n--form-factor=mobile    # Mobile device emulation (default)\n--form-factor=desktop   # Desktop\n--throttling-method=devtools  # More accurate throttling\n--only-categories=performance,accessibility  # Specific categories\n--chrome-flags=\"--headless\"   # Headless Chrome\n```\n\n## Performance Budgets\n\nCreate `budget.json`:\n\n```json\n[\n  {\n    \"resourceSizes\": [\n      { \"resourceType\": \"script\", \"budget\": 200 },\n      { \"resourceType\": \"image\", \"budget\": 300 },\n      { \"resourceType\": \"stylesheet\", \"budget\": 50 },\n      { \"resourceType\": \"total\", \"budget\": 500 }\n    ],\n    \"resourceCounts\": [\n      { \"resourceType\": \"third-party\", \"budget\": 5 }\n    ],\n    \"timings\": [\n      { \"metric\": \"interactive\", \"budget\": 3000 },\n      { \"metric\": \"first-contentful-paint\", \"budget\": 1500 },\n      { \"metric\": \"largest-contentful-paint\", \"budget\": 2500 }\n    ]\n  }\n]\n```\n\nRun with budget:\n\n```bash\nlighthouse https://example.com --budget-path=./budget.json\n```\n\n## Node API\n\n```javascript\nimport lighthouse from 'lighthouse';\nimport * as chromeLauncher from 'chrome-launcher';\n\nasync function runAudit(url) {\n  const chrome = await chromeLauncher.launch({ chromeFlags: ['--headless'] });\n\n  const result = await lighthouse(url, {\n    port: chrome.port,\n    onlyCategories: ['performance'],\n    formFactor: 'mobile',\n    throttling: {\n      cpuSlowdownMultiplier: 4,\n    },\n  });\n\n  await chrome.kill();\n\n  const { performance } = result.lhr.categories;\n  const { 'largest-contentful-paint': lcp } = result.lhr.audits;\n\n  return {\n    score: Math.round(performance.score * 100),\n    lcp: lcp.numericValue,\n  };\n}\n```\n\n## GitHub Actions\n\n```yaml\n# .github/workflows/lighthouse.yml\nname: Lighthouse\n\non:\n  pull_request:\n  push:\n    branches: [main]\n\njobs:\n  lighthouse:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build site\n        run: npm ci && npm run build\n\n      - name: Run Lighthouse\n        uses: treosh/lighthouse-ci-action@v11\n        with:\n          urls: |\n            http://localhost:3000\n            http://localhost:3000/about\n          budgetPath: ./budget.json\n          uploadArtifacts: true\n          temporaryPublicStorage: true\n        env:\n          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}\n```\n\n## Lighthouse CI (LHCI)\n\nFor full CI integration with historical tracking:\n\n```bash\n# Install\nnpm install -g @lhci/cli\n\n# Initialize config\nlhci wizard\n```\n\nCreates `lighthouserc.js`:\n\n```javascript\nmodule.exports = {\n  ci: {\n    collect: {\n      url: ['http://localhost:3000/', 'http://localhost:3000/about'],\n      startServerCommand: 'npm run start',\n      numberOfRuns: 3,\n    },\n    assert: {\n      assertions: {\n        'categories:performance': ['error', { minScore: 0.9 }],\n        'categories:accessibility': ['warn', { minScore: 0.9 }],\n        'first-contentful-paint': ['error', { maxNumericValue: 1500 }],\n        'largest-contentful-paint': ['error', { maxNumericValue: 2500 }],\n        'cumulative-layout-shift': ['error', { maxNumericValue: 0.1 }],\n      },\n    },\n    upload: {\n      target: 'temporary-public-storage', // or 'lhci' for self-hosted\n    },\n  },\n};\n```\n\nRun:\n\n```bash\nlhci autorun\n```\n\n## Parse JSON Report\n\n```javascript\nimport fs from 'fs';\n\nconst report = JSON.parse(fs.readFileSync('./report.json'));\n\n// Overall scores (0-1, multiply by 100 for percentage)\nconst scores = {\n  performance: report.categories.performance.score,\n  accessibility: report.categories.accessibility.score,\n  seo: report.categories.seo.score,\n};\n\n// Core Web Vitals\nconst vitals = {\n  lcp: report.audits['largest-contentful-paint'].numericValue,\n  cls: report.audits['cumulative-layout-shift'].numericValue,\n  fcp: report.audits['first-contentful-paint'].numericValue,\n  tbt: report.audits['total-blocking-time'].numericValue,\n};\n\n// Failed audits\nconst failed = Object.values(report.audits)\n  .filter(a => a.score !== null && a.score < 0.9)\n  .map(a => ({ id: a.id, score: a.score, title: a.title }));\n```\n\n## Compare Builds\n\n```bash\n# Save baseline\nlighthouse https://prod.example.com --output=json --output-path=baseline.json\n\n# Run on PR\nlighthouse https://preview.example.com --output=json --output-path=pr.json\n\n# Compare (custom script)\nnode compare-reports.js baseline.json pr.json\n```\n\nSimple comparison script:\n\n```javascript\nconst baseline = JSON.parse(fs.readFileSync(process.argv[2]));\nconst pr = JSON.parse(fs.readFileSync(process.argv[3]));\n\nconst metrics = ['largest-contentful-paint', 'cumulative-layout-shift', 'total-blocking-time'];\n\nmetrics.forEach(metric => {\n  const base = baseline.audits[metric].numericValue;\n  const current = pr.audits[metric].numericValue;\n  const diff = ((current - base) / base * 100).toFixed(1);\n  const emoji = current <= base ? '✅' : '❌';\n  console.log(`${emoji} ${metric}: ${diff}% (${base.toFixed(0)} → ${current.toFixed(0)})`);\n});\n```\n\n## Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| Inconsistent scores | Run multiple times (`--number-of-runs=3`), use median |\n| Chrome not found | Set `CHROME_PATH` env var |\n| Timeouts | Increase with `--max-wait-for-load=60000` |\n| Auth required | Use `--extra-headers` or puppeteer script |",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "perf-web-optimization",
      "name": "perf-web-optimization",
      "description": "\"Optimize web performance: Core Web Vitals (LCP, CLS, INP), bundle size, images, caching. Use when site is slow, optimizing for Lighthouse scores, reducing bundle size, fixing layout shifts, or improving Time to Interactive. Triggers on: web performance, Core Web Vitals, LCP, CLS, INP, FID, bundle size, page speed, slow site.\"",
      "category": "performance",
      "path": "skills/(performance)/perf-web-optimization/SKILL.md",
      "content": "# Web Performance Optimization\n\nSystematic approach: Measure → Identify → Prioritize → Implement → Verify.\n\n## Target Metrics\n\n| Metric | Good | Needs Work | Poor |\n|--------|------|------------|------|\n| LCP | < 2.5s | 2.5-4s | > 4s |\n| INP | < 200ms | 200-500ms | > 500ms |\n| CLS | < 0.1 | 0.1-0.25 | > 0.25 |\n| TTFB | < 800ms | 800ms-1.8s | > 1.8s |\n\n## Quick Wins\n\n### 1. Images (usually biggest impact on LCP)\n\n```html\n<!-- Hero/LCP image: eager + high priority -->\n<img src=\"/hero.webp\" alt=\"Hero\" width=\"1200\" height=\"600\"\n     loading=\"eager\" fetchpriority=\"high\" decoding=\"async\">\n\n<!-- Below fold: lazy load -->\n<img src=\"/product.webp\" alt=\"Product\" width=\"400\" height=\"300\"\n     loading=\"lazy\" decoding=\"async\">\n```\n\nAlways set `width` and `height` to prevent CLS.\n\n### 2. Fonts (common LCP/CLS culprit)\n\n```html\n<!-- Preconnect to font origin -->\n<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n\n<!-- Non-blocking font load -->\n<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Inter&display=swap\"\n      media=\"print\" onload=\"this.media='all'\">\n```\n\n### 3. Third-party Scripts (common INP killer)\n\n```html\n<!-- Defer to user interaction -->\n<script>\n  function loadThirdParty() {\n    // Load analytics, chat widgets, etc.\n  }\n  ['scroll','click','touchstart'].forEach(e =>\n    addEventListener(e, loadThirdParty, {once:true, passive:true})\n  );\n  setTimeout(loadThirdParty, 5000);\n</script>\n```\n\n### 4. Critical CSS\n\nInline critical CSS in `<head>`, defer the rest:\n\n```html\n<style>/* critical styles */</style>\n<link rel=\"preload\" href=\"/styles.css\" as=\"style\" onload=\"this.rel='stylesheet'\">\n```\n\n## Bundle Analysis\n\n```bash\n# Webpack\nnpx webpack-bundle-analyzer dist/stats.json\n\n# Vite\nnpx vite-bundle-visualizer\n\n# Check package size before installing\nnpx bundlephobia <package-name>\n```\n\nCommon heavy packages to replace:\n- `moment` (67KB) → `date-fns` (12KB) or `dayjs` (2KB)\n- `lodash` (72KB) → cherry-pick imports or native methods\n\n## Code Splitting Patterns\n\n```javascript\n// React lazy\nconst Chart = lazy(() => import('./Chart'));\n\n// Next.js dynamic\nconst Admin = dynamic(() => import('./Admin'), { ssr: false });\n\n// Vite/Rollup manual chunks\nbuild: {\n  rollupOptions: {\n    output: {\n      manualChunks: { vendor: ['react', 'react-dom'] }\n    }\n  }\n}\n```\n\n## Caching Headers\n\n```\n# Static assets (immutable hash in filename)\nCache-Control: public, max-age=31536000, immutable\n\n# HTML (revalidate)\nCache-Control: no-cache\n\n# API responses\nCache-Control: private, max-age=0, must-revalidate\n```\n\n## Measurement\n\n```bash\n# Quick audit\nnpx lighthouse https://site.com --preset=perf --form-factor=mobile\n```\n\nFor running audits, reading reports, and setting budgets, see **perf-lighthouse**.\n\n## Checklist\n\n### Images\n- [ ] Modern formats (WebP/AVIF)\n- [ ] Responsive `srcset`\n- [ ] `width`/`height` attributes\n- [ ] `loading=\"lazy\"` below fold\n- [ ] `fetchpriority=\"high\"` on LCP image\n\n### JavaScript\n- [ ] Bundle < 200KB gzipped\n- [ ] Code splitting by route\n- [ ] Third-party scripts deferred\n- [ ] No unused dependencies\n\n### CSS\n- [ ] Critical CSS inlined\n- [ ] Non-critical CSS deferred\n- [ ] No unused CSS\n\n### Fonts\n- [ ] `font-display: swap`\n- [ ] Preconnect to font origin\n- [ ] Subset if possible\n\n## Detailed Examples\n\nFor in-depth optimization patterns, see:\n- [references/core-web-vitals.md](references/core-web-vitals.md) - Fixing LCP, CLS, INP issues\n- [references/bundle-optimization.md](references/bundle-optimization.md) - Reducing JS bundle size\n- [references/image-optimization.md](references/image-optimization.md) - Image formats, responsive images, sharp scripts",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "bundle-optimization.md",
          "core-web-vitals.md",
          "image-optimization.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "playwright-skill",
      "name": "playwright-skill",
      "description": "Complete browser automation with Playwright. Auto-detects dev servers, writes clean test scripts to /tmp. Test pages, fill forms, take screenshots, check responsive design, validate UX, test login flows, check links, automate any browser task. Use when user wants to test websites, automate browser interactions, validate web functionality, or perform any browser-based testing.",
      "category": "web-automation",
      "path": "skills/(web-automation)/playwright-skill/SKILL.md",
      "content": "**IMPORTANT - Path Resolution:**\nThis skill can be installed in different locations (plugin system, manual installation, global, or project-specific). Before executing any commands, determine the skill directory based on where you loaded this SKILL.md file, and use that path in all commands below. Replace `$SKILL_DIR` with the actual discovered path.\n\n# Playwright Browser Automation\n\nGeneral-purpose browser automation skill. I'll write custom Playwright code for any automation task you request and execute it via the universal executor.\n\n**CRITICAL WORKFLOW - Follow these steps in order:**\n\n1. **Auto-detect dev servers** - For localhost testing, ALWAYS run server detection FIRST:\n\n   ```bash\n   cd $SKILL_DIR && node -e \"require('./lib/helpers').detectDevServers().then(servers => console.log(JSON.stringify(servers)))\"\n   ```\n\n   - If **1 server found**: Use it automatically, inform user\n   - If **multiple servers found**: Ask user which one to test\n   - If **no servers found**: Ask for URL or offer to help start dev server\n\n2. **Write scripts to /tmp** - NEVER write test files to skill directory; always use `/tmp/playwright-test-*.js`\n\n3. **Use visible browser by default** - Always use `headless: false` unless user specifically requests headless mode\n\n4. **Parameterize URLs** - Always make URLs configurable via environment variable or constant at top of script\n\n## How It Works\n\n1. You describe what you want to test/automate\n2. I auto-detect running dev servers (or ask for URL if testing external site)\n3. I write custom Playwright code in `/tmp/playwright-test-*.js` (won't clutter your project)\n4. I execute it via: `cd $SKILL_DIR && node run.js /tmp/playwright-test-*.js`\n5. Results displayed in real-time, browser window visible for debugging\n6. Test files auto-cleaned from /tmp by your OS\n\n## Setup (First Time)\n\n```bash\ncd $SKILL_DIR\nnpm run setup\n```\n\nThis installs Playwright and Chromium browser. Only needed once.\n\n## Execution Pattern\n\n**Step 1: Detect dev servers (for localhost testing)**\n\n```bash\ncd $SKILL_DIR && node -e \"require('./lib/helpers').detectDevServers().then(s => console.log(JSON.stringify(s)))\"\n```\n\n**Step 2: Write test script to /tmp with URL parameter**\n\n```javascript\n// /tmp/playwright-test-page.js\nconst { chromium } = require('playwright');\n\n// Parameterized URL (detected or user-provided)\nconst TARGET_URL = 'http://localhost:3001'; // <-- Auto-detected or from user\n\n(async () => {\n  const browser = await chromium.launch({ headless: false });\n  const page = await browser.newPage();\n\n  await page.goto(TARGET_URL);\n  console.log('Page loaded:', await page.title());\n\n  await page.screenshot({ path: '/tmp/screenshot.png', fullPage: true });\n  console.log('📸 Screenshot saved to /tmp/screenshot.png');\n\n  await browser.close();\n})();\n```\n\n**Step 3: Execute from skill directory**\n\n```bash\ncd $SKILL_DIR && node run.js /tmp/playwright-test-page.js\n```\n\n## Common Patterns\n\n### Test a Page (Multiple Viewports)\n\n```javascript\n// /tmp/playwright-test-responsive.js\nconst { chromium } = require('playwright');\n\nconst TARGET_URL = 'http://localhost:3001'; // Auto-detected\n\n(async () => {\n  const browser = await chromium.launch({ headless: false, slowMo: 100 });\n  const page = await browser.newPage();\n\n  // Desktop test\n  await page.setViewportSize({ width: 1920, height: 1080 });\n  await page.goto(TARGET_URL);\n  console.log('Desktop - Title:', await page.title());\n  await page.screenshot({ path: '/tmp/desktop.png', fullPage: true });\n\n  // Mobile test\n  await page.setViewportSize({ width: 375, height: 667 });\n  await page.screenshot({ path: '/tmp/mobile.png', fullPage: true });\n\n  await browser.close();\n})();\n```\n\n### Test Login Flow\n\n```javascript\n// /tmp/playwright-test-login.js\nconst { chromium } = require('playwright');\n\nconst TARGET_URL = 'http://localhost:3001'; // Auto-detected\n\n(async () => {\n  const browser = await chromium.launch({ headless: false });\n  const page = await browser.newPage();\n\n  await page.goto(`${TARGET_URL}/login`);\n\n  await page.fill('input[name=\"email\"]', 'test@example.com');\n  await page.fill('input[name=\"password\"]', 'password123');\n  await page.click('button[type=\"submit\"]');\n\n  // Wait for redirect\n  await page.waitForURL('**/dashboard');\n  console.log('✅ Login successful, redirected to dashboard');\n\n  await browser.close();\n})();\n```\n\n### Fill and Submit Form\n\n```javascript\n// /tmp/playwright-test-form.js\nconst { chromium } = require('playwright');\n\nconst TARGET_URL = 'http://localhost:3001'; // Auto-detected\n\n(async () => {\n  const browser = await chromium.launch({ headless: false, slowMo: 50 });\n  const page = await browser.newPage();\n\n  await page.goto(`${TARGET_URL}/contact`);\n\n  await page.fill('input[name=\"name\"]', 'John Doe');\n  await page.fill('input[name=\"email\"]', 'john@example.com');\n  await page.fill('textarea[name=\"message\"]', 'Test message');\n  await page.click('button[type=\"submit\"]');\n\n  // Verify submission\n  await page.waitForSelector('.success-message');\n  console.log('✅ Form submitted successfully');\n\n  await browser.close();\n})();\n```\n\n### Check for Broken Links\n\n```javascript\nconst { chromium } = require('playwright');\n\n(async () => {\n  const browser = await chromium.launch({ headless: false });\n  const page = await browser.newPage();\n\n  await page.goto('http://localhost:3000');\n\n  const links = await page.locator('a[href^=\"http\"]').all();\n  const results = { working: 0, broken: [] };\n\n  for (const link of links) {\n    const href = await link.getAttribute('href');\n    try {\n      const response = await page.request.head(href);\n      if (response.ok()) {\n        results.working++;\n      } else {\n        results.broken.push({ url: href, status: response.status() });\n      }\n    } catch (e) {\n      results.broken.push({ url: href, error: e.message });\n    }\n  }\n\n  console.log(`✅ Working links: ${results.working}`);\n  console.log(`❌ Broken links:`, results.broken);\n\n  await browser.close();\n})();\n```\n\n### Take Screenshot with Error Handling\n\n```javascript\nconst { chromium } = require('playwright');\n\n(async () => {\n  const browser = await chromium.launch({ headless: false });\n  const page = await browser.newPage();\n\n  try {\n    await page.goto('http://localhost:3000', {\n      waitUntil: 'networkidle',\n      timeout: 10000,\n    });\n\n    await page.screenshot({\n      path: '/tmp/screenshot.png',\n      fullPage: true,\n    });\n\n    console.log('📸 Screenshot saved to /tmp/screenshot.png');\n  } catch (error) {\n    console.error('❌ Error:', error.message);\n  } finally {\n    await browser.close();\n  }\n})();\n```\n\n### Test Responsive Design\n\n```javascript\n// /tmp/playwright-test-responsive-full.js\nconst { chromium } = require('playwright');\n\nconst TARGET_URL = 'http://localhost:3001'; // Auto-detected\n\n(async () => {\n  const browser = await chromium.launch({ headless: false });\n  const page = await browser.newPage();\n\n  const viewports = [\n    { name: 'Desktop', width: 1920, height: 1080 },\n    { name: 'Tablet', width: 768, height: 1024 },\n    { name: 'Mobile', width: 375, height: 667 },\n  ];\n\n  for (const viewport of viewports) {\n    console.log(\n      `Testing ${viewport.name} (${viewport.width}x${viewport.height})`,\n    );\n\n    await page.setViewportSize({\n      width: viewport.width,\n      height: viewport.height,\n    });\n\n    await page.goto(TARGET_URL);\n    await page.waitForTimeout(1000);\n\n    await page.screenshot({\n      path: `/tmp/${viewport.name.toLowerCase()}.png`,\n      fullPage: true,\n    });\n  }\n\n  console.log('✅ All viewports tested');\n  await browser.close();\n})();\n```\n\n## Inline Execution (Simple Tasks)\n\nFor quick one-off tasks, you can execute code inline without creating files:\n\n```bash\n# Take a quick screenshot\ncd $SKILL_DIR && node run.js \"\nconst browser = await chromium.launch({ headless: false });\nconst page = await browser.newPage();\nawait page.goto('http://localhost:3001');\nawait page.screenshot({ path: '/tmp/quick-screenshot.png', fullPage: true });\nconsole.log('Screenshot saved');\nawait browser.close();\n\"\n```\n\n**When to use inline vs files:**\n\n- **Inline**: Quick one-off tasks (screenshot, check if element exists, get page title)\n- **Files**: Complex tests, responsive design checks, anything user might want to re-run\n\n## Available Helpers\n\nOptional utility functions in `lib/helpers.js`:\n\n```javascript\nconst helpers = require('./lib/helpers');\n\n// Detect running dev servers (CRITICAL - use this first!)\nconst servers = await helpers.detectDevServers();\nconsole.log('Found servers:', servers);\n\n// Safe click with retry\nawait helpers.safeClick(page, 'button.submit', { retries: 3 });\n\n// Safe type with clear\nawait helpers.safeType(page, '#username', 'testuser');\n\n// Take timestamped screenshot\nawait helpers.takeScreenshot(page, 'test-result');\n\n// Handle cookie banners\nawait helpers.handleCookieBanner(page);\n\n// Extract table data\nconst data = await helpers.extractTableData(page, 'table.results');\n```\n\nSee `lib/helpers.js` for full list.\n\n## Custom HTTP Headers\n\nConfigure custom headers for all HTTP requests via environment variables. Useful for:\n\n- Identifying automated traffic to your backend\n- Getting LLM-optimized responses (e.g., plain text errors instead of styled HTML)\n- Adding authentication tokens globally\n\n### Configuration\n\n**Single header (common case):**\n\n```bash\nPW_HEADER_NAME=X-Automated-By PW_HEADER_VALUE=playwright-skill \\\n  cd $SKILL_DIR && node run.js /tmp/my-script.js\n```\n\n**Multiple headers (JSON format):**\n\n```bash\nPW_EXTRA_HEADERS='{\"X-Automated-By\":\"playwright-skill\",\"X-Debug\":\"true\"}' \\\n  cd $SKILL_DIR && node run.js /tmp/my-script.js\n```\n\n### How It Works\n\nHeaders are automatically applied when using `helpers.createContext()`:\n\n```javascript\nconst context = await helpers.createContext(browser);\nconst page = await context.newPage();\n// All requests from this page include your custom headers\n```\n\nFor scripts using raw Playwright API, use the injected `getContextOptionsWithHeaders()`:\n\n```javascript\nconst context = await browser.newContext(\n  getContextOptionsWithHeaders({ viewport: { width: 1920, height: 1080 } }),\n);\n```\n\n## Advanced Usage\n\nFor comprehensive Playwright API documentation, see [API_REFERENCE.md](API_REFERENCE.md):\n\n- Selectors & Locators best practices\n- Network interception & API mocking\n- Authentication & session management\n- Visual regression testing\n- Mobile device emulation\n- Performance testing\n- Debugging techniques\n- CI/CD integration\n\n## Tips\n\n- **CRITICAL: Detect servers FIRST** - Always run `detectDevServers()` before writing test code for localhost testing\n- **Custom headers** - Use `PW_HEADER_NAME`/`PW_HEADER_VALUE` env vars to identify automated traffic to your backend\n- **Use /tmp for test files** - Write to `/tmp/playwright-test-*.js`, never to skill directory or user's project\n- **Parameterize URLs** - Put detected/provided URL in a `TARGET_URL` constant at the top of every script\n- **DEFAULT: Visible browser** - Always use `headless: false` unless user explicitly asks for headless mode\n- **Headless mode** - Only use `headless: true` when user specifically requests \"headless\" or \"background\" execution\n- **Slow down:** Use `slowMo: 100` to make actions visible and easier to follow\n- **Wait strategies:** Use `waitForURL`, `waitForSelector`, `waitForLoadState` instead of fixed timeouts\n- **Error handling:** Always use try-catch for robust automation\n- **Console output:** Use `console.log()` to track progress and show what's happening\n\n## Troubleshooting\n\n**Playwright not installed:**\n\n```bash\ncd $SKILL_DIR && npm run setup\n```\n\n**Module not found:**\nEnsure running from skill directory via `run.js` wrapper\n\n**Browser doesn't open:**\nCheck `headless: false` and ensure display available\n\n**Element not found:**\nAdd wait: `await page.waitForSelector('.element', { timeout: 10000 })`\n\n## Example Usage\n\n```\nUser: \"Test if the marketing page looks good\"\n\nClaude: I'll test the marketing page across multiple viewports. Let me first detect running servers...\n[Runs: detectDevServers()]\n[Output: Found server on port 3001]\nI found your dev server running on http://localhost:3001\n\n[Writes custom automation script to /tmp/playwright-test-marketing.js with URL parameterized]\n[Runs: cd $SKILL_DIR && node run.js /tmp/playwright-test-marketing.js]\n[Shows results with screenshots from /tmp/]\n```\n\n```\nUser: \"Check if login redirects correctly\"\n\nClaude: I'll test the login flow. First, let me check for running servers...\n[Runs: detectDevServers()]\n[Output: Found servers on ports 3000 and 3001]\nI found 2 dev servers. Which one should I test?\n- http://localhost:3000\n- http://localhost:3001\n\nUser: \"Use 3001\"\n\n[Writes login automation to /tmp/playwright-test-login.js]\n[Runs: cd $SKILL_DIR && node run.js /tmp/playwright-test-login.js]\n[Reports: ✅ Login successful, redirected to /dashboard]\n```\n\n## Notes\n\n- Each automation is custom-written for your specific request\n- Not limited to pre-built scripts - any browser task possible\n- Auto-detects running dev servers to eliminate hardcoded URLs\n- Test scripts written to `/tmp` for automatic cleanup (no clutter)\n- Code executes reliably with proper module resolution via `run.js`\n- Progressive disclosure - API_REFERENCE.md loaded only when advanced features needed",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "render-deploy",
      "name": "render-deploy",
      "description": "Deploy applications to Render by analyzing codebases, generating render.yaml Blueprints, and providing Dashboard deeplinks. Use when the user wants to deploy, host, publish, or set up their application on Render's cloud platform.",
      "category": "cloud",
      "path": "skills/(cloud)/render-deploy/SKILL.md",
      "content": "# Deploy to Render\n\nRender supports **Git-backed** services and **prebuilt Docker image** services.\n\nThis skill covers **Git-backed** flows:\n\n1. **Blueprint Method** - Generate render.yaml for Infrastructure-as-Code deployments\n2. **Direct Creation** - Create services instantly via MCP tools\n\nBlueprints can also run a **prebuilt Docker image** by using `runtime: image`, but the `render.yaml` still must live in a Git repo.\n\nIf there is no Git remote, stop and ask the user to either:\n\n- Create/push a Git remote (can be minimal if only the Blueprint is needed), or\n- Use the Render Dashboard/API to deploy a prebuilt Docker image (MCP cannot create image-backed services).\n\n## Prerequisites\n\n- When sandboxing blocks the deployment network calls, rerun with `sandbox_permissions=require_escalated`.\n- The deployment might take a few minutes. Use appropriate timeout values.\n\n## When to Use This Skill\n\nActivate this skill when users want to:\n\n- Deploy an application to Render\n- Create a render.yaml Blueprint file\n- Set up Render deployment for their project\n- Host or publish their application on Render's cloud platform\n- Create databases, cron jobs, or other Render resources\n\n## Happy Path (New Users)\n\nUse this short prompt sequence before deep analysis to reduce friction:\n\n1. Ask whether they want to deploy from a Git repo or a prebuilt Docker image.\n2. Ask whether Render should provision everything the app needs (based on what seems likely from the user's description) or only the app while they bring their own infra. If dependencies are unclear, ask a short follow-up to confirm whether they need a database, workers, cron, or other services.\n\nThen proceed with the appropriate method below.\n\n## Choose Your Source Path\n\n**Git Repo Path:** Required for both Blueprint and Direct Creation. The repo must be pushed to GitHub, GitLab, or Bitbucket.\n\n**Prebuilt Docker Image Path:** Supported by Render via image-backed services. This is **not** supported by MCP; use the Dashboard/API. Ask for:\n\n- Image URL (registry + tag)\n- Registry auth (if private)\n- Service type (web/worker) and port\n\nIf the user chooses a Docker image, guide them to the Render Dashboard image deploy flow or ask them to add a Git remote (so you can use a Blueprint with `runtime: image`).\n\n## Choose Your Deployment Method (Git Repo)\n\nBoth methods require a Git repository pushed to GitHub, GitLab, or Bitbucket. (If using `runtime: image`, the repo can be minimal and only contain `render.yaml`.)\n\n| Method              | Best For                           | Pros                                                      |\n| ------------------- | ---------------------------------- | --------------------------------------------------------- |\n| **Blueprint**       | Multi-service apps, IaC workflows  | Version controlled, reproducible, supports complex setups |\n| **Direct Creation** | Single services, quick deployments | Instant creation, no render.yaml file needed              |\n\n### Method Selection Heuristic\n\nUse this decision rule by default unless the user requests a specific method. Analyze the codebase first; only ask if deployment intent is unclear (e.g., DB, workers, cron).\n\n**Use Direct Creation (MCP) when ALL are true:**\n\n- Single service (one web app or one static site)\n- No separate worker/cron services\n- No attached databases or Key Value\n- Simple env vars only (no shared env groups)\n  If this path fits and MCP isn't configured yet, stop and guide MCP setup before proceeding.\n\n**Use Blueprint when ANY are true:**\n\n- Multiple services (web + worker, API + frontend, etc.)\n- Databases, Redis/Key Value, or other datastores are required\n- Cron jobs, background workers, or private services\n- You want reproducible IaC or a render.yaml committed to the repo\n- Monorepo or multi-env setup that needs consistent configuration\n\nIf unsure, ask a quick clarifying question, but default to Blueprint for safety. For a single service, strongly prefer Direct Creation via MCP and guide MCP setup if needed.\n\n## Prerequisites Check\n\nWhen starting a deployment, verify these requirements in order:\n\n**1. Confirm Source Path (Git vs Docker)**\n\nIf using Git-based methods (Blueprint or Direct Creation), the repo must be pushed to GitHub/GitLab/Bitbucket. Blueprints that reference a prebuilt image still require a Git repo with `render.yaml`.\n\n```bash\ngit remote -v\n```\n\n- If no remote exists, stop and ask the user to create/push a remote **or** switch to Docker image deploy.\n\n**2. Check MCP Tools Availability (Preferred for Single-Service)**\n\nMCP tools provide the best experience. Check if available by attempting:\n\n```\nlist_services()\n```\n\nIf MCP tools are available, you can skip CLI installation for most operations.\n\n**3. Check Render CLI Installation (for Blueprint validation)**\n\n```bash\nrender --version\n```\n\nIf not installed, offer to install:\n\n- macOS: `brew install render`\n- Linux/macOS: `curl -fsSL https://raw.githubusercontent.com/render-oss/cli/main/bin/install.sh | sh`\n\n**4. MCP Setup (if MCP isn't configured)**\n\nIf `list_services()` fails because MCP isn't configured, ask whether they want to set up MCP (preferred) or continue with the CLI fallback. If they choose MCP, ask which AI tool they're using, then provide the matching instructions below. Always use their API key.\n\n### Cursor\n\nWalk the user through these steps:\n\n1. Get a Render API key:\n\n```\nhttps://dashboard.render.com/u/*/settings#api-keys\n```\n\n2. Add this to `~/.cursor/mcp.json` (replace `<YOUR_API_KEY>`):\n\n```json\n{\n  \"mcpServers\": {\n    \"render\": {\n      \"url\": \"https://mcp.render.com/mcp\",\n      \"headers\": {\n        \"Authorization\": \"Bearer <YOUR_API_KEY>\"\n      }\n    }\n  }\n}\n```\n\n3. Restart Cursor, then retry `list_services()`.\n\n### Claude Code\n\nWalk the user through these steps:\n\n1. Get a Render API key:\n\n```\nhttps://dashboard.render.com/u/*/settings#api-keys\n```\n\n2. Add the MCP server with Claude Code (replace `<YOUR_API_KEY>`):\n\n```bash\nclaude mcp add --transport http render https://mcp.render.com/mcp --header \"Authorization: Bearer <YOUR_API_KEY>\"\n```\n\n3. Restart Claude Code, then retry `list_services()`.\n\n### Other Tools\n\nIf the user is on another AI app, direct them to the Render MCP docs for that tool's setup steps and install method.\n\n### Workspace Selection\n\nAfter MCP is configured, have the user set the active Render workspace with a prompt like:\n\n```\nSet my Render workspace to [WORKSPACE_NAME]\n```\n\n**5. Check Authentication (CLI fallback only)**\n\nIf MCP isn't available, use the CLI instead and verify you can access your account:\n\n```bash\n# Check if user is logged in (use -o json for non-interactive mode)\nrender whoami -o json\n```\n\nIf `render whoami` fails or returns empty data, the CLI is not authenticated. The CLI won't always prompt automatically, so explicitly prompt the user to authenticate:\n\nIf neither is configured, ask user which method they prefer:\n\n- **API Key (CLI)**: `export RENDER_API_KEY=\"rnd_xxxxx\"` (Get from https://dashboard.render.com/u/*/settings#api-keys)\n- **Login**: `render login` (Opens browser for OAuth)\n\n**6. Check Workspace Context**\n\nVerify the active workspace:\n\n```\nget_selected_workspace()\n```\n\nOr via CLI:\n\n```bash\nrender workspace current -o json\n```\n\nTo list available workspaces:\n\n```\nlist_workspaces()\n```\n\nIf user needs to switch workspaces, they must do so via Dashboard or CLI (`render workspace set`).\n\nOnce prerequisites are met, proceed with deployment workflow.\n\n---\n\n# Method 1: Blueprint Deployment (Recommended for Complex Apps)\n\n## Blueprint Workflow\n\n### Step 1: Analyze Codebase\n\nAnalyze the codebase to determine framework/runtime, build and start commands, required env vars, datastores, and port binding. Use the detailed checklists in [references/codebase-analysis.md](references/codebase-analysis.md).\n\n### Step 2: Generate render.yaml\n\nCreate a `render.yaml` Blueprint file following the Blueprint specification.\n\nComplete specification: [references/blueprint-spec.md](references/blueprint-spec.md)\n\n**Key Points:**\n\n- Always use `plan: free` unless user specifies otherwise\n- Include ALL environment variables the app needs\n- Mark secrets with `sync: false` (user fills these in Dashboard)\n- Use appropriate service type: `web`, `worker`, `cron`, `static`, or `pserv`\n- Use appropriate runtime: [references/runtimes.md](references/runtimes.md)\n\n**Basic Structure:**\n\n```yaml\nservices:\n  - type: web\n    name: my-app\n    runtime: node\n    plan: free\n    buildCommand: npm ci\n    startCommand: npm start\n    envVars:\n      - key: DATABASE_URL\n        fromDatabase:\n          name: postgres\n          property: connectionString\n      - key: JWT_SECRET\n        sync: false # User fills in Dashboard\n\ndatabases:\n  - name: postgres\n    databaseName: myapp_db\n    plan: free\n```\n\n**Service Types:**\n\n- `web`: HTTP services, APIs, web applications (publicly accessible)\n- `worker`: Background job processors (not publicly accessible)\n- `cron`: Scheduled tasks that run on a cron schedule\n- `static`: Static sites (HTML/CSS/JS served via CDN)\n- `pserv`: Private services (internal only, within same account)\n\nService type details: [references/service-types.md](references/service-types.md)\nRuntime options: [references/runtimes.md](references/runtimes.md)\nTemplate examples: [assets/](assets/)\n\n### Step 2.5: Immediate Next Steps (Always Provide)\n\nAfter creating `render.yaml`, always give the user a short, explicit checklist and run validation immediately when the CLI is available:\n\n1. **Authenticate (CLI)**: run `render whoami -o json` (if not logged in, run `render login` or set `RENDER_API_KEY`)\n2. **Validate (recommended)**: run `render blueprints validate`\n   - If the CLI isn't installed, offer to install it and provide the command.\n3. **Commit + push**: `git add render.yaml && git commit -m \"Add Render deployment configuration\" && git push origin main`\n4. **Open Dashboard**: Use the Blueprint deeplink and complete Git OAuth if prompted\n5. **Fill secrets**: Set env vars marked `sync: false`\n6. **Deploy**: Click \"Apply\" and monitor the deploy\n\n### Step 3: Validate Configuration\n\nValidate the render.yaml file to catch errors before deployment. If the CLI is installed, run the commands directly; only prompt the user if the CLI is missing:\n\n```bash\nrender whoami -o json  # Ensure CLI is authenticated (won't always prompt)\nrender blueprints validate\n```\n\nFix any validation errors before proceeding. Common issues:\n\n- Missing required fields (`name`, `type`, `runtime`)\n- Invalid runtime values\n- Incorrect YAML syntax\n- Invalid environment variable references\n\nConfiguration guide: [references/configuration-guide.md](references/configuration-guide.md)\n\n### Step 4: Commit and Push\n\n**IMPORTANT:** You must merge the `render.yaml` file into your repository before deploying.\n\nEnsure the `render.yaml` file is committed and pushed to your Git remote:\n\n```bash\ngit add render.yaml\ngit commit -m \"Add Render deployment configuration\"\ngit push origin main\n```\n\nIf there is no Git remote yet, stop here and guide the user to create a GitHub/GitLab/Bitbucket repo, add it as `origin`, and push before continuing.\n\n**Why this matters:** The Dashboard deeplink will read the render.yaml from your repository. If the file isn't merged and pushed, Render won't find the configuration and deployment will fail.\n\nVerify the file is in your remote repository before proceeding to the next step.\n\n### Step 5: Generate Deeplink\n\nGet the Git repository URL:\n\n```bash\ngit remote get-url origin\n```\n\nThis will return a URL from your Git provider. **If the URL is SSH format, convert it to HTTPS:**\n\n| SSH Format                        | HTTPS Format                      |\n| --------------------------------- | --------------------------------- |\n| `git@github.com:user/repo.git`    | `https://github.com/user/repo`    |\n| `git@gitlab.com:user/repo.git`    | `https://gitlab.com/user/repo`    |\n| `git@bitbucket.org:user/repo.git` | `https://bitbucket.org/user/repo` |\n\n**Conversion pattern:** Replace `git@<host>:` with `https://<host>/` and remove `.git` suffix.\n\nFormat the Dashboard deeplink using the HTTPS repository URL:\n\n```\nhttps://dashboard.render.com/blueprint/new?repo=<REPOSITORY_URL>\n```\n\nExample:\n\n```\nhttps://dashboard.render.com/blueprint/new?repo=https://github.com/username/repo-name\n```\n\n### Step 6: Guide User\n\n**CRITICAL:** Ensure the user has merged and pushed the render.yaml file to their repository before clicking the deeplink. If the file isn't in the repository, Render cannot read the Blueprint configuration and deployment will fail.\n\nProvide the deeplink to the user with these instructions:\n\n1. **Verify render.yaml is merged** - Confirm the file exists in your repository on GitHub/GitLab/Bitbucket\n2. Click the deeplink to open Render Dashboard\n3. Complete Git provider OAuth if prompted\n4. Name the Blueprint (or use default from render.yaml)\n5. Fill in secret environment variables (marked with `sync: false`)\n6. Review services and databases configuration\n7. Click \"Apply\" to deploy\n\nThe deployment will begin automatically. Users can monitor progress in the Render Dashboard.\n\n### Step 7: Verify Deployment\n\nAfter the user deploys via Dashboard, verify everything is working.\n\n**Check deployment status via MCP:**\n\n```\nlist_deploys(serviceId: \"<service-id>\", limit: 1)\n```\n\nLook for `status: \"live\"` to confirm successful deployment.\n\n**Check for runtime errors (wait 2-3 minutes after deploy):**\n\n```\nlist_logs(resource: [\"<service-id>\"], level: [\"error\"], limit: 20)\n```\n\n**Check service health metrics:**\n\n```\nget_metrics(\n  resourceId: \"<service-id>\",\n  metricTypes: [\"http_request_count\", \"cpu_usage\", \"memory_usage\"]\n)\n```\n\nIf errors are found, proceed to the **Post-deploy verification and basic triage** section below.\n\n---\n\n# Method 2: Direct Service Creation (Quick Single-Service Deployments)\n\nFor simple deployments without Infrastructure-as-Code, create services directly via MCP tools.\n\n## When to Use Direct Creation\n\n- Single web service or static site\n- Quick prototypes or demos\n- When you don't need a render.yaml file in your repo\n- Adding databases or cron jobs to existing projects\n\n## Prerequisites for Direct Creation\n\n**Repository must be pushed to a Git provider.** Render clones your repository to build and deploy services.\n\n```bash\ngit remote -v  # Verify remote exists\ngit push origin main  # Ensure code is pushed\n```\n\nSupported providers: GitHub, GitLab, Bitbucket\n\nIf no remote exists, stop and ask the user to create/push a remote or switch to Docker image deploy.\n\n**Note:** MCP does not support creating image-backed services. Use the Dashboard/API for prebuilt Docker image deploys.\n\n## Direct Creation Workflow\n\nUse the concise steps below, and refer to [references/direct-creation.md](references/direct-creation.md) for full MCP command examples and follow-on configuration.\n\n### Step 1: Analyze Codebase\n\nUse [references/codebase-analysis.md](references/codebase-analysis.md) to determine runtime, build/start commands, env vars, and datastores.\n\n### Step 2: Create Resources via MCP\n\nCreate the service (web or static) and any required databases or key-value stores. See [references/direct-creation.md](references/direct-creation.md).\n\nIf MCP returns an error about missing Git credentials or repo access, stop and guide the user to connect their Git provider in the Render Dashboard, then retry.\n\n### Step 3: Configure Environment Variables\n\nAdd required env vars via MCP after creation. See [references/direct-creation.md](references/direct-creation.md).\n\nRemind the user that secrets can be set in the Dashboard if they prefer not to pass them via MCP.\n\n### Step 4: Verify Deployment\n\nCheck deploy status, logs, and metrics. See [references/direct-creation.md](references/direct-creation.md).\n\n---\n\nFor service discovery, configuration details, quick commands, and common issues, see [references/deployment-details.md](references/deployment-details.md).\n\n---\n\n# Post-deploy verification and basic triage (All Methods)\n\nKeep this short and repeatable. If any check fails, fix it before redeploying.\n\n1. Confirm the latest deploy is `live` and serving traffic\n2. Hit the health endpoint (or root) and verify a 200 response\n3. Scan recent error logs for a clear failure signature\n4. Verify required env vars and port binding (`0.0.0.0:$PORT`)\n\nDetailed checklist and commands: [references/post-deploy-checks.md](references/post-deploy-checks.md)\n\nIf the service fails to start or health checks time out, use the basic triage guide:\n[references/troubleshooting-basics.md](references/troubleshooting-basics.md)\n\n## Troubleshooting\n\n### Escalated Network Access\n\nIf deployment fails due to network issues (timeouts, DNS errors, connection resets), rerun the deploy with escalated permissions (use `sandbox_permissions=require_escalated`). The deploy requires escalated network access when sandbox networking blocks outbound requests.\n\nExample guidance to the user:\n\n```\nThe deploy needs escalated network access to deploy to Render. I can rerun the command with escalated permissions—want me to proceed?\n```\n\nOptional: If you need deeper diagnostics (metrics/DB checks/error catalog), suggest installing the\n`render-debug` skill. It is not required for the core deploy flow.",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "blueprint-spec.md",
          "codebase-analysis.md",
          "configuration-guide.md",
          "deployment-details.md",
          "direct-creation.md",
          "error-patterns.md",
          "post-deploy-checks.md",
          "runtimes.md",
          "service-types.md",
          "troubleshooting-basics.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "run-nx-generator",
      "name": "run-nx-generator",
      "description": "Run Nx generators with prioritization for workspace-plugin generators. Use this when generating code, scaffolding new features, or automating repetitive tasks in the monorepo.",
      "category": "tooling",
      "path": "skills/(tooling)/run-nx-generator/SKILL.md",
      "content": "# Run Nx Generator\n\nThis skill helps you execute Nx generators efficiently, with special focus on workspace-plugin generators from your internal tooling.\n\n## Generator Priority List\n\nUse the `mcp__nx-mcp__nx_generator_schema` tool to get more information about how to use the generator\n\nChoose which generators to run in this priority order:\n\n### 🔥 Workspace-Plugin Generators (High Priority)\n\nThese are your custom internal tools in `tools/workspace-plugin/`\n\n### 📦 Core Nx Generators (Standard)\n\nOnly use these if workspace-plugin generators don't fit:\n\n- `nx generate @nx/devkit:...` - DevKit utilities\n- `nx generate @nx/node:...` - Node.js libraries\n- `nx generate @nx/react:...` - React components and apps\n- Framework-specific generators\n\n## How to Run Generators\n\n1. **List available generators**:\n\n2. **Get generator schema** (to see available options):\n   Use the `mcp__nx-mcp__nx_generator_schema` tool to get more information about how to use the generator\n\n3. **Run the generator**:\n\n   ```bash\n   nx generate [generator-path] [options]\n   ```\n\n4. **Verify the changes**:\n   - Review generated files\n   - Run tests: `nx affected -t test`\n   - Format code: `npx prettier --write [files]`\n\n## Best Practices\n\n- ✅ Always check workspace-plugin first - it has your custom solutions\n- ✅ Use `--dry-run` flag to preview changes before applying\n- ✅ Format generated code immediately with Prettier\n- ✅ Test affected projects after generation\n- ✅ Commit generator changes separately from manual edits\n\n## Examples\n\n### Bumping Maven Version\n\nWhen updating the Maven plugin version, use the workspace-plugin generator:\n\n```bash\nnx generate @nx/workspace-plugin:bump-maven-version \\\n  --newVersion 0.0.10 \\\n  --nxVersion 22.1.0-beta.7\n```\n\nThis automates all the version bumping instead of manual file edits.\n\n### Creating a New Plugin\n\nFor creating a new create-nodes plugin:\n\n```bash\nnx generate @nx/workspace-plugin:create-nodes-plugin \\\n  --name my-custom-plugin\n```\n\n## When to Use This Skill\n\nUse this skill when you need to:\n\n- Generate new code or projects\n- Scaffold new features or libraries\n- Automate repetitive setup tasks\n- Update internal tools and configurations\n- Create migrations or version updates",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "security-best-practices",
      "name": "security-best-practices",
      "description": "Perform language and framework specific security best-practice reviews and suggest improvements. Trigger only when the user explicitly requests security best practices guidance, a security review/report, or secure-by-default coding help. Trigger only for supported languages (python, javascript/typescript, go). Do not trigger for general code review, debugging, or non-security tasks.",
      "category": "security",
      "path": "skills/(security)/security-best-practices/SKILL.md",
      "content": "# Security Best Practices\n\n## Overview\n\nThis skill provides a description of how to identify the language and frameworks used by the current context, and then to load information from this skill's references directory about the security best practices for this language and or frameworks.\n\nThis information, if present, can be used to write new secure by default code, or to passively detect major issues within existing code, or (if requested by the user) provide a vulnerability report and suggest fixes.\n\n## Workflow\n\nThe initial step for this skill is to identify ALL languages and ALL frameworks which you are being asked to use or already exist in the scope of the project you are working in. Focus on the primary core frameworks. Often you will want to identify both frontend and backend languages and frameworks.\n\nThen check this skill's references directory to see if there are any relevant documentation for the language and or frameworks. Make sure you read ALL reference files which relate to the specific framework or language. The format of the filenames is `<language>-<framework>-<stack>-security.md`. You should also check if there is a `<language>-general-<stack>-security.md` which is agnostic to the framework you may be using.\n\nIf working on a web application which includes a frontend and a backend, make sure you have checked for reference documents for BOTH the frontend and backend!\n\nIf you are asked to make a web app which will include both a frontend and backend, but the frontend framework is not specified, also check out `javascript-general-web-frontend-security.md`. It is important that you understand how to secure both the frontend and backend.\n\nIf no relevant information is available in the skill's references directory, think a little bit about what you know about the language, the framework, and all well known security best practices for it. If you are unsure you can try to search online for documentation on security best practices.\n\nFrom there it can operate in a few ways.\n\n1. The primary mode is to just use the information to write secure by default code from this point forward. This is useful for starting a new project or when writing new code.\n\n2. The secondary mode is to passively detect vulnerabilities while working in the project and writing code for the user. Critical or very important vulnerabilities or major issues going against security guidance can be flagged and the user can be told about them. This passive mode should focus on the largest impact vulnerabilities and secure defaults.\n\n3. The user can ask for a security report or to improve the security of the codebase. In this case a full report should be produced describe anyways the project fails to follow security best practices guidance. The report should be prioritized and have clear sections of severity and urgency. Then offer to start working on fixes for these issues. See #fixes below.\n\n## Workflow Decision Tree\n\n- If the language/framework is unclear, inspect the repo to determine it and list your evidence.\n- If matching guidance exists in `references/`, load only the relevant files and follow their instructions.\n- If no matching guidance exists, consider if you know any well known security best practices for the chosen language and or frameworks, but if asked to generate a report, let the user know that concrete guidance is not available (you can still generate the report or detect for sure critical vulnerabilities)\n\n# Overrides\n\nWhile these references contain the security best practices for languages and frameworks, customers may have cases where they need to bypass or override these practices. Pay attention to specific rules and instructions in the project's documentation and prompt files which may require you to override certain best practices. When overriding a best practice, you MAY report it to the user, but do not fight with them. If a security best practice needs to be bypassed / ignored for some project specific reason, you can also suggest to add documentation about this to the project so it is clear why the best practice is not being followed and to follow that bypass in the future.\n\n# Report Format\n\nWhen producing a report, you should write the report as a markdown file in `security_best_practices_report.md` or some other location if provided by the user. You can ask the user where they would like the report to be written to.\n\nThe report should have a short executive summary at the top.\n\nThe report should be clearly delineated into multiple sections based on severity of the vulnerability. The report should focus on the most critical findings as these have the highest impact for the user. All findings should be noted with an numeric ID to make them easier to reference.\n\nFor critical findings include a one sentence impact statement.\n\nOnce the report is written, also report it to the user directly, although you may be less verbose. You can offer to explain any of the findings or the reasons behind the security best practices guidance if the user wants more info on any findings.\n\nImportant: When referencing code in the report, make sure to find and include line numbers for the code you are referencing.\n\nAfter you write the report file, summarize the findings to the user.\n\nAlso tell the user where the final report was written to\n\n# Fixes\n\nIf you produced a report, let the user read the report and ask to begin performing fixes.\n\nIf you passively found a critical finding, notify the user and ask if they would like you to fix this finding.\n\nWhen producing fixes, focus on fixing a single finding at a time. The fixes should have concise clear comments explaining that the new code is based on the specific security best practice, and perhaps a very short reason why it would be dangerous to not do it in this way.\n\nAlways consider if the changes you want to make will impact the functionality of the user's code. Consider if the changes may cause regressions with how the project works currently. It is often the case that insecure code is relied on for other reasons (and this is why insecure code lives on for so long). Avoid breaking the user's project as this may make them not want to apply security fixes in the future. It is better to write a well thought out, well informed by the rest of the project, fix, then a quick slapdash change.\n\nAlways follow any normal change or commit flow the user has configured. If making git commits, provide clear commit messages explaining this is to align with security best practices. Try to avoid bunching a number of unrelated findings into a single commit.\n\nAlways follow any normal testing flows the user has configured (if any) to confirm that your changes are not introducing regressions. Consider the second order impacts the changes may have and inform the user before making them if there are any.\n\n# General Security Advice\n\nBelow is a few bits of secure coding advice that applies to almost any language or framework.\n\n### Avoid Using Incrementing IDs for Public IDs of Resources\n\nWhen assigning an ID for some resource, which will then be used by exposed to the internet, avoid using small auto-incrementing IDs. Use longer, random UUID4 or random hex string instead. This will prevent users from learning the quantity of a resource and being able to guess resource IDs.\n\n### A note on TLS\n\nWhile TLS is important for production deployments, most development work will be with TLS disabled or provided by some out-of-scope TLS proxy. Due to this, be very careful about not reporting lack of TLS as a security issue. Also be very careful around use of \"secure\" cookies. They should only be set if the application will actually be over TLS. If they are set on non-TLS applications (such as when deployed for local dev or testing), it will break the application. You can provide a env or other flag to override setting secure as a way to keep it off until on a TLS production deployment. Additionally avoid recommending HSTS. It is dangerous to use without full understanding of the lasting impacts (can cause major outages and user lockout) and it is not generally recommended for most projects in review.",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "golang-general-backend-security.md",
          "javascript-express-web-server-security.md",
          "javascript-general-web-frontend-security.md",
          "javascript-jquery-web-frontend-security.md",
          "javascript-typescript-nextjs-web-server-security.md",
          "javascript-typescript-react-web-frontend-security.md",
          "javascript-typescript-vue-web-frontend-security.md",
          "python-django-web-server-security.md",
          "python-fastapi-web-server-security.md",
          "python-flask-web-server-security.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "security-ownership-map",
      "name": "security-ownership-map",
      "description": "'Analyze git repositories to build a security ownership topology (people-to-file), compute bus factor and sensitive-code ownership, and export CSV/JSON for graph databases and visualization. Trigger only when the user explicitly wants a security-oriented ownership or bus-factor analysis grounded in git history (for example: orphaned sensitive code, security maintainers, CODEOWNERS reality checks for risk, sensitive hotspots, or ownership clusters). Do not trigger for general maintainer lists or non-security ownership questions.'",
      "category": "security",
      "path": "skills/(security)/security-ownership-map/SKILL.md",
      "content": "# Security Ownership Map\n\n## Overview\n\nBuild a bipartite graph of people and files from git history, then compute ownership risk and export graph artifacts for Neo4j/Gephi. Also build a file co-change graph (Jaccard similarity on shared commits) to cluster files by how they move together while ignoring large, noisy commits.\n\n## Requirements\n\n- Python 3\n- `networkx` (required; community detection is enabled by default)\n\nInstall with:\n\n```bash\npip install networkx\n```\n\n## Workflow\n\n1. Scope the repo and time window (optional `--since/--until`).\n2. Decide sensitivity rules (use defaults or provide a CSV config).\n3. Build the ownership map with `scripts/run_ownership_map.py` (co-change graph is on by default; use `--cochange-max-files` to ignore supernode commits).\n4. Communities are computed by default; graphml output is optional (`--graphml`).\n5. Query the outputs with `scripts/query_ownership.py` for bounded JSON slices.\n6. Persist and visualize (see `references/neo4j-import.md`).\n\nBy default, the co-change graph ignores common “glue” files (lockfiles, `.github/*`, editor config) so clusters reflect actual code movement instead of shared infra edits. Override with `--cochange-exclude` or `--no-default-cochange-excludes`. Dependabot commits are excluded by default; override with `--no-default-author-excludes` or add patterns via `--author-exclude-regex`.\n\nIf you want to exclude Linux build glue like `Kbuild` from co-change clustering, pass:\n\n```bash\npython skills/skills/security-ownership-map/scripts/run_ownership_map.py \\\n  --repo /path/to/linux \\\n  --out ownership-map-out \\\n  --cochange-exclude \"**/Kbuild\"\n```\n\n## Quick start\n\nRun from the repo root:\n\n```bash\npython skills/skills/security-ownership-map/scripts/run_ownership_map.py \\\n  --repo . \\\n  --out ownership-map-out \\\n  --since \"12 months ago\" \\\n  --emit-commits\n```\n\nDefaults: author identity, author date, and merge commits excluded. Use `--identity committer`, `--date-field committer`, or `--include-merges` if needed.\n\nExample (override co-change excludes):\n\n```bash\npython skills/skills/security-ownership-map/scripts/run_ownership_map.py \\\n  --repo . \\\n  --out ownership-map-out \\\n  --cochange-exclude \"**/Cargo.lock\" \\\n  --cochange-exclude \"**/.github/**\" \\\n  --no-default-cochange-excludes\n```\n\nCommunities are computed by default. To disable:\n\n```bash\npython skills/skills/security-ownership-map/scripts/run_ownership_map.py \\\n  --repo . \\\n  --out ownership-map-out \\\n  --no-communities\n```\n\n## Sensitivity rules\n\nBy default, the script flags common auth/crypto/secret paths. Override by providing a CSV file:\n\n```\n# pattern,tag,weight\n**/auth/**,auth,1.0\n**/crypto/**,crypto,1.0\n**/*.pem,secrets,1.0\n```\n\nUse it with `--sensitive-config path/to/sensitive.csv`.\n\n## Output artifacts\n\n`ownership-map-out/` contains:\n\n- `people.csv` (nodes: people)\n- `files.csv` (nodes: files)\n- `edges.csv` (edges: touches)\n- `cochange_edges.csv` (file-to-file co-change edges with Jaccard weight; omitted with `--no-cochange`)\n- `summary.json` (security ownership findings)\n- `commits.jsonl` (optional, if `--emit-commits`)\n- `communities.json` (computed by default from co-change edges when available; includes `maintainers` per community; disable with `--no-communities`)\n- `cochange.graph.json` (NetworkX node-link JSON with `community_id` + `community_maintainers`; falls back to `ownership.graph.json` if no co-change edges)\n- `ownership.graphml` / `cochange.graphml` (optional, if `--graphml`)\n\n`people.csv` includes timezone detection based on author commit offsets: `primary_tz_offset`, `primary_tz_minutes`, and `timezone_offsets`.\n\n## LLM query helper\n\nUse `scripts/query_ownership.py` to return small, JSON-bounded slices without loading the full graph into context.\n\nExamples:\n\n```bash\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out people --limit 10\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out files --tag auth --bus-factor-max 1\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out person --person alice@corp --limit 10\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out file --file crypto/tls\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out cochange --file crypto/tls --limit 10\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out summary --section orphaned_sensitive_code\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out community --id 3\n```\n\nUse `--community-top-owners 5` (default) to control how many maintainers are stored per community.\n\n## Basic security queries\n\nRun these to answer common security ownership questions with bounded output:\n\n```bash\n# Orphaned sensitive code (stale + low bus factor)\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out summary --section orphaned_sensitive_code\n\n# Hidden owners for sensitive tags\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out summary --section hidden_owners\n\n# Sensitive hotspots with low bus factor\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out summary --section bus_factor_hotspots\n\n# Auth/crypto files with bus factor <= 1\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out files --tag auth --bus-factor-max 1\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out files --tag crypto --bus-factor-max 1\n\n# Who is touching sensitive code the most\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out people --sort sensitive_touches --limit 10\n\n# Co-change neighbors (cluster hints for ownership drift)\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out cochange --file path/to/file --min-jaccard 0.05 --limit 20\n\n# Community maintainers (for a cluster)\npython skills/skills/security-ownership-map/scripts/query_ownership.py --data-dir ownership-map-out community --id 3\n\n# Monthly maintainers for the community containing a file\npython skills/skills/security-ownership-map/scripts/community_maintainers.py \\\n  --data-dir ownership-map-out \\\n  --file network/card.c \\\n  --since 2025-01-01 \\\n  --top 5\n\n# Quarterly buckets instead of monthly\npython skills/skills/security-ownership-map/scripts/community_maintainers.py \\\n  --data-dir ownership-map-out \\\n  --file network/card.c \\\n  --since 2025-01-01 \\\n  --bucket quarter \\\n  --top 5\n```\n\nNotes:\n\n- Touches default to one authored commit (not per-file). Use `--touch-mode file` to count per-file touches.\n- Use `--window-days 90` or `--weight recency --half-life-days 180` to smooth churn.\n- Filter bots with `--ignore-author-regex '(bot|dependabot)'`.\n- Use `--min-share 0.1` to show stable maintainers only.\n- Use `--bucket quarter` for calendar quarter groupings.\n- Use `--identity committer` or `--date-field committer` to switch from author attribution.\n- Use `--include-merges` to include merge commits (excluded by default).\n\n### Summary format (default)\n\nUse this structure, add fields if needed:\n\n```json\n{\n  \"orphaned_sensitive_code\": [\n    {\n      \"path\": \"crypto/tls/handshake.rs\",\n      \"last_security_touch\": \"2023-03-12T18:10:04+00:00\",\n      \"bus_factor\": 1\n    }\n  ],\n  \"hidden_owners\": [\n    {\n      \"person\": \"alice@corp\",\n      \"controls\": \"63% of auth code\"\n    }\n  ]\n}\n```\n\n## Graph persistence\n\nUse `references/neo4j-import.md` when you need to load the CSVs into Neo4j. It includes constraints, import Cypher, and visualization tips.\n\n## Notes\n\n- `bus_factor_hotspots` in `summary.json` lists sensitive files with low bus factor; `orphaned_sensitive_code` is the stale subset.\n- If `git log` is too large, narrow with `--since` or `--until`.\n- Compare `summary.json` against CODEOWNERS to highlight ownership drift.",
      "metadata": {
        "hasScripts": true,
        "hasReferences": true,
        "referenceFiles": [
          "neo4j-import.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "security-threat-model",
      "name": "security-threat-model",
      "description": "Repository-grounded threat modeling that enumerates trust boundaries, assets, attacker capabilities, abuse paths, and mitigations, and writes a concise Markdown threat model. Trigger only when the user explicitly asks to threat model a codebase or path, enumerate threats/abuse paths, or perform AppSec threat modeling. Do not trigger for general architecture summaries, code review, or non-security design work.",
      "category": "security",
      "path": "skills/(security)/security-threat-model/SKILL.md",
      "content": "# Threat Model Source Code Repo\n\nDeliver an actionable AppSec-grade threat model that is specific to the repository or a project path, not a generic checklist. Anchor every architectural claim to evidence in the repo and keep assumptions explicit. Prioritizing realistic attacker goals and concrete impacts over generic checklists.\n\n## Quick start\n\n1. Collect (or infer) inputs:\n\n- Repo root path and any in-scope paths.\n- Intended usage, deployment model, internet exposure, and auth expectations (if known).\n- Any existing repository summary or architecture spec.\n- Use prompts in `references/prompt-template.md` to generate a repository summary.\n- Follow the required output contract in `references/prompt-template.md`. Use it verbatim when possible.\n\n## Workflow\n\n### 1) Scope and extract the system model\n\n- Identify primary components, data stores, and external integrations from the repo summary.\n- Identify how the system runs (server, CLI, library, worker) and its entrypoints.\n- Separate runtime behavior from CI/build/dev tooling and from tests/examples.\n- Map the in-scope locations to those components and exclude out-of-scope items explicitly.\n- Do not claim components, flows, or controls without evidence.\n\n### 2) Derive boundaries, assets, and entry points\n\n- Enumerate trust boundaries as concrete edges between components, noting protocol, auth, encryption, validation, and rate limiting.\n- List assets that drive risk (data, credentials, models, config, compute resources, audit logs).\n- Identify entry points (endpoints, upload surfaces, parsers/decoders, job triggers, admin tooling, logging/error sinks).\n\n### 3) Calibrate assets and attacker capabilities\n\n- List the assets that drive risk (credentials, PII, integrity-critical state, availability-critical components, build artifacts).\n- Describe realistic attacker capabilities based on exposure and intended usage.\n- Explicitly note non-capabilities to avoid inflated severity.\n\n### 4) Enumerate threats as abuse paths\n\n- Prefer attacker goals that map to assets and boundaries (exfiltration, privilege escalation, integrity compromise, denial of service).\n- Classify each threat and tie it to impacted assets.\n- Keep the number of threats small but high quality.\n\n### 5) Prioritize with explicit likelihood and impact reasoning\n\n- Use qualitative likelihood and impact (low/medium/high) with short justifications.\n- Set overall priority (critical/high/medium/low) using likelihood x impact, adjusted for existing controls.\n- State which assumptions most influence the ranking.\n\n### 6) Validate service context and assumptions with the user\n\n- Summarize key assumptions that materially affect threat ranking or scope, then ask the user to confirm or correct them.\n- Ask 1–3 targeted questions to resolve missing context (service owner and environment, scale/users, deployment model, authn/authz, internet exposure, data sensitivity, multi-tenancy).\n- Pause and wait for user feedback before producing the final report.\n- If the user declines or can’t answer, state which assumptions remain and how they influence priority.\n\n### 7) Recommend mitigations and focus paths\n\n- Distinguish existing mitigations (with evidence) from recommended mitigations.\n- Tie mitigations to concrete locations (component, boundary, or entry point) and control types (authZ checks, input validation, schema enforcement, sandboxing, rate limits, secrets isolation, audit logging).\n- Prefer specific implementation hints over generic advice (e.g., \"enforce schema at gateway for upload payloads\" vs \"validate inputs\").\n- Base recommendations on validated user context; if assumptions remain unresolved, mark recommendations as conditional.\n\n### 8) Run a quality check before finalizing\n\n- Confirm all discovered entrypoints are covered.\n- Confirm each trust boundary is represented in threats.\n- Confirm runtime vs CI/dev separation.\n- Confirm user clarifications (or explicit non-responses) are reflected.\n- Confirm assumptions and open questions are explicit.\n- Confirm that the format of the report matches closely the required output format defined in prompt template: `references/prompt-template.md`\n- Write the final Markdown to a file named `<repo-or-dir-name>-threat-model.md` (use the basename of the repo root, or the in-scope directory if you were asked to model a subpath).\n\n## Risk prioritization guidance (illustrative, not exhaustive)\n\n- High: pre-auth RCE, auth bypass, cross-tenant access, sensitive data exfiltration, key or token theft, model or config integrity compromise, sandbox escape.\n- Medium: targeted DoS of critical components, partial data exposure, rate-limit bypass with measurable impact, log/metrics poisoning that affects detection.\n- Low: low-sensitivity info leaks, noisy DoS with easy mitigation, issues requiring unlikely preconditions.\n\n## References\n\n- Output contract and full prompt template: `references/prompt-template.md`\n- Optional controls/asset list: `references/security-controls-and-assets.md`\n\nOnly load the reference files you need. Keep the final result concise, grounded, and reviewable.",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "prompt-template.md",
          "security-controls-and-assets.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "sentry",
      "name": "sentry",
      "description": "Use when the user asks to inspect Sentry issues or events, summarize recent production errors, or pull basic Sentry health data via the Sentry API; perform read-only queries with the bundled script and require `SENTRY_AUTH_TOKEN`.",
      "category": "monitoring",
      "path": "skills/(monitoring)/sentry/SKILL.md",
      "content": "# Sentry (Read-only Observability)\n\n## Quick start\n\n- If not already authenticated, ask the user to provide a valid `SENTRY_AUTH_TOKEN` (read-only scopes such as `project:read`, `event:read`) or to log in and create one before running commands.\n- Set `SENTRY_AUTH_TOKEN` as an env var.\n- Optional defaults: `SENTRY_ORG`, `SENTRY_PROJECT`, `SENTRY_BASE_URL`.\n- Defaults: org/project `{your-org}`/`{your-project}`, time range `24h`, environment `prod`, limit 20 (max 50).\n- Always call the Sentry API (no heuristics, no caching).\n\nIf the token is missing, give the user these steps:\n\n1. Create a Sentry auth token: <https://sentry.io/settings/account/api/auth-tokens/>\n2. Create a token with read-only scopes such as `project:read`, `event:read`, and `org:read`.\n3. Set `SENTRY_AUTH_TOKEN` as an environment variable in their system.\n4. Offer to guide them through setting the environment variable for their OS/shell if needed.\n\n- Never ask the user to paste the full token in chat. Ask them to set it locally and confirm when ready.\n\n## Core tasks (use bundled script)\n\nUse `scripts/sentry_api.py` for deterministic API calls. It handles pagination and retries once on transient errors.\n\n## Skill path (set once)\n\n```bash\nexport AGENT_SKILLS_HOME=\"${AGENT_SKILLS_HOME:-$HOME/.agent-skills}\"\nexport SENTRY_API=\"$AGENT_SKILLS_HOME/skills/sentry/scripts/sentry_api.py\"\n```\n\nUser-scoped skills install under `$AGENT_SKILLS_HOME/skills` (default: `~/.agent-skills/skills`).\n\n### 1) List issues (ordered by most recent)\n\n```bash\npython3 \"$SENTRY_API\" \\\n  list-issues \\\n  --org {your-org} \\\n  --project {your-project} \\\n  --environment prod \\\n  --time-range 24h \\\n  --limit 20 \\\n  --query \"is:unresolved\"\n```\n\n### 2) Resolve an issue short ID to issue ID\n\n```bash\npython3 \"$SENTRY_API\" \\\n  list-issues \\\n  --org {your-org} \\\n  --project {your-project} \\\n  --query \"ABC-123\" \\\n  --limit 1\n```\n\nUse the returned `id` for issue detail or events.\n\n### 3) Issue detail\n\n```bash\npython3 \"$SENTRY_API\" \\\n  issue-detail \\\n  1234567890\n```\n\n### 4) Issue events\n\n```bash\npython3 \"$SENTRY_API\" \\\n  issue-events \\\n  1234567890 \\\n  --limit 20\n```\n\n### 5) Event detail (no stack traces by default)\n\n```bash\npython3 \"$SENTRY_API\" \\\n  event-detail \\\n  --org {your-org} \\\n  --project {your-project} \\\n  abcdef1234567890\n```\n\n## API requirements\n\nAlways use these endpoints (GET only):\n\n- List issues: `/api/0/projects/{org_slug}/{project_slug}/issues/`\n- Issue detail: `/api/0/issues/{issue_id}/`\n- Events for issue: `/api/0/issues/{issue_id}/events/`\n- Event detail: `/api/0/projects/{org_slug}/{project_slug}/events/{event_id}/`\n\n## Inputs and defaults\n\n- `org_slug`, `project_slug`: default to `{your-org}`/`{your-project}` (avoid non-prod orgs).\n- `time_range`: default `24h` (pass as `statsPeriod`).\n- `environment`: default `prod`.\n- `limit`: default 20, max 50 (paginate until limit reached).\n- `search_query`: optional `query` parameter.\n- `issue_short_id`: resolve via list-issues query first.\n\n## Output formatting rules\n\n- Issue list: show title, short_id, status, first_seen, last_seen, count, environments, top_tags; order by most recent.\n- Event detail: include culprit, timestamp, environment, release, url.\n- If no results, state explicitly.\n- Redact PII in output (emails, IPs). Do not print raw stack traces.\n- Never echo auth tokens.\n\n## Golden test inputs\n\n- Org: `{your-org}`\n- Project: `{your-project}`\n- Issue short ID: `{ABC-123}`\n\nExample prompt: “List the top 10 open issues for prod in the last 24h.”\nExpected: ordered list with titles, short IDs, counts, last seen.",
      "metadata": {
        "hasScripts": true,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "seo",
      "name": "seo",
      "description": "Optimize for search engine visibility and ranking. Use when asked to \"improve SEO\", \"optimize for search\", \"fix meta tags\", \"add structured data\", \"sitemap optimization\", or \"search engine optimization\".",
      "category": "quality",
      "path": "skills/(quality)/seo/SKILL.md",
      "content": "# SEO optimization\n\nSearch engine optimization based on Lighthouse SEO audits and Google Search guidelines. Focus on technical SEO, on-page optimization, and structured data.\n\n## SEO fundamentals\n\nSearch ranking factors (approximate influence):\n\n| Factor                            | Influence | This Skill                                         |\n| --------------------------------- | --------- | -------------------------------------------------- |\n| Content quality & relevance       | ~40%      | Partial (structure)                                |\n| Backlinks & authority             | ~25%      | ✗                                                  |\n| Technical SEO                     | ~15%      | ✓                                                  |\n| Page experience (Core Web Vitals) | ~10%      | See [Core Web Vitals](../core-web-vitals/SKILL.md) |\n| On-page SEO                       | ~10%      | ✓                                                  |\n\n---\n\n## Technical SEO\n\n### Crawlability\n\n**robots.txt:**\n\n```text\n# /robots.txt\nUser-agent: *\nAllow: /\n\n# Block admin/private areas\nDisallow: /admin/\nDisallow: /api/\nDisallow: /private/\n\n# Don't block resources needed for rendering\n# ❌ Disallow: /static/\n\nSitemap: https://example.com/sitemap.xml\n```\n\n**Meta robots:**\n\n```html\n<!-- Default: indexable, followable -->\n<meta name=\"robots\" content=\"index, follow\" />\n\n<!-- Noindex specific pages -->\n<meta name=\"robots\" content=\"noindex, nofollow\" />\n\n<!-- Indexable but don't follow links -->\n<meta name=\"robots\" content=\"index, nofollow\" />\n\n<!-- Control snippets -->\n<meta name=\"robots\" content=\"max-snippet:150, max-image-preview:large\" />\n```\n\n**Canonical URLs:**\n\n```html\n<!-- Prevent duplicate content issues -->\n<link rel=\"canonical\" href=\"https://example.com/page\" />\n\n<!-- Self-referencing canonical (recommended) -->\n<link rel=\"canonical\" href=\"https://example.com/current-page\" />\n\n<!-- For paginated content -->\n<link rel=\"canonical\" href=\"https://example.com/products\" />\n<!-- Or use rel=\"prev\" / rel=\"next\" for explicit pagination -->\n```\n\n### XML sitemap\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\">\n  <url>\n    <loc>https://example.com/</loc>\n    <lastmod>2024-01-15</lastmod>\n    <changefreq>daily</changefreq>\n    <priority>1.0</priority>\n  </url>\n  <url>\n    <loc>https://example.com/products</loc>\n    <lastmod>2024-01-14</lastmod>\n    <changefreq>weekly</changefreq>\n    <priority>0.8</priority>\n  </url>\n</urlset>\n```\n\n**Sitemap best practices:**\n\n- Maximum 50,000 URLs or 50MB per sitemap\n- Use sitemap index for larger sites\n- Include only canonical, indexable URLs\n- Update `lastmod` when content changes\n- Submit to Google Search Console\n\n### URL structure\n\n```\n✅ Good URLs:\nhttps://example.com/products/blue-widget\nhttps://example.com/blog/how-to-use-widgets\n\n❌ Poor URLs:\nhttps://example.com/p?id=12345\nhttps://example.com/products/item/category/subcategory/blue-widget-2024-sale-discount\n```\n\n**URL guidelines:**\n\n- Use hyphens, not underscores\n- Lowercase only\n- Keep short (< 75 characters)\n- Include target keywords naturally\n- Avoid parameters when possible\n- Use HTTPS always\n\n### HTTPS & security\n\n```html\n<!-- Ensure all resources use HTTPS -->\n<img src=\"https://example.com/image.jpg\" />\n\n<!-- Not: -->\n<img src=\"http://example.com/image.jpg\" />\n```\n\n**Security headers for SEO trust signals:**\n\n```\nStrict-Transport-Security: max-age=31536000; includeSubDomains\nX-Content-Type-Options: nosniff\nX-Frame-Options: DENY\n```\n\n---\n\n## On-page SEO\n\n### Title tags\n\n```html\n<!-- ❌ Missing or generic -->\n<title>Page</title>\n<title>Home</title>\n\n<!-- ✅ Descriptive with primary keyword -->\n<title>Blue Widgets for Sale | Premium Quality | Example Store</title>\n```\n\n**Title tag guidelines:**\n\n- 50-60 characters (Google truncates ~60)\n- Primary keyword near the beginning\n- Unique for every page\n- Brand name at end (unless homepage)\n- Action-oriented when appropriate\n\n### Meta descriptions\n\n```html\n<!-- ❌ Missing or duplicate -->\n<meta name=\"description\" content=\"\" />\n\n<!-- ✅ Compelling and unique -->\n<meta\n  name=\"description\"\n  content=\"Shop premium blue widgets with free shipping. 30-day returns. Rated 4.9/5 by 10,000+ customers. Order today and save 20%.\"\n/>\n```\n\n**Meta description guidelines:**\n\n- 150-160 characters\n- Include primary keyword naturally\n- Compelling call-to-action\n- Unique for every page\n- Matches page content\n\n### Heading structure\n\n```html\n<!-- ❌ Poor structure -->\n<h2>Welcome to Our Store</h2>\n<h4>Products</h4>\n<h1>Contact Us</h1>\n\n<!-- ✅ Proper hierarchy -->\n<h1>Blue Widgets - Premium Quality</h1>\n<h2>Product Features</h2>\n<h3>Durability</h3>\n<h3>Design</h3>\n<h2>Customer Reviews</h2>\n<h2>Pricing</h2>\n```\n\n**Heading guidelines:**\n\n- Single `<h1>` per page (the main topic)\n- Logical hierarchy (don't skip levels)\n- Include keywords naturally\n- Descriptive, not generic\n\n### Image SEO\n\n```html\n<!-- ❌ Poor image SEO -->\n<img src=\"IMG_12345.jpg\" />\n\n<!-- ✅ Optimized image -->\n<img\n  src=\"blue-widget-product-photo.webp\"\n  alt=\"Blue widget with chrome finish, side view showing control panel\"\n  width=\"800\"\n  height=\"600\"\n  loading=\"lazy\"\n/>\n```\n\n**Image guidelines:**\n\n- Descriptive filenames with keywords\n- Alt text describes the image content\n- Compressed and properly sized\n- WebP/AVIF with fallbacks\n- Lazy load below-fold images\n\n### Internal linking\n\n```html\n<!-- ❌ Non-descriptive -->\n<a href=\"/products\">Click here</a>\n<a href=\"/widgets\">Read more</a>\n\n<!-- ✅ Descriptive anchor text -->\n<a href=\"/products/blue-widgets\">Browse our blue widget collection</a>\n<a href=\"/guides/widget-maintenance\">Learn how to maintain your widgets</a>\n```\n\n**Linking guidelines:**\n\n- Descriptive anchor text with keywords\n- Link to relevant internal pages\n- Reasonable number of links per page\n- Fix broken links promptly\n- Use breadcrumbs for hierarchy\n\n---\n\n## Structured data (JSON-LD)\n\n### Organization\n\n```html\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"Organization\",\n    \"name\": \"Example Company\",\n    \"url\": \"https://example.com\",\n    \"logo\": \"https://example.com/logo.png\",\n    \"sameAs\": [\"https://twitter.com/example\", \"https://linkedin.com/company/example\"],\n    \"contactPoint\": {\n      \"@type\": \"ContactPoint\",\n      \"telephone\": \"+1-555-123-4567\",\n      \"contactType\": \"customer service\"\n    }\n  }\n</script>\n```\n\n### Article\n\n```html\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"Article\",\n    \"headline\": \"How to Choose the Right Widget\",\n    \"description\": \"Complete guide to selecting widgets for your needs.\",\n    \"image\": \"https://example.com/article-image.jpg\",\n    \"author\": {\n      \"@type\": \"Person\",\n      \"name\": \"Jane Smith\",\n      \"url\": \"https://example.com/authors/jane-smith\"\n    },\n    \"publisher\": {\n      \"@type\": \"Organization\",\n      \"name\": \"Example Blog\",\n      \"logo\": {\n        \"@type\": \"ImageObject\",\n        \"url\": \"https://example.com/logo.png\"\n      }\n    },\n    \"datePublished\": \"2024-01-15\",\n    \"dateModified\": \"2024-01-20\"\n  }\n</script>\n```\n\n### Product\n\n```html\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"Product\",\n    \"name\": \"Blue Widget Pro\",\n    \"image\": \"https://example.com/blue-widget.jpg\",\n    \"description\": \"Premium blue widget with advanced features.\",\n    \"brand\": {\n      \"@type\": \"Brand\",\n      \"name\": \"WidgetCo\"\n    },\n    \"offers\": {\n      \"@type\": \"Offer\",\n      \"price\": \"49.99\",\n      \"priceCurrency\": \"USD\",\n      \"availability\": \"https://schema.org/InStock\",\n      \"url\": \"https://example.com/products/blue-widget\"\n    },\n    \"aggregateRating\": {\n      \"@type\": \"AggregateRating\",\n      \"ratingValue\": \"4.8\",\n      \"reviewCount\": \"1250\"\n    }\n  }\n</script>\n```\n\n### FAQ\n\n```html\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"FAQPage\",\n    \"mainEntity\": [\n      {\n        \"@type\": \"Question\",\n        \"name\": \"What colors are available?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"Our widgets come in blue, red, and green.\"\n        }\n      },\n      {\n        \"@type\": \"Question\",\n        \"name\": \"What is the warranty?\",\n        \"acceptedAnswer\": {\n          \"@type\": \"Answer\",\n          \"text\": \"All widgets include a 2-year warranty.\"\n        }\n      }\n    ]\n  }\n</script>\n```\n\n### Breadcrumbs\n\n```html\n<script type=\"application/ld+json\">\n  {\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"BreadcrumbList\",\n    \"itemListElement\": [\n      {\n        \"@type\": \"ListItem\",\n        \"position\": 1,\n        \"name\": \"Home\",\n        \"item\": \"https://example.com\"\n      },\n      {\n        \"@type\": \"ListItem\",\n        \"position\": 2,\n        \"name\": \"Products\",\n        \"item\": \"https://example.com/products\"\n      },\n      {\n        \"@type\": \"ListItem\",\n        \"position\": 3,\n        \"name\": \"Blue Widgets\",\n        \"item\": \"https://example.com/products/blue-widgets\"\n      }\n    ]\n  }\n</script>\n```\n\n### Validation\n\nTest structured data at:\n\n- [Google Rich Results Test](https://search.google.com/test/rich-results)\n- [Schema.org Validator](https://validator.schema.org/)\n\n---\n\n## Mobile SEO\n\n### Responsive design\n\n```html\n<!-- ❌ Not mobile-friendly -->\n<meta name=\"viewport\" content=\"width=1024\" />\n\n<!-- ✅ Responsive viewport -->\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n```\n\n### Tap targets\n\n```css\n/* ❌ Too small for mobile */\n.small-link {\n  padding: 4px;\n  font-size: 12px;\n}\n\n/* ✅ Adequate tap target */\n.mobile-friendly-link {\n  padding: 12px;\n  font-size: 16px;\n  min-height: 48px;\n  min-width: 48px;\n}\n```\n\n### Font sizes\n\n```css\n/* ❌ Too small on mobile */\nbody {\n  font-size: 10px;\n}\n\n/* ✅ Readable without zooming */\nbody {\n  font-size: 16px;\n  line-height: 1.5;\n}\n```\n\n---\n\n## International SEO\n\n### Hreflang tags\n\n```html\n<!-- For multi-language sites -->\n<link rel=\"alternate\" hreflang=\"en\" href=\"https://example.com/page\" />\n<link rel=\"alternate\" hreflang=\"es\" href=\"https://example.com/es/page\" />\n<link rel=\"alternate\" hreflang=\"fr\" href=\"https://example.com/fr/page\" />\n<link rel=\"alternate\" hreflang=\"x-default\" href=\"https://example.com/page\" />\n```\n\n### Language declaration\n\n```html\n<html lang=\"en\">\n  <!-- or -->\n  <html lang=\"es-MX\"></html>\n</html>\n```\n\n---\n\n## SEO audit checklist\n\n### Critical\n\n- [ ] HTTPS enabled\n- [ ] robots.txt allows crawling\n- [ ] No `noindex` on important pages\n- [ ] Title tags present and unique\n- [ ] Single `<h1>` per page\n\n### High priority\n\n- [ ] Meta descriptions present\n- [ ] Sitemap submitted\n- [ ] Canonical URLs set\n- [ ] Mobile-responsive\n- [ ] Core Web Vitals passing\n\n### Medium priority\n\n- [ ] Structured data implemented\n- [ ] Internal linking strategy\n- [ ] Image alt text\n- [ ] Descriptive URLs\n- [ ] Breadcrumb navigation\n\n### Ongoing\n\n- [ ] Fix crawl errors in Search Console\n- [ ] Update sitemap when content changes\n- [ ] Monitor ranking changes\n- [ ] Check for broken links\n- [ ] Review Search Console insights\n\n---\n\n## Tools\n\n| Tool                      | Use                           |\n| ------------------------- | ----------------------------- |\n| Google Search Console     | Monitor indexing, fix issues  |\n| Google PageSpeed Insights | Performance + Core Web Vitals |\n| Rich Results Test         | Validate structured data      |\n| Lighthouse                | Full SEO audit                |\n| Screaming Frog            | Crawl analysis                |\n\n## References\n\n- [Google Search Central](https://developers.google.com/search)\n- [Schema.org](https://schema.org/)\n- [Core Web Vitals](../core-web-vitals/SKILL.md)\n- [Web Quality Audit](../web-quality-audit/SKILL.md)",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "skill-creator",
      "name": "skill-creator",
      "description": "Guide for creating effective AI agent skills. Use when users want to create a new skill (or update an existing skill) that extends an AI agent's capabilities with specialized knowledge, workflows, or tool integrations. Works with any agent that supports the SKILL.md format (Claude Code, Cursor, Roo, Cline, Windsurf, etc.). Triggers on \"create skill\", \"new skill\", \"package knowledge\", \"skill for\".",
      "category": "creation",
      "path": "skills/(creation)/skill-creator/SKILL.md",
      "content": "# Skill Creator\n\nThis skill provides guidance for creating effective, agent-agnostic skills.\n\n## About Skills\n\nSkills are modular, self-contained packages that extend AI agent capabilities by providing specialized knowledge, workflows, and tools. Think of them as \"onboarding guides\" for specific domains or tasks—they transform a general-purpose agent into a specialized agent equipped with procedural knowledge.\n\n### What Skills Provide\n\n1. **Specialized workflows** - Multi-step procedures for specific domains\n2. **Tool integrations** - Instructions for working with specific file formats or APIs\n3. **Domain expertise** - Company-specific knowledge, schemas, business logic\n4. **Bundled resources** - Scripts, references, and assets for complex and repetitive tasks\n\n## Core Principles\n\n### Concise is Key\n\nThe context window is a public good. Skills share context with everything else the agent needs.\n\n**Default assumption: The agent is already very smart.** Only add context it doesn't already have. Challenge each piece of information: \"Does the agent really need this?\" and \"Does this paragraph justify its token cost?\"\n\nPrefer concise examples over verbose explanations.\n\n### Anatomy of a Skill\n\nEvery skill consists of a required SKILL.md file and optional bundled resources:\n\n```\nskill-name/\n├── SKILL.md (required)\n│   ├── YAML frontmatter metadata (required)\n│   │   ├── name: (required)\n│   │   └── description: (required)\n│   └── Markdown instructions (required)\n└── Bundled Resources (optional)\n    ├── scripts/          - Executable code (Python/Bash/etc.)\n    ├── references/       - Documentation loaded into context as needed\n    └── assets/           - Files used in output (templates, icons, fonts, etc.)\n```\n\n#### SKILL.md (required)\n\nEvery SKILL.md consists of:\n\n- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields read to determine when the skill gets used—be clear and comprehensive.\n- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers.\n\n#### Bundled Resources (optional)\n\n##### Scripts (`scripts/`)\n\nExecutable code for tasks that require deterministic reliability or are repeatedly rewritten.\n\n- **When to include**: When the same code is being rewritten repeatedly\n- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks\n- **Benefits**: Token efficient, deterministic\n\n##### References (`references/`)\n\nDocumentation and reference material loaded as needed into context.\n\n- **When to include**: For documentation the agent should reference while working\n- **Examples**: `references/schema.md` for database schemas, `references/api_docs.md` for API specifications\n- **Benefits**: Keeps SKILL.md lean, loaded only when needed\n\n##### Assets (`assets/`)\n\nFiles not intended to be loaded into context, but used within output.\n\n- **When to include**: When the skill needs files for final output\n- **Examples**: `assets/logo.png` for brand assets, `assets/template.html` for HTML boilerplate\n\n### Progressive Disclosure\n\nSkills use a three-level loading system:\n\n1. **Metadata (name + description)** - Always in context (~100 words)\n2. **SKILL.md body** - When skill triggers (<5k words)\n3. **Bundled resources** - As needed (unlimited)\n\nKeep SKILL.md body under 500 lines. Split content into separate files when approaching this limit.\n\n## Skill Creation Process\n\n### Step 1: Understand the Skill\n\nClarify with concrete examples:\n\n- \"What functionality should this skill support?\"\n- \"Can you give examples of how this skill would be used?\"\n- \"What would trigger this skill?\"\n\n### Step 2: Plan Reusable Contents\n\nAnalyze each example:\n\n1. Consider how to execute from scratch\n2. Identify helpful scripts, references, and assets\n\n### Step 3: Create the Skill\n\nCreate the skill directory:\n\n```\nskill-name/\n├── SKILL.md\n├── scripts/     (if needed)\n├── references/  (if needed)\n└── assets/      (if needed)\n```\n\n### Step 4: Write SKILL.md\n\n#### Frontmatter\n\n```yaml\n---\nname: skill-name\ndescription: What the skill does and when to use it. Include specific triggers and contexts. Max 1024 characters.\n---\n```\n\n**Description guidelines:**\n- Include both what the skill does AND when to use it\n- Include trigger phrases\n- Max 1024 characters, no XML tags\n- Write in third person\n\n#### Body\n\nWrite instructions for using the skill. Include:\n- Quick start guide\n- Step-by-step workflow\n- Links to reference files when needed\n\n### Step 5: Test and Iterate\n\n1. Use the skill on real tasks\n2. Notice struggles or inefficiencies\n3. Update SKILL.md or resources accordingly\n4. Test again\n\n## Quality Checklist\n\nBefore finalizing:\n\n- [ ] Description is specific about when to use (max 1024 chars)\n- [ ] Folder name uses kebab-case\n- [ ] Instructions are actionable and unambiguous\n- [ ] Scope is focused (one responsibility)\n- [ ] SKILL.md body < 500 lines\n- [ ] References are one level deep from SKILL.md\n\n## Output Messages\n\nWhen creating a skill, inform the user:\n\n```\n✅ Skill created successfully!\n\n📁 Location: .agent/skills/[name]/SKILL.md\n🎯 Purpose: [brief description]\n🔧 How to test: [example prompt that should trigger the skill]\n\n💡 Tip: The agent will use this skill automatically when it detects [context].\n```",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "subagent-creator",
      "name": "subagent-creator",
      "description": "Guide for creating AI subagents with isolated context for complex multi-step workflows. Use when users want to create a subagent, specialized agent, verifier, debugger, or orchestrator that requires isolated context and deep specialization. Works with any agent that supports subagent delegation. Triggers on \"create subagent\", \"new agent\", \"specialized assistant\", \"create verifier\".",
      "category": "creation",
      "path": "skills/(creation)/subagent-creator/SKILL.md",
      "content": "# Subagent Creator\n\nThis skill provides guidance for creating effective, agent-agnostic subagents.\n\n## What are Subagents?\n\nSubagents are specialized assistants that an AI agent can delegate tasks to. Characteristics:\n\n- **Isolated context**: Each subagent has its own context window\n- **Parallel execution**: Multiple subagents can run simultaneously\n- **Specialization**: Configured with specific prompts and expertise\n- **Reusable**: Defined once, used in multiple contexts\n\n### When to Use Subagents vs Skills\n\n```\nIs the task complex with multiple steps?\n├─ YES → Does it require isolated context?\n│         ├─ YES → Use SUBAGENT\n│         └─ NO → Use SKILL\n│\n└─ NO → Use SKILL\n```\n\n**Use Subagents for:**\n- Complex workflows requiring isolated context\n- Long-running tasks that benefit from specialization\n- Verification and auditing (independent perspective)\n- Parallel workstreams\n\n**Use Skills for:**\n- Quick, one-off actions\n- Domain knowledge without context isolation\n- Reusable procedures that don't need isolation\n\n## Subagent Structure\n\nA subagent is typically a markdown file with frontmatter metadata:\n\n```markdown\n---\nname: agent-name\ndescription: Description of when to use this subagent.\nmodel: inherit  # or fast, or specific model ID\nreadonly: false  # true to restrict write permissions\n---\n\nYou are an [expert in X].\n\nWhen invoked:\n1. [Step 1]\n2. [Step 2]\n3. [Step 3]\n\n[Detailed instructions about expected behavior]\n\nReport [type of expected result]:\n- [Output format]\n- [Metrics or specific information]\n```\n\n## Subagent Creation Process\n\n### 1. Define the Purpose\n\n- What specific responsibility does the subagent have?\n- Why does it need isolated context?\n- Does it involve multiple complex steps?\n- Does it require deep specialization?\n\n### 2. Configure the Metadata\n\n#### name (required)\nUnique identifier. Use kebab-case.\n\n```yaml\nname: security-auditor\n```\n\n#### description (critical)\nCRITICAL for automatic delegation. Explains when to use this subagent.\n\n**Good descriptions:**\n- \"Security specialist. Use when implementing auth, payments, or handling sensitive data.\"\n- \"Debugging specialist for errors and test failures. Use when encountering issues.\"\n- \"Validates completed work. Use after tasks are marked done.\"\n\n**Phrases that encourage automatic delegation:**\n- \"Use proactively when...\"\n- \"Always use for...\"\n- \"Automatically delegate when...\"\n\n#### model (optional)\n```yaml\nmodel: inherit  # Uses same model as parent (default)\nmodel: fast     # Uses fast model for quick tasks\n```\n\n#### readonly (optional)\n```yaml\nreadonly: true  # Restricts write permissions\n```\n\n### 3. Write the Subagent Prompt\n\nDefine:\n1. **Identity**: \"You are an [expert]...\"\n2. **When invoked**: Context of use\n3. **Process**: Specific steps to follow\n4. **Expected output**: Format and content\n\n**Template:**\n\n```markdown\nYou are an [expert in X] specialized in [Y].\n\nWhen invoked:\n1. [First action]\n2. [Second action]\n3. [Third action]\n\n[Detailed instructions about approach]\n\nReport [type of result]:\n- [Specific format]\n- [Information to include]\n- [Metrics or criteria]\n\n[Philosophy or principles to follow]\n```\n\n## Common Subagent Patterns\n\n### 1. Verification Agent\n\n**Purpose**: Independently validates that completed work actually works.\n\n```markdown\n---\nname: verifier\ndescription: Validates completed work. Use after tasks are marked done.\nmodel: fast\n---\n\nYou are a skeptical validator.\n\nWhen invoked:\n1. Identify what was declared as complete\n2. Verify the implementation exists and is functional\n3. Execute tests or relevant verification steps\n4. Look for edge cases that may have been missed\n\nBe thorough. Report:\n- What was verified and passed\n- What is incomplete or broken\n- Specific issues to address\n```\n\n### 2. Debugger\n\n**Purpose**: Expert in root cause analysis.\n\n```markdown\n---\nname: debugger\ndescription: Debugging specialist. Use when encountering errors or test failures.\n---\n\nYou are a debugging expert.\n\nWhen invoked:\n1. Capture the error message and stack trace\n2. Identify reproduction steps\n3. Isolate the failure location\n4. Implement minimal fix\n5. Verify the solution works\n\nFor each issue, provide:\n- Root cause explanation\n- Evidence supporting the diagnosis\n- Specific code fix\n- Testing approach\n```\n\n### 3. Security Auditor\n\n**Purpose**: Security expert auditing code.\n\n```markdown\n---\nname: security-auditor\ndescription: Security specialist. Use for auth, payments, or sensitive data.\n---\n\nYou are a security expert.\n\nWhen invoked:\n1. Identify security-sensitive code paths\n2. Check for common vulnerabilities\n3. Confirm secrets are not hardcoded\n4. Review input validation\n\nReport findings by severity:\n- **Critical** (must fix before deploy)\n- **High** (fix soon)\n- **Medium** (address when possible)\n- **Low** (suggestions)\n```\n\n### 4. Code Reviewer\n\n**Purpose**: Code review with focus on quality.\n\n```markdown\n---\nname: code-reviewer\ndescription: Code review specialist. Use when changes are ready for review.\n---\n\nYou are a code review expert.\n\nWhen invoked:\n1. Analyze the code changes\n2. Check readability, performance, patterns, error handling\n3. Identify code smells and potential bugs\n4. Suggest specific improvements\n\nReport:\n**✅ Approved / ⚠️ Approved with caveats / ❌ Changes needed**\n\n**Issues Found:**\n- **[Severity]** [Location]: [Issue]\n  - Suggestion: [How to fix]\n```\n\n## Best Practices\n\n### ✅ DO\n\n- **Write focused subagents**: One clear responsibility\n- **Invest in the description**: Determines when to delegate\n- **Keep prompts concise**: Direct and specific\n- **Share with team**: Version control subagent definitions\n- **Test the description**: Check correct subagent is triggered\n\n### ❌ AVOID\n\n- **Vague descriptions**: \"Use for general tasks\" gives no signal\n- **Prompts too long**: 2000 words don't make it smarter\n- **Too many subagents**: Start with 2-3 focused ones\n\n## Quality Checklist\n\nBefore finalizing:\n\n- [ ] Description is specific about when to delegate\n- [ ] Name uses kebab-case\n- [ ] One clear responsibility (not generic)\n- [ ] Prompt is concise but complete\n- [ ] Instructions are actionable\n- [ ] Output format is well defined\n- [ ] Model configuration appropriate\n\n## Output Messages\n\nWhen creating a subagent:\n\n```\n✅ Subagent created successfully!\n\n📁 Location: .agent/subagents/[name].md\n🎯 Purpose: [brief description]\n🔧 How to invoke:\n   - Automatic: Agent delegates when it detects [context]\n   - Explicit: /[name] [instruction]\n\n💡 Tip: Include keywords like \"use proactively\" to encourage delegation.\n```",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "Technical Design Doc Creator",
      "name": "Technical Design Doc Creator",
      "description": "Creates comprehensive Technical Design Documents (TDD) following industry standards with mandatory sections, optional sections, and interactive gathering of missing information.",
      "category": "creation",
      "path": "skills/(creation)/create-technical-design-doc/SKILL.md",
      "content": "# Technical Design Doc Creator\n\nYou are an expert in creating Technical Design Documents (TDDs) that clearly communicate software architecture decisions, implementation plans, and risk assessments following industry best practices.\n\n## When to Use This Skill\n\nUse this skill when:\n\n- User asks to \"create a TDD\", \"write a design doc\", or \"document technical design\"\n- User asks to \"criar um TDD\", \"escrever um design doc\", or \"documentar design técnico\"\n- Starting a new feature or integration project\n- Designing a system that requires team alignment\n- Planning a migration or replacement of existing systems\n- User mentions needing documentation for stakeholder approval\n- Before implementing significant technical changes\n\n## Language Adaptation\n\n**CRITICAL**: Always generate the TDD in the **same language as the user's request**. Detect the language automatically from the user's input and generate all content (headers, prose, explanations) in that language.\n\n**Translation Guidelines**:\n\n- Translate all section headers, prose, and explanations to match user's language\n- Keep technical terms in English when appropriate (e.g., \"API\", \"webhook\", \"JSON\", \"rollback\", \"feature flag\")\n- Keep code examples and schemas language-agnostic (JSON, diagrams, code)\n- Company/product names remain in original language\n- Use natural, professional language for the target language\n- Maintain consistency in terminology throughout the document\n\n**Common Section Header Translations**:\n\n| English                    | Portuguese                      | Spanish                      |\n| -------------------------- | ------------------------------- | ---------------------------- |\n| Context                    | Contexto                        | Contexto                     |\n| Problem Statement          | Definição do Problema           | Definición del Problema      |\n| Scope                      | Escopo                          | Alcance                      |\n| Technical Solution         | Solução Técnica                 | Solución Técnica             |\n| Risks                      | Riscos                          | Riesgos                      |\n| Implementation Plan        | Plano de Implementação          | Plan de Implementación       |\n| Security Considerations    | Considerações de Segurança      | Consideraciones de Seguridad |\n| Testing Strategy           | Estratégia de Testes            | Estrategia de Pruebas        |\n| Monitoring & Observability | Monitoramento e Observabilidade | Monitoreo y Observabilidad   |\n| Rollback Plan              | Plano de Rollback               | Plan de Reversión            |\n\n## Industry Standards Reference\n\nThis skill follows established patterns from:\n\n- **Google Design Docs**: Context, Goals, Non-Goals, Design, Alternatives, Security, Testing\n- **Amazon PR-FAQ**: Working Backwards - start with customer problem\n- **RFC Pattern**: Summary, Motivation, Explanation, Alternatives, Drawbacks\n- **ADR (Architecture Decision Records)**: Context, Decision, Consequences\n- **SRE Book**: Monitoring, Rollback, SLOs, Observability\n- **PCI DSS**: Security requirements for payment systems\n- **OWASP**: Security best practices\n\n## High-Level vs Implementation Details\n\n**CRITICAL PRINCIPLE**: TDDs document **architectural decisions and contracts**, NOT implementation code.\n\n### ✅ What to Include (High-Level)\n\n| Category          | Include                       | Example                                                         |\n| ----------------- | ----------------------------- | --------------------------------------------------------------- |\n| **API Contracts** | Request/Response schemas      | `POST /subscriptions` with JSON body structure                  |\n| **Data Schemas**  | Table structures, field types | `BillingCustomer` table with fields: id, email, stripeId        |\n| **Architecture**  | Components, data flow         | \"Frontend → API → Service → Stripe → Database\"                  |\n| **Decisions**     | What technology, why chosen   | \"Use Stripe because: global support, PCI compliance, best docs\" |\n| **Diagrams**      | Sequence, architecture, flow  | Mermaid/PlantUML diagrams showing interactions                  |\n| **Structures**    | Log format, event schemas     | JSON structure for structured logging                           |\n| **Strategies**    | Approach, not commands        | \"Rollback via feature flag\" (not the curl command)              |\n\n### ❌ What to Avoid (Implementation Code)\n\n| Category                 | Avoid                                    | Why                                               |\n| ------------------------ | ---------------------------------------- | ------------------------------------------------- |\n| **CLI Commands**         | `nx db:generate`, `kubectl rollout undo` | Too specific, may change with tooling             |\n| **Code Snippets**        | TypeScript/JavaScript implementation     | Belongs in code, not docs                         |\n| **Framework Specifics**  | `@Injectable()`, `extends Repository`    | Framework may change, decision is what matters    |\n| **File Paths**           | `scripts/backfill-feature.ts`            | Implementation detail, not architectural decision |\n| **Tool-Specific Syntax** | NestJS decorators, TypeORM entities      | Document pattern, not implementation              |\n\n### Examples: High-Level vs Implementation\n\n#### ❌ BAD (Too Implementation-Specific)\n\n````markdown\n**Rollback Steps**:\n\n```bash\ncurl -X PATCH https://api.launchdarkly.com/flags/FEATURE_X \\\n  -H \"Authorization: Bearer $API_KEY\" \\\n  -d '{\"enabled\": false}'\n\nnx db:rollback billing\n```\n````\n\n````\n\n#### ✅ GOOD (High-Level Decision)\n\n```markdown\n**Rollback Steps**:\n1. Disable feature flag via feature flag service dashboard\n2. Revert database schema using down migration\n3. Verify system returns to previous state\n4. Monitor error rates to confirm rollback success\n````\n\n#### ❌ BAD (Implementation Code)\n\n````markdown\n**Service Implementation**:\n\n```typescript\n@Injectable()\nexport class CustomerService {\n  @Transactional({ connectionName: 'billing' })\n  async create(data: CreateCustomerDto) {\n    const customer = new Customer()\n    customer.email = data.email\n    return this.repository.save(customer)\n  }\n}\n```\n````\n\n````\n\n#### ✅ GOOD (High-Level Structure)\n\n```markdown\n**Service Layer**:\n- `CustomerService`: Manages customer lifecycle\n  - `create()`: Creates customer, validates email uniqueness\n  - `getById()`: Retrieves customer by ID\n  - `updatePaymentMethod()`: Updates default payment method\n- All write operations use transactions to ensure data consistency\n- Services call external Stripe API and cache results locally\n````\n\n### Guideline: Ask \"Will This Change?\"\n\nBefore adding detail to TDD, ask:\n\n- **\"If we change frameworks, does this detail still apply?\"**\n  - YES → Include (it's an architectural decision)\n  - NO → Exclude (it's implementation detail)\n\n- **\"Can someone implement this differently and still meet the requirement?\"**\n  - YES → Focus on the requirement, not the implementation\n  - NO → You might be too specific\n\n**Goal**: TDD should survive implementation changes. If you migrate from NestJS to Express, or TypeORM to Prisma, the TDD should still be valid.\n\n## Document Structure\n\n### Mandatory Sections (Must Have)\n\nThese sections are **required**. If the user doesn't provide information, you **must ask** using AskQuestion tool:\n\n1. **Header & Metadata**\n2. **Context**\n3. **Problem Statement & Motivation**\n4. **Scope** (In Scope / Out of Scope)\n5. **Technical Solution**\n6. **Risks**\n7. **Implementation Plan**\n\n### Critical Sections (Ask if Missing)\n\nThese are **highly recommended** especially for:\n\n- Payment integrations (Security is MANDATORY)\n- Production systems (Monitoring, Rollback are MANDATORY)\n- External integrations (Dependencies, Security)\n\n8. **Security Considerations** (MANDATORY for payments/auth/PII)\n9. **Testing Strategy**\n10. **Monitoring & Observability**\n11. **Rollback Plan**\n\n### Suggested Sections (Offer to User)\n\nAsk user: \"Would you like to add these sections now or later?\"\n\n12. **Success Metrics**\n13. **Glossary & Domain Terms**\n14. **Alternatives Considered**\n15. **Dependencies**\n16. **Performance Requirements**\n17. **Migration Plan** (if applicable)\n18. **Open Questions**\n19. **Roadmap / Timeline**\n20. **Approval & Sign-off**\n\n## Project Size Adaptation\n\nUse this heuristic to determine project complexity:\n\n### Small Project (< 1 week)\n\n**Use sections**: 1, 2, 3, 4, 5, 6, 7, 9\n\n**Skip**: Alternatives, Migration Plan, Approval\n\n### Medium Project (1-4 weeks)\n\n**Use sections**: 1-11, 15, 18\n\n**Offer**: Success Metrics, Glossary, Alternatives, Performance\n\n### Large Project (> 1 month)\n\n**Use all sections** (1-20)\n\n**Critical**: All mandatory + critical sections must be detailed\n\n## Interactive Workflow\n\n### Step 1: Initial Gathering\n\nUse **AskQuestion** tool to collect basic information:\n\n```json\n{\n  \"title\": \"TDD Project Information\",\n  \"questions\": [\n    {\n      \"id\": \"project_name\",\n      \"prompt\": \"What is the name of the feature/integration/project?\",\n      \"options\": [] // Free text\n    },\n    {\n      \"id\": \"project_size\",\n      \"prompt\": \"What is the expected project size?\",\n      \"options\": [\n        { \"id\": \"small\", \"label\": \"Small (< 1 week)\" },\n        { \"id\": \"medium\", \"label\": \"Medium (1-4 weeks)\" },\n        { \"id\": \"large\", \"label\": \"Large (> 1 month)\" }\n      ]\n    },\n    {\n      \"id\": \"project_type\",\n      \"prompt\": \"What type of project is this?\",\n      \"allow_multiple\": true,\n      \"options\": [\n        { \"id\": \"integration\", \"label\": \"External integration (API, service)\" },\n        { \"id\": \"feature\", \"label\": \"New feature\" },\n        { \"id\": \"refactor\", \"label\": \"Refactoring/migration\" },\n        { \"id\": \"infrastructure\", \"label\": \"Infrastructure/platform\" },\n        { \"id\": \"payment\", \"label\": \"Payment/billing system\" },\n        { \"id\": \"auth\", \"label\": \"Authentication/authorization\" },\n        { \"id\": \"data\", \"label\": \"Data migration/processing\" }\n      ]\n    },\n    {\n      \"id\": \"has_context\",\n      \"prompt\": \"Do you have a clear problem statement and context?\",\n      \"options\": [\n        { \"id\": \"yes\", \"label\": \"Yes, I can provide it now\" },\n        { \"id\": \"partial\", \"label\": \"Partially, need help clarifying\" },\n        { \"id\": \"no\", \"label\": \"No, need help defining it\" }\n      ]\n    }\n  ]\n}\n```\n\n### Step 2: Validate Mandatory Information\n\nBased on answers, check if user can provide:\n\n**MANDATORY fields to ask if missing**:\n\n- Tech Lead / Owner\n- Team members\n- Problem description (what/why/impact)\n- What is in scope\n- What is out of scope\n- High-level solution approach\n- At least 3 risks\n- Implementation tasks breakdown\n\n**Ask using AskQuestion or natural conversation IN THE USER'S LANGUAGE**:\n\n**English Example**:\n\n```\nI need the following information to create the TDD:\n\n1. **Problem Statement**:\n   - What problem are we solving?\n   - Why is this important now?\n   - What happens if we don't solve it?\n\n2. **Scope**:\n   - What WILL be delivered in this project?\n   - What will NOT be included (out of scope)?\n\n3. **Technical Approach**:\n   - High-level description of the solution\n   - Main components involved\n   - Integration points\n\nCan you provide this information?\n```\n\n**Portuguese Example**:\n\n```\nPreciso das seguintes informações para criar o TDD:\n\n1. **Definição do Problema**:\n   - Que problema estamos resolvendo?\n   - Por que isso é importante agora?\n   - O que acontece se não resolvermos?\n\n2. **Escopo**:\n   - O que SERÁ entregue neste projeto?\n   - O que NÃO será incluído (fora do escopo)?\n\n3. **Abordagem Técnica**:\n   - Descrição de alto nível da solução\n   - Principais componentes envolvidos\n   - Pontos de integração\n\nVocê pode fornecer essas informações?\n```\n\n### Step 3: Check for Critical Sections\n\nBased on `project_type`, determine if critical sections are mandatory:\n\n| Project Type      | Critical Sections Required                 |\n| ----------------- | ------------------------------------------ |\n| `payment`, `auth` | **Security Considerations** (MANDATORY)    |\n| All production    | **Monitoring & Observability** (MANDATORY) |\n| All production    | **Rollback Plan** (MANDATORY)              |\n| `integration`     | **Dependencies**, **Security**             |\n| All               | **Testing Strategy** (highly recommended)  |\n\n**If critical sections are missing, ASK IN THE USER'S LANGUAGE**:\n\n**English**:\n\n```\nThis is a [payment/auth/production] system. These sections are CRITICAL:\n\n❗ **Security Considerations** - Required for compliance (PCI DSS, OWASP)\n❗ **Monitoring & Observability** - Required to detect issues in production\n❗ **Rollback Plan** - Required to revert if something fails\n\nCan you provide:\n1. Security requirements (auth, encryption, PII handling)?\n2. What metrics will you monitor?\n3. How will you rollback if something goes wrong?\n```\n\n**Portuguese**:\n\n```\nEste é um sistema de [pagamento/autenticação/produção]. Estas seções são CRÍTICAS:\n\n❗ **Considerações de Segurança** - Obrigatório para compliance (PCI DSS, OWASP)\n❗ **Monitoramento e Observabilidade** - Obrigatório para detectar problemas em produção\n❗ **Plano de Rollback** - Obrigatório para reverter se algo falhar\n\nVocê pode fornecer:\n1. Requisitos de segurança (autenticação, encriptação, tratamento de PII)?\n2. Quais métricas você vai monitorar?\n3. Como você fará rollback se algo der errado?\n```\n\n### Step 4: Offer Suggested Sections\n\nAfter mandatory sections are covered, **offer optional sections IN THE USER'S LANGUAGE**:\n\n**English**:\n\n```\nI can also add these sections to make the TDD more complete:\n\n📊 **Success Metrics** - How will you measure success?\n📚 **Glossary** - Define domain-specific terms\n⚖️ **Alternatives Considered** - Why this approach over others?\n🔗 **Dependencies** - External services/teams needed\n⚡ **Performance Requirements** - Latency, throughput, availability targets\n📋 **Open Questions** - Track pending decisions\n\nWould you like me to add any of these now? (You can add them later)\n```\n\n**Portuguese**:\n\n```\nTambém posso adicionar estas seções para tornar o TDD mais completo:\n\n📊 **Métricas de Sucesso** - Como você vai medir o sucesso?\n📚 **Glossário** - Definir termos específicos do domínio\n⚖️ **Alternativas Consideradas** - Por que esta abordagem ao invés de outras?\n🔗 **Dependências** - Serviços/times externos necessários\n⚡ **Requisitos de Performance** - Latência, throughput, disponibilidade\n📋 **Questões em Aberto** - Rastrear decisões pendentes\n\nGostaria que eu adicionasse alguma dessas agora? (Você pode adicionar depois)\n```\n\n### Step 5: Generate Document\n\nGenerate the TDD in Markdown format following the templates below.\n\n### Step 6: Offer Confluence Integration\n\nIf user has Confluence Assistant skill available, **ask in their language**:\n\n**English**:\n\n```\nWould you like me to publish this TDD to Confluence?\n- I can create a new page in your space\n- Or update an existing page\n```\n\n**Portuguese**:\n\n```\nGostaria que eu publicasse este TDD no Confluence?\n- Posso criar uma nova página no seu espaço\n- Ou atualizar uma página existente\n```\n\n## Section Templates\n\n### 1. Header & Metadata (MANDATORY)\n\n```markdown\n# TDD - [Project/Feature Name]\n\n| Field           | Value                        |\n| --------------- | ---------------------------- |\n| Tech Lead       | @Name                        |\n| Product Manager | @Name (if applicable)        |\n| Team            | Name1, Name2, Name3          |\n| Epic/Ticket     | [Link to Jira/Linear]        |\n| Figma/Design    | [Link if applicable]         |\n| Status          | Draft / In Review / Approved |\n| Created         | YYYY-MM-DD                   |\n| Last Updated    | YYYY-MM-DD                   |\n```\n\n**If user doesn't provide**: Ask for Tech Lead, Team members, and Epic link.\n\n---\n\n### 2. Context (MANDATORY)\n\n```markdown\n## Context\n\n[2-4 paragraph description of the project]\n\n**Background**:\nWhat is the current state? What system/feature does this relate to?\n\n**Domain**:\nWhat business domain is this part of? (e.g., billing, authentication, content delivery)\n\n**Stakeholders**:\nWho cares about this project? (users, business, compliance, etc.)\n```\n\n**If unclear**: Ask \"Can you describe the current situation and what business domain this relates to?\"\n\n---\n\n### 3. Problem Statement & Motivation (MANDATORY)\n\n```markdown\n## Problem Statement & Motivation\n\n### Problems We're Solving\n\n- **Problem 1**: [Specific pain point with impact]\n  - Impact: [quantify if possible - time wasted, cost, user friction]\n- **Problem 2**: [Another pain point]\n  - Impact: [quantify if possible]\n\n### Why Now?\n\n- [Business driver - market expansion, competitor pressure, regulatory requirement]\n- [Technical driver - technical debt, scalability limits]\n- [User driver - customer feedback, usage patterns]\n\n### Impact of NOT Solving\n\n- **Business**: [revenue loss, competitive disadvantage]\n- **Technical**: [technical debt accumulation, system degradation]\n- **Users**: [poor experience, churn risk]\n```\n\n**If user says \"to integrate with X\"**: Ask \"What specific problems will this integration solve? Why is it important now? What happens if we don't do it?\"\n\n---\n\n### 4. Scope (MANDATORY)\n\n```markdown\n## Scope\n\n### ✅ In Scope (V1 - MVP)\n\nExplicit list of what WILL be delivered:\n\n- Feature/capability 1\n- Feature/capability 2\n- Feature/capability 3\n- Integration point A\n- Data migration for X\n\n### ❌ Out of Scope (V1)\n\nExplicit list of what will NOT be included in this phase:\n\n- Feature X (deferred to V2)\n- Integration Y (not needed for MVP)\n- Advanced analytics (future enhancement)\n- Multi-region support (V2)\n\n### 🔮 Future Considerations (V2+)\n\nWhat might come later:\n\n- Feature A (user demand dependent)\n- Feature B (after V1 validation)\n```\n\n**If user doesn't define**: Ask \"What are the must-haves for V1? What can wait for later versions?\"\n\n---\n\n### 5. Technical Solution (MANDATORY)\n\n````markdown\n## Technical Solution\n\n### Architecture Overview\n\n[High-level description of the solution]\n\n**Key Components**:\n\n- Component A: [responsibility]\n- Component B: [responsibility]\n- Component C: [responsibility]\n\n**Architecture Diagram**:\n\n[Include Mermaid diagram, PlantUML, or link to diagram]\n\n```mermaid\ngraph LR\n    A[Frontend] -->|HTTP| B[API Gateway]\n    B -->|GraphQL| C[Backend Service]\n    C -->|REST| D[External API]\n    C -->|Write| E[(Database)]\n```\n````\n\n### Data Flow\n\n1. **Step 1**: User action → Frontend\n2. **Step 2**: Frontend → API Gateway (POST /resource)\n3. **Step 3**: API Gateway → Service Layer\n4. **Step 4**: Service → External API (if applicable)\n5. **Step 5**: Service → Database (persist)\n6. **Step 6**: Response → Frontend\n\n### APIs & Endpoints\n\n| Endpoint               | Method | Description      | Request     | Response         |\n| ---------------------- | ------ | ---------------- | ----------- | ---------------- |\n| `/api/v1/resource`     | POST   | Creates resource | `CreateDto` | `ResourceDto`    |\n| `/api/v1/resource/:id` | GET    | Get by ID        | -           | `ResourceDto`    |\n| `/api/v1/resource/:id` | DELETE | Delete resource  | -           | `204 No Content` |\n\n**Example Request/Response**:\n\n```json\n// POST /api/v1/resource\n{\n  \"name\": \"Example\",\n  \"type\": \"standard\"\n}\n\n// Response 201 Created\n{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"name\": \"Example\",\n  \"type\": \"standard\",\n  \"status\": \"active\",\n  \"createdAt\": \"2026-02-04T10:00:00Z\"\n}\n```\n\n### Database Changes\n\n**New Tables**:\n\n- `{ModuleName}{EntityName}` - [description]\n  - Primary fields: id, userId, name, status\n  - Timestamps: createdAt, updatedAt\n  - Indexes: userId, status (for query performance)\n\n**Schema Changes** (if modifying existing):\n\n- Add column `newField` to `ExistingTable`\n  - Type: [varchar/integer/jsonb/etc.]\n  - Constraints: [nullable/unique/foreign key]\n\n**Migration Strategy**:\n\n- Generate migration from schema changes\n- Test migration on staging environment first\n- Run during low-traffic window\n- Have rollback migration ready\n\n**Data Backfill** (if needed):\n\n- Affected records: Estimate quantity\n- Processing time: Estimate duration for data migration\n- Validation: How to verify data integrity after backfill\n\n````\n\n**If user provides vague description**: Ask \"What are the main components? How does data flow through the system? What APIs will be created/modified?\"\n\n---\n\n### 6. Risks (MANDATORY)\n\n```markdown\n## Risks\n\n| Risk | Impact | Probability | Mitigation |\n|------|--------|-------------|------------|\n| External API downtime | High | Medium | Implement circuit breaker, cache responses, fallback to degraded mode |\n| Data migration failure | High | Low | Test on staging copy, run dry-run first, have rollback script ready |\n| Performance degradation | Medium | Medium | Load test before deployment, implement caching, monitor latency |\n| Security vulnerability | High | Low | Security review, penetration testing, follow OWASP guidelines |\n| Scope creep | Medium | High | Strict scope definition, change request process, regular stakeholder alignment |\n\n**Risk Scoring**:\n- **Impact**: High (system down, data loss) / Medium (degraded UX) / Low (minor inconvenience)\n- **Probability**: High (>50%) / Medium (20-50%) / Low (<20%)\n````\n\n**If user provides < 3 risks**: Ask \"What could go wrong? Consider: external dependencies, data integrity, performance, security, scope changes.\"\n\n---\n\n### 7. Implementation Plan (MANDATORY)\n\n```markdown\n## Implementation Plan\n\n| Phase                 | Task              | Description                            | Owner   | Status | Estimate |\n| --------------------- | ----------------- | -------------------------------------- | ------- | ------ | -------- |\n| **Phase 1 - Setup**   | Setup credentials | Obtain API keys, configure environment | @Dev1   | TODO   | 1d       |\n|                       | Database setup    | Create schema, configure datasource    | @Dev1   | TODO   | 1d       |\n| **Phase 2 - Core**    | Entities & repos  | Create TypeORM entities, repositories  | @Dev2   | TODO   | 3d       |\n|                       | Services          | Implement business logic services      | @Dev2   | TODO   | 4d       |\n| **Phase 3 - APIs**    | REST endpoints    | Create controllers, DTOs               | @Dev3   | TODO   | 3d       |\n|                       | Integration       | Integrate with external API            | @Dev1   | TODO   | 3d       |\n| **Phase 4 - Testing** | Unit tests        | Test services and repositories         | @Team   | TODO   | 2d       |\n|                       | E2E tests         | Test full flow                         | @Team   | TODO   | 3d       |\n| **Phase 5 - Deploy**  | Staging deploy    | Deploy to staging, smoke test          | @DevOps | TODO   | 1d       |\n|                       | Production deploy | Phased rollout to production           | @DevOps | TODO   | 1d       |\n\n**Total Estimate**: ~20 days (4 weeks)\n\n**Dependencies**:\n\n- Must complete Phase N before Phase N+1\n- External API access required before Phase 3\n- Security review required before Phase 5\n```\n\n**If user provides vague plan**: Ask \"Can you break this down into phases with specific tasks? Who will work on each part? What's the estimated timeline?\"\n\n---\n\n### 8. Security Considerations (CRITICAL for payments/auth/PII)\n\n```markdown\n## Security Considerations\n\n### Authentication & Authorization\n\n- **Authentication**: How users prove identity\n  - Example: JWT tokens, OAuth 2.0, session-based\n- **Authorization**: What authenticated users can access\n  - Example: Role-based (RBAC), Attribute-based (ABAC)\n  - Ensure users can only access their own resources\n\n### Data Protection\n\n**Encryption**:\n\n- **At Rest**: Database encryption enabled (AES-256)\n- **In Transit**: TLS 1.3 for all API communication\n- **Secrets**: Store API keys in environment variables / secret manager (AWS Secrets Manager, HashiCorp Vault)\n\n**PII Handling**:\n\n- What PII is collected: [email, name, payment info]\n- Legal basis: [consent, contract, legitimate interest]\n- Retention: [how long data is kept]\n- Deletion: [GDPR right to be forgotten implementation]\n\n### Compliance Requirements\n\n| Regulation  | Requirement                        | Implementation                                    |\n| ----------- | ---------------------------------- | ------------------------------------------------- |\n| **GDPR**    | Data protection, right to deletion | Implement data export/deletion endpoints          |\n| **PCI DSS** | No storage of card data            | Use Stripe tokenization, never store CVV/full PAN |\n| **LGPD**    | Brazil data protection             | Same as GDPR compliance                           |\n\n### Security Best Practices\n\n- ✅ Input validation on all endpoints\n- ✅ SQL injection prevention (parameterized queries)\n- ✅ XSS prevention (sanitize user input, CSP headers)\n- ✅ CSRF protection (tokens for state-changing operations)\n- ✅ Rate limiting (e.g., 10 req/min per user, 100 req/min per IP)\n- ✅ Audit logging (log all sensitive operations)\n\n### Secrets Management\n\n**API Keys**:\n\n- Storage: Environment variables or secret management service\n- Rotation: Define rotation policy (e.g., every 90 days)\n- Access: Backend services only, never exposed to frontend\n- Examples: Stripe keys, database credentials, API tokens\n\n**Webhook Signatures**:\n\n- Validate webhook signatures from external services\n- Reject requests without valid signature headers\n- Log invalid signature attempts for security monitoring\n```\n\n**If missing and project involves payments/auth**: Ask \"This is a [payment/auth] system. I need security details: How will you handle authentication? What encryption will be used? What PII is collected? Any compliance requirements (GDPR, PCI DSS)?\"\n\n---\n\n### 9. Testing Strategy (CRITICAL)\n\n```markdown\n## Testing Strategy\n\n| Test Type             | Scope                    | Coverage Target          | Approach             |\n| --------------------- | ------------------------ | ------------------------ | -------------------- |\n| **Unit Tests**        | Services, repositories   | > 80%                    | Jest with mocks      |\n| **Integration Tests** | API endpoints + database | Critical paths           | Supertest + test DB  |\n| **E2E Tests**         | Full user flows          | Happy path + error cases | Playwright           |\n| **Contract Tests**    | External API integration | API contract validation  | Pact or manual mocks |\n| **Load Tests**        | Performance under load   | Baseline performance     | k6 or Artillery      |\n\n### Test Scenarios\n\n**Unit Tests**:\n\n- ✅ Service business logic (create, update, delete)\n- ✅ Repository query methods\n- ✅ Error handling (throw correct exceptions)\n- ✅ Edge cases (null inputs, invalid data)\n\n**Integration Tests**:\n\n- ✅ POST `/api/v1/resource` → creates in DB\n- ✅ GET `/api/v1/resource/:id` → returns correct data\n- ✅ DELETE `/api/v1/resource/:id` → removes from DB\n- ✅ Invalid input → returns 400 Bad Request\n- ✅ Unauthorized access → returns 401/403\n\n**E2E Tests**:\n\n- ✅ User creates resource → success flow\n- ✅ User tries to access another user's resource → denied\n- ✅ External API fails → graceful degradation\n- ✅ Database connection lost → proper error handling\n\n**Load Tests**:\n\n- Target: 100 req/s sustained, 500 req/s peak\n- Monitor: Latency (p50, p95, p99), error rate, throughput\n- Pass criteria: p95 < 500ms, error rate < 1%\n\n### Test Data Management\n\n- Use factories for test data (e.g., `@faker-js/faker`)\n- Seed test database with realistic data\n- Clean up test data after each test\n- Use separate test database (never use production)\n```\n\n**If missing**: Ask \"How will you test this? What test types are needed (unit, integration, e2e)? What are critical test scenarios?\"\n\n---\n\n### 10. Monitoring & Observability (CRITICAL for production)\n\n````markdown\n## Monitoring & Observability\n\n### Metrics to Track\n\n| Metric                    | Type       | Alert Threshold   | Dashboard          |\n| ------------------------- | ---------- | ----------------- | ------------------ |\n| `api.latency`             | Latency    | p95 > 1s for 5min | DataDog / Grafana  |\n| `api.error_rate`          | Error rate | > 1% for 5min     | DataDog / Grafana  |\n| `external_api.latency`    | Latency    | p95 > 2s for 5min | DataDog            |\n| `external_api.errors`     | Counter    | > 5 in 1min       | PagerDuty          |\n| `database.query_time`     | Duration   | p95 > 100ms       | DataDog            |\n| `webhook.processing_time` | Duration   | > 5s              | Internal Dashboard |\n\n### Structured Logging\n\n**Log Format** (JSON):\n\n```json\n{\n  \"level\": \"info\",\n  \"timestamp\": \"2026-02-04T10:00:00Z\",\n  \"message\": \"Resource created\",\n  \"context\": {\n    \"userId\": \"user-123\",\n    \"resourceId\": \"res-456\",\n    \"action\": \"create\",\n    \"duration_ms\": 45\n  }\n}\n```\n````\n\n**What to Log**:\n\n- ✅ All API requests (method, path, status, duration)\n- ✅ External API calls (endpoint, status, duration)\n- ✅ Database queries (slow queries > 100ms)\n- ✅ Errors and exceptions (stack trace, context)\n- ✅ Business events (resource created, payment processed)\n\n**What NOT to Log**:\n\n- ❌ Passwords, API keys, secrets\n- ❌ Full credit card numbers\n- ❌ Sensitive PII (redact or hash)\n\n### Alerts\n\n| Alert                              | Severity      | Channel            | On-Call Action                              |\n| ---------------------------------- | ------------- | ------------------ | ------------------------------------------- |\n| Error rate > 5%                    | P1 (Critical) | PagerDuty          | Immediate investigation, rollback if needed |\n| External API down                  | P1 (Critical) | PagerDuty          | Enable fallback mode, notify stakeholders   |\n| Latency > 2s (p95)                 | P2 (High)     | Slack #engineering | Investigate performance degradation         |\n| Webhook failures > 20              | P2 (High)     | Slack #engineering | Check webhook endpoint, Stripe status       |\n| Database connection pool exhausted | P1 (Critical) | PagerDuty          | Scale up connections or investigate leak    |\n\n### Dashboards\n\n**Operational Dashboard**:\n\n- Request rate (per endpoint)\n- Error rate (overall and per endpoint)\n- Latency (p50, p95, p99)\n- External API health\n- Database performance\n\n**Business Dashboard**:\n\n- Resources created (count per day)\n- Active users\n- Conversion metrics (if applicable)\n\n````\n\n**If missing for production system**: Ask \"How will you monitor this in production? What metrics matter? What alerts do you need?\"\n\n---\n\n### 11. Rollback Plan (CRITICAL for production)\n\n```markdown\n## Rollback Plan\n\n### Deployment Strategy\n\n- **Feature Flag**: `FEATURE_X_ENABLED` (LaunchDarkly / custom)\n- **Phased Rollout**:\n  - Phase 1: 5% of traffic (1 day)\n  - Phase 2: 25% of traffic (1 day)\n  - Phase 3: 50% of traffic (1 day)\n  - Phase 4: 100% of traffic\n\n- **Canary Deployment**: Deploy to 1 instance first, monitor for 1h before full rollout\n\n### Rollback Triggers\n\n| Trigger | Action |\n|---------|--------|\n| Error rate > 5% for 5 minutes | **Immediate rollback** - disable feature flag |\n| Latency > 3s (p95) for 10 minutes | **Investigate** - rollback if no quick fix |\n| External API integration failing > 50% | **Rollback** - revert to previous version |\n| Database migration fails | **STOP** - do not proceed, investigate |\n| Customer reports of data loss | **Immediate rollback** + incident response |\n\n### Rollback Steps\n\n**1. Immediate Rollback (< 5 minutes)**:\n- **Feature Flag**: Disable via feature flag dashboard (instant)\n- **Deployment**: Revert to previous version via deployment tool (2-3 minutes)\n\n**2. Database Rollback** (if schema changed):\n- Run down migration using migration tool\n- Verify schema integrity\n- Confirm data consistency\n\n**3. Communication**:\n\n- Notify #engineering Slack channel\n- Update status page (if customer-facing)\n- Create incident ticket\n- Schedule post-mortem within 24h\n\n### Post-Rollback\n\n- **Root Cause Analysis**: Within 24 hours\n- **Fix**: Implement fix in development environment\n- **Re-test**: Full test suite + additional tests for root cause\n- **Re-deploy**: Following same phased rollout strategy\n\n### Database Rollback Considerations\n\n- **Migrations**: Always create reversible migrations (down migration)\n- **Data Backfill**: If data was modified, have script to restore previous state\n- **Backup**: Take database snapshot before running migrations\n- **Testing**: Test rollback procedure on staging before production\n\n````\n\n**If missing for production**: Ask \"What happens if the deploy goes wrong? How will you rollback? What are the triggers for rollback?\"\n\n---\n\n### 12. Success Metrics (SUGGESTED)\n\n```markdown\n## Success Metrics\n\n| Metric                  | Baseline      | Target  | Measurement        |\n| ----------------------- | ------------- | ------- | ------------------ |\n| API latency (p95)       | N/A (new API) | < 200ms | DataDog APM        |\n| Error rate              | N/A           | < 0.1%  | Sentry / logs      |\n| Conversion rate         | N/A           | > 70%   | Analytics          |\n| User satisfaction       | N/A           | NPS > 8 | User survey        |\n| Time to complete action | N/A           | < 30s   | Frontend analytics |\n\n**Business Metrics**:\n\n- Increase in [metric] by [X%]\n- Reduction in [cost/time] by [Y%]\n- User adoption: [Z%] of users using new feature within 30 days\n\n**Technical Metrics**:\n\n- Zero production incidents in first 30 days\n- Test coverage > 80%\n- Documentation completeness: 100% of public APIs documented\n```\n\n---\n\n### 13. Glossary & Domain Terms (SUGGESTED)\n\n```markdown\n## Glossary\n\n| Term                | Description                                                           |\n| ------------------- | --------------------------------------------------------------------- |\n| **Customer**        | A user who has an active subscription or has made a purchase          |\n| **Subscription**    | Recurring payment arrangement with defined interval (monthly, annual) |\n| **Trial**           | Free period for users to test service before payment required         |\n| **Webhook**         | HTTP callback from external service to notify of events               |\n| **Idempotency**     | Operation can be applied multiple times with same result              |\n| **Circuit Breaker** | Pattern to prevent cascading failures when external service is down   |\n\n**Acronyms**:\n\n- **API**: Application Programming Interface\n- **SLA**: Service Level Agreement\n- **PII**: Personally Identifiable Information\n- **GDPR**: General Data Protection Regulation\n- **PCI DSS**: Payment Card Industry Data Security Standard\n```\n\n---\n\n### 14. Alternatives Considered (SUGGESTED)\n\n```markdown\n## Alternatives Considered\n\n| Option                | Pros                                                     | Cons                                                                        | Why Not Chosen                                    |\n| --------------------- | -------------------------------------------------------- | --------------------------------------------------------------------------- | ------------------------------------------------- |\n| **Option A** (Chosen) | + Best documentation<br>+ Global support<br>+ Mature SDK | - Cost: 2.9% + $0.30<br>- Vendor lock-in                                    | ✅ **Chosen** - Best balance of features and cost |\n| Option B              | + Lower fees (2.5%)<br>+ Brand recognition               | - Poor developer experience<br>- Limited international support              | Developer experience inferior, harder to maintain |\n| Option C              | + Full control<br>+ No transaction fees                  | - High maintenance cost<br>- Compliance burden (PCI DSS)<br>- Security risk | Too risky and expensive to maintain in-house      |\n| Option D              | + Cheapest option                                        | - No support<br>- Limited features<br>- Unknown reliability                 | Too risky for production payment processing       |\n\n**Decision Criteria**:\n\n1. Developer experience and documentation quality (weight: 40%)\n2. Total cost of ownership (weight: 30%)\n3. International support and compliance (weight: 20%)\n4. Reliability and uptime (weight: 10%)\n\n**Why Option A Won**:\n\n- Scored highest on developer experience (critical for fast iteration)\n- Industry-standard for startups (easier to hire developers with experience)\n- Built-in compliance (PCI DSS, SCA, 3D Secure) reduces risk\n```\n\n---\n\n### 15. Dependencies (SUGGESTED)\n\n```markdown\n## Dependencies\n\n| Dependency            | Type           | Owner       | Status           | Risk                |\n| --------------------- | -------------- | ----------- | ---------------- | ------------------- |\n| Stripe API            | External       | Stripe Inc. | Production-ready | Low (99.99% uptime) |\n| Identity Module       | Internal       | Team Auth   | Production-ready | Low                 |\n| Database (PostgreSQL) | Infrastructure | DevOps      | Ready            | Low                 |\n| Redis (caching)       | Infrastructure | DevOps      | Needs setup      | Medium              |\n| Feature flag service  | Internal       | Platform    | Ready            | Low                 |\n\n**Approval Requirements**:\n\n- [ ] Security team review (for payment/auth projects)\n- [ ] Compliance sign-off (for PII/payment data)\n- [ ] Ops team ready for monitoring setup\n- [ ] Product sign-off on scope\n\n**Blockers**:\n\n- Waiting for Stripe production keys (ETA: 2026-02-10)\n- Need Redis setup in staging (ETA: 2026-02-08)\n```\n\n---\n\n### 16. Performance Requirements (SUGGESTED)\n\n```markdown\n## Performance Requirements\n\n| Metric              | Requirement                   | Measurement Method |\n| ------------------- | ----------------------------- | ------------------ |\n| API Latency (p50)   | < 100ms                       | DataDog APM        |\n| API Latency (p95)   | < 500ms                       | DataDog APM        |\n| API Latency (p99)   | < 1s                          | DataDog APM        |\n| Throughput          | 1000 req/s sustained          | Load testing (k6)  |\n| Availability        | 99.9% (< 8.76h downtime/year) | Uptime monitoring  |\n| Database query time | < 50ms (p95)                  | Slow query log     |\n\n**Load Testing Plan**:\n\n- Baseline: 100 req/s for 10 minutes\n- Peak: 500 req/s for 5 minutes\n- Spike: 1000 req/s for 1 minute\n\n**Scalability**:\n\n- Horizontal scaling: Add more instances (Kubernetes autoscaling)\n- Database: Read replicas if needed (after 10k req/s)\n- Caching: Redis for frequently accessed data (> 100 req/s per resource)\n```\n\n---\n\n### 17. Migration Plan (SUGGESTED - if applicable)\n\n```markdown\n## Migration Plan\n\n### Migration Strategy\n\n**Type**: [Blue-Green / Rolling / Big Bang / Phased]\n\n**Phases**:\n\n| Phase             | Description                            | Users Affected | Duration | Rollback            |\n| ----------------- | -------------------------------------- | -------------- | -------- | ------------------- |\n| 1. Preparation    | Set up new system, run in parallel     | 0%             | 1 week   | N/A                 |\n| 2. Shadow Mode    | New system processes but doesn't serve | 0%             | 1 week   | Instant             |\n| 3. Pilot          | 5% of users on new system              | 5%             | 1 week   | < 5min              |\n| 4. Ramp Up        | 50% of users on new system             | 50%            | 1 week   | < 5min              |\n| 5. Full Migration | 100% of users on new system            | 100%           | 1 day    | < 5min              |\n| 6. Decommission   | Turn off old system                    | 0%             | 1 week   | Restore from backup |\n\n### Data Migration\n\n**Source**: Old system database\n**Destination**: New system database\n**Volume**: [X million records]\n**Method**: [ETL script / database replication / API sync]\n\n**Steps**:\n\n1. Export data from old system (script: `scripts/export-old-data.ts`)\n2. Transform data to new schema (script: `scripts/transform-data.ts`)\n3. Validate data integrity (checksums, row counts)\n4. Load into new system (script: `scripts/load-new-data.ts`)\n5. Verify: Run parallel reads, compare results\n\n**Timeline**:\n\n- Dry run on staging: 2026-02-10\n- Production migration window: 2026-02-15 02:00-06:00 UTC (low traffic)\n\n### Backward Compatibility\n\n- Old API endpoints will remain active for 90 days\n- Deprecation warnings added to responses\n- Client libraries updated with migration guide\n```\n\n---\n\n### 18. Open Questions (SUGGESTED)\n\n```markdown\n## Open Questions\n\n| #   | Question                                               | Context                                        | Owner     | Status           | Decision Date |\n| --- | ------------------------------------------------------ | ---------------------------------------------- | --------- | ---------------- | ------------- |\n| 1   | How to handle trial expiration without payment method? | User loses access immediately or grace period? | @Product  | 🟡 In Discussion | TBD           |\n| 2   | Allow multiple trials for same email?                  | Prevent abuse vs. legitimate use cases         | @TechLead | 🔴 Open          | TBD           |\n| 3   | SLA for webhook processing?                            | Stripe retries for 72h, what's our target?     | @Backend  | 🔴 Open          | TBD           |\n| 4   | Support for promo codes in V1?                         | Marketing requested, is it in scope?           | @Product  | ✅ Resolved: V2  | 2026-02-01    |\n| 5   | Fallback if Identity Module fails?                     | Can we create subscription without user data?  | @TechLead | 🔴 Open          | TBD           |\n\n**Status Legend**:\n\n- 🔴 Open - needs decision\n- 🟡 In Discussion - actively being discussed\n- ✅ Resolved - decision made\n```\n\n---\n\n### 19. Roadmap / Timeline (SUGGESTED)\n\n```markdown\n## Roadmap / Timeline\n\n| Phase                    | Deliverables                                                                      | Duration | Target Date | Status         |\n| ------------------------ | --------------------------------------------------------------------------------- | -------- | ----------- | -------------- |\n| **Phase 0: Setup**       | - Stripe credentials<br>- Staging environment<br>- SDK installed                  | 2 days   | 2026-02-05  | ✅ Complete    |\n| **Phase 1: Persistence** | - Entities created<br>- Repositories implemented<br>- Migrations generated        | 3 days   | 2026-02-08  | 🟡 In Progress |\n| **Phase 2: Services**    | - CustomerService<br>- SubscriptionService<br>- Identity integration              | 5 days   | 2026-02-15  | ⏳ Pending     |\n| **Phase 3: APIs**        | - POST /subscriptions<br>- DELETE /subscriptions/:id<br>- GET /subscriptions      | 3 days   | 2026-02-18  | ⏳ Pending     |\n| **Phase 4: Webhooks**    | - Webhook endpoint<br>- Signature validation<br>- Event handlers                  | 4 days   | 2026-02-22  | ⏳ Pending     |\n| **Phase 5: Testing**     | - Unit tests (80% coverage)<br>- Integration tests<br>- E2E tests                 | 5 days   | 2026-02-27  | ⏳ Pending     |\n| **Phase 6: Deploy**      | - Documentation<br>- Monitoring setup<br>- Staging deploy<br>- Production rollout | 3 days   | 2026-03-02  | ⏳ Pending     |\n\n**Total Duration**: ~25 days (5 weeks)\n\n**Milestones**:\n\n- 🎯 M1: MVP ready for staging (2026-02-22)\n- 🎯 M2: Production deployment (2026-03-02)\n- 🎯 M3: 100% rollout complete (2026-03-09)\n\n**Critical Path**:\nPhase 0 → Phase 1 → Phase 2 → Phase 3 → Phase 4 → Phase 5 → Phase 6\n```\n\n---\n\n### 20. Approval & Sign-off (SUGGESTED)\n\n```markdown\n## Approval & Sign-off\n\n| Role                     | Name  | Status         | Date       | Comments                          |\n| ------------------------ | ----- | -------------- | ---------- | --------------------------------- |\n| Tech Lead                | @Name | ✅ Approved    | 2026-02-04 | LGTM, proceed with implementation |\n| Staff/Principal Engineer | @Name | ⏳ Pending     | -          | Requested security review first   |\n| Product Manager          | @Name | ✅ Approved    | 2026-02-03 | Scope aligned with roadmap        |\n| Engineering Manager      | @Name | ⏳ Pending     | -          | -                                 |\n| Security Team            | @Name | 🔴 Not Started | -          | Required for payment integration  |\n| Compliance/Legal         | @Name | N/A            | -          | Not required for this project     |\n\n**Approval Criteria**:\n\n- ✅ All mandatory sections complete\n- ✅ Security review passed (if applicable)\n- ✅ Risks identified and mitigated\n- ✅ Timeline realistic and agreed upon\n- ⏳ Test strategy approved by QA\n- ⏳ Monitoring plan reviewed by SRE\n\n**Next Steps After Approval**:\n\n1. Create Epic in Jira (link in metadata)\n2. Break down into User Stories\n3. Begin Phase 1 implementation\n4. Schedule kickoff meeting with team\n```\n\n---\n\n## Validation Rules\n\n### Mandatory Section Checklist\n\nBefore finalizing TDD, ensure:\n\n- [ ] **Header**: Tech Lead, Team, Epic link present\n- [ ] **Context**: 2+ paragraphs describing background and domain\n- [ ] **Problem**: At least 2 specific problems identified with impact\n- [ ] **Scope**: Clear in-scope and out-of-scope items (min 3 each)\n- [ ] **Technical Solution**: Architecture diagram or description\n- [ ] **Technical Solution**: At least 1 API endpoint defined\n- [ ] **Risks**: At least 3 risks with impact/probability/mitigation\n- [ ] **Implementation Plan**: Broken into phases with estimates\n\n### Critical Section Checklist (by project type)\n\n**If Payment/Auth project**:\n\n- [ ] **Security**: Authentication method defined\n- [ ] **Security**: Encryption (at rest, in transit) specified\n- [ ] **Security**: PII handling approach documented\n- [ ] **Security**: Compliance requirements identified\n\n**If Production system**:\n\n- [ ] **Monitoring**: At least 3 metrics defined with thresholds\n- [ ] **Monitoring**: Alerts configured\n- [ ] **Rollback**: Rollback triggers defined\n- [ ] **Rollback**: Rollback steps documented\n\n**All projects**:\n\n- [ ] **Testing**: At least 2 test types defined (unit, integration, e2e)\n- [ ] **Testing**: Critical test scenarios listed\n\n## Output Format\n\n### When Creating TDD\n\n1. **Generate Markdown document**\n2. **Validate against checklists above**\n3. **Highlight any missing critical sections**\n4. **Provide summary to user**:\n\n```\n✅ TDD Created: \"[Project Name]\"\n\n**Sections Included**:\n✅ Mandatory (7/7): All present\n✅ Critical (3/4): Security, Testing, Monitoring\n⚠️ Missing: Rollback Plan (recommended for production)\n\n**Suggested Next Steps**:\n- Add Rollback Plan section (critical for production)\n- Review Security section with InfoSec team\n- Create Epic in Jira and link in metadata\n- Schedule TDD review meeting with stakeholders\n\nWould you like me to:\n1. Add the missing Rollback Plan section?\n2. Publish this TDD to Confluence?\n3. Create a Jira Epic for this project?\n```\n\n### Confluence Integration\n\nIf user wants to publish to Confluence:\n\n```\nI'll publish this TDD to Confluence.\n\nWhich space should I use?\n- Personal space (~557058...)\n- Team space (provide space key)\n\nShould I:\n- Create a new page\n- Update existing page (provide page ID or URL)\n```\n\nThen use Confluence Assistant skill to publish.\n\n## Common Anti-Patterns to Avoid\n\n### ❌ Vague Problem Statements\n\n**BAD**:\n\n```\n\nWe need to integrate with Stripe.\n\n```\n\n**GOOD**:\n\n```\n\n### Problems We're Solving\n\n- **Manual payment processing takes 2 hours/day**: Currently processing payments manually, costing $500/month in labor\n- **Cannot expand internationally**: Current payment processor only supports USD\n- **High cart abandonment (45%)**: Poor checkout UX causing revenue loss of $10k/month\n\n```\n\n### ❌ Undefined Scope\n\n**BAD**:\n\n```\n\nBuild payment integration with all features.\n\n```\n\n**GOOD**:\n\n```\n\n### ✅ In Scope (V1)\n\n- Trial subscriptions (14 days)\n- Single payment method per user\n- USD only\n- Cancel subscription\n\n### ❌ Out of Scope (V1)\n\n- Multiple payment methods\n- Multi-currency\n- Promo codes\n- Usage-based billing\n\n```\n\n### ❌ Missing Security for Payment Systems\n\n**BAD**:\n\n```\n\nNo security section for payment integration.\n\n```\n\n**GOOD**:\n\n```\n\n### Security Considerations (MANDATORY)\n\n**PCI DSS Compliance**:\n\n- Never store full card numbers (use Stripe tokens)\n- Never log CVV or full PAN\n- Use Stripe Elements for card input (PCI SAQ A)\n\n**Secrets Management**:\n\n- Store `STRIPE_SECRET_KEY` in environment variables\n- Rotate keys every 90 days\n- Never commit keys to git\n\n```\n\n### ❌ No Rollback Plan\n\n**BAD**:\n\n```\n\nWe'll deploy and hope it works.\n\n```\n\n**GOOD**:\n\n```\n\n### Rollback Plan\n\n**Triggers**:\n\n- Error rate > 5% → immediate rollback\n- Payment processing failures > 10% → immediate rollback\n\n**Steps**:\n\n1. Disable feature flag `STRIPE_INTEGRATION_ENABLED`\n2. Verify old payment processor is active\n3. Notify #engineering and #product\n4. Schedule post-mortem within 24h\n\n```\n\n## Important Notes\n\n- **Respect user's language** - Automatically detect and generate TDD in the same language as user's request\n- **Focus on architecture, not implementation** - Document decisions and contracts, not code\n- **High-level examples only** - Show API contracts, data schemas, diagrams (not CLI commands or code snippets)\n- **Always validate mandatory sections** - Don't let user skip them\n- **For payments/auth** - Security section is MANDATORY\n- **For production** - Monitoring and Rollback are MANDATORY\n- **Ask clarifying questions** - Don't guess missing information (ask in user's language)\n- **Be thorough but pragmatic** - Small projects don't need all 20 sections\n- **Update the document** - TDDs should evolve as the project progresses\n- **Use industry standards** - Reference Google, Amazon, RFC patterns\n- **Think about compliance** - GDPR, PCI DSS, HIPAA where applicable\n- **Test for longevity** - If implementation framework changes, TDD should still be valid\n\n## Example Prompts that Trigger This Skill\n\n### English\n\n- \"Create a TDD for Stripe integration\"\n- \"I need a technical design document for the new auth system\"\n- \"Write a design doc for the API redesign\"\n- \"Help me document the payment integration architecture\"\n- \"Create a tech spec for migrating to microservices\"\n\n### Portuguese\n\n- \"Crie um TDD para integração com Stripe\"\n- \"Preciso de um documento de design técnico para o novo sistema de autenticação\"\n- \"Escreva um design doc para o redesign da API\"\n- \"Me ajude a documentar a arquitetura de integração de pagamento\"\n- \"Crie uma especificação técnica para migração para microserviços\"\n\n### Spanish\n\n- \"Crea un TDD para integración con Stripe\"\n- \"Necesito un documento de diseño técnico para el nuevo sistema de autenticación\"\n- \"Escribe un design doc para el rediseño de la API\"\n- \"Ayúdame a documentar la arquitectura de integración de pagos\"\n- \"Crea una especificación técnica para migración a microservicios\"\n\n## References\n\n### Industry Standards\n\n- [Google Engineering Practices](https://google.github.io/eng-practices/)\n- [Google SRE Book](https://sre.google/sre-book/table-of-contents/)\n- [OWASP Top 10](https://owasp.org/www-project-top-ten/)\n- [Architecture Decision Records](https://adr.github.io/)\n\n```\n\n```",
      "metadata": {
        "hasScripts": false,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "tlc-spec-driven",
      "name": "tlc-spec-driven",
      "description": "Project and feature planning with 4 phases - Specify, Design, Tasks, Implement+Validate. Creates atomic tasks with verification criteria and maintains persistent memory across sessions. Stack-agnostic. Use when: (1) Starting new projects (initialize vision, goals, roadmap), (2) Working with existing codebases (map stack, architecture, conventions), (3) Planning features (requirements, design, task breakdown), (4) Implementing with verification, (5) Tracking decisions/blockers across sessions, (6) Pausing/resuming work. Triggers on \"initialize project\", \"map codebase\", \"specify feature\", \"design\", \"tasks\", \"implement\", \"pause work\", \"resume work\".",
      "category": "development",
      "path": "skills/(development)/tlc-spec-driven/SKILL.md",
      "content": "# Tech Lead's Club - Spec-Driven Development\n\nPlan and implement projects with precision. Granular tasks. Clear dependencies. Right tools.\n\n```\n┌──────────┐   ┌──────────┐   ┌─────────┐   ┌───────────────────┐\n│ SPECIFY  │ → │  DESIGN  │ → │  TASKS  │ → │ IMPLEMENT+VALIDATE│\n└──────────┘   └──────────┘   └─────────┘   └───────────────────┘\n```\n\n## Project Structure\n\n```\n.specs/\n├── project/\n│   ├── PROJECT.md      # Vision & goals\n│   ├── ROADMAP.md      # Features & milestones\n│   └── STATE.md        # Memory between sessions\n├── codebase/           # Brownfield analysis (existing projects)\n│   ├── STACK.md\n│   ├── ARCHITECTURE.md\n│   ├── CONVENTIONS.md\n│   ├── STRUCTURE.md\n│   ├── TESTING.md\n│   └── INTEGRATIONS.md\n└── features/           # Feature specifications\n    └── [feature]/\n        ├── spec.md\n        ├── design.md\n        └── tasks.md\n```\n\n## Workflow\n\n**New project:**\n\n1. Initialize project → PROJECT.md\n2. Create roadmap → ROADMAP.md\n3. Specify features → existing workflow\n\n**Existing codebase:**\n\n1. Map codebase → 6 brownfield docs\n2. Initialize project → PROJECT.md + ROADMAP.md\n3. Specify features → existing workflow\n\n## Context Loading Strategy\n\n**Base load (~15k tokens):**\n\n- PROJECT.md (if exists)\n- ROADMAP.md (when planning/working on features)\n- STATE.md (persistent memory)\n\n**On-demand load:**\n\n- Codebase docs (when working in existing project)\n- spec.md (when working on specific feature)\n- design.md (when implementing from design)\n- tasks.md (when executing tasks)\n\n**Never load simultaneously:**\n\n- Multiple feature specs\n- Multiple architecture docs\n- Archived documents\n\n**Target:** <40k tokens total context\n**Reserve:** 160k+ tokens for work, reasoning, outputs\n**Monitoring:** Display status when >40k (see [context-limits.md](references/context-limits.md))\n\n## Commands\n\n**Project-level:**\n| Trigger Pattern | Reference |\n|----------------|-----------|\n| Initialize project, setup project | [project-init.md](references/project-init.md) |\n| Create roadmap, plan features | [roadmap.md](references/roadmap.md) |\n| Map codebase, analyze existing code | [brownfield-mapping.md](references/brownfield-mapping.md) |\n| Record decision, log blocker | [state-management.md](references/state-management.md) |\n| Pause work, end session | [session-handoff.md](references/session-handoff.md) |\n| Resume work, continue | [session-handoff.md](references/session-handoff.md) |\n\n**Feature-level:**\n| Trigger Pattern | Reference |\n|----------------|-----------|\n| Specify feature, define requirements | [specify.md](references/specify.md) |\n| Design feature, architecture | [design.md](references/design.md) |\n| Break into tasks, create tasks | [tasks.md](references/tasks.md) |\n| Implement task, build | [implement.md](references/implement.md) |\n| Validate, verify, test | [validate.md](references/validate.md) |\n\n**Tools:**\n| Trigger Pattern | Reference |\n|----------------|-----------|\n| Code analysis, search patterns | [code-analysis.md](references/code-analysis.md) |\n\n## Output Behavior\n\n**Model guidance:** After completing lightweight tasks (validation, state updates, session handoff), naturally mention once that such tasks work well with faster/cheaper models. Track in STATE.md under `Preferences` to avoid repeating. For heavy tasks (brownfield mapping, complex design), briefly note the reasoning requirements before starting.\n\nBe conversational, not robotic. Don't interrupt workflow—add as a natural closing note. Skip if user seems experienced or has already acknowledged the tip.\n\n## Code Analysis\n\nUse available tools with graceful degradation. See [code-analysis.md](references/code-analysis.md).",
      "metadata": {
        "hasScripts": false,
        "hasReferences": true,
        "referenceFiles": [
          "brownfield-mapping.md",
          "code-analysis.md",
          "coding-principles.md",
          "context-limits.md",
          "design.md",
          "implement.md",
          "project-init.md",
          "roadmap.md",
          "session-handoff.md",
          "specify.md",
          "state-management.md",
          "tasks.md",
          "validate.md"
        ],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "vercel-deploy",
      "name": "vercel-deploy",
      "description": "Deploy applications and websites to Vercel. Use when the user requests deployment actions like \"deploy my app\", \"deploy and give me the link\", \"push this live\", or \"create a preview deployment\".",
      "category": "cloud",
      "path": "skills/(cloud)/vercel-deploy/SKILL.md",
      "content": "# Vercel Deploy\n\nDeploy any project to Vercel instantly. **Always deploy as preview** (not production) unless the user explicitly asks for production.\n\n## Prerequisites\n\n- When sandboxing blocks the deployment network calls, rerun with `sandbox_permissions=require_escalated`.\n- The deployment might take a few minutes. Use appropriate timeout values.\n\n## Quick Start\n\n**Just run this (with a 10 minute timeout):**\n\n```bash\nvercel deploy [path] -y\n```\n\n**Important:** Use a 10 minute (600000ms) timeout for the deploy command since builds can take a while.\n\nIf that fails with \"No existing credentials found\", use the fallback method below.\n\n## Fallback (No Auth)\n\nIf CLI fails with auth error, use the deploy script:\n\n```bash\n# Deploy current directory\nbash scripts/deploy.sh\n\n# Deploy specific project\nbash scripts/deploy.sh /path/to/project\n\n# Deploy existing tarball\nbash scripts/deploy.sh /path/to/project.tgz\n```\n\nThe script handles framework detection, packaging, and deployment. It waits for the build to complete and returns JSON with `previewUrl` and `claimUrl`.\n\n**Tell the user:** \"Your deployment is ready at [previewUrl]. Claim it at [claimUrl] to manage your deployment.\"\n\n## Production Deploys\n\nOnly if user explicitly asks:\n\n```bash\nvercel deploy [path] --prod -y\n```\n\n## Output\n\nShow the user the deployment URL. For fallback deployments, also show the claim URL.\n\n**Do not** curl or fetch the deployed URL to verify it works. Just return the link.\n\n## Troubleshooting\n\n### Escalated Network Access\n\nIf deployment fails due to network issues (timeouts, DNS errors, connection resets), rerun the deploy with escalated permissions (use `sandbox_permissions=require_escalated`). The deploy requires escalated network access when sandbox networking blocks outbound requests.\n\nExample guidance to the user:\n\n```\nThe deploy needs escalated network access to deploy to Vercel. I can rerun the command with escalated permissions—want me to proceed?\n```",
      "metadata": {
        "hasScripts": true,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    },
    {
      "id": "web-quality-audit",
      "name": "web-quality-audit",
      "description": "Comprehensive web quality audit covering performance, accessibility, SEO, and best practices. Use when asked to \"audit my site\", \"review web quality\", \"run lighthouse audit\", \"check page quality\", or \"optimize my website\".",
      "category": "quality",
      "path": "skills/(quality)/web-quality-audit/SKILL.md",
      "content": "# Web quality audit\n\nComprehensive quality review based on Google Lighthouse audits. Covers Performance, Accessibility, SEO, and Best Practices across 150+ checks.\n\n## How it works\n\n1. Analyze the provided code/project for quality issues\n2. Categorize findings by severity (Critical, High, Medium, Low)\n3. Provide specific, actionable recommendations\n4. Include code examples for fixes\n\n## Audit categories\n\n### Performance (40% of typical issues)\n\n**Core Web Vitals** — Must pass for good page experience:\n\n- **LCP (Largest Contentful Paint) < 2.5s.** The largest visible element must render quickly. Optimize images, fonts, and server response time.\n- **INP (Interaction to Next Paint) < 200ms.** User interactions must feel instant. Reduce JavaScript execution time and break up long tasks.\n- **CLS (Cumulative Layout Shift) < 0.1.** Content must not jump around. Set explicit dimensions on images, embeds, and ads.\n\n**Resource Optimization:**\n\n- **Compress images.** Use WebP/AVIF with fallbacks. Serve correctly sized images via `srcset`.\n- **Minimize JavaScript.** Remove unused code. Use code splitting. Defer non-critical scripts.\n- **Optimize CSS.** Extract critical CSS. Remove unused styles. Avoid `@import`.\n- **Efficient fonts.** Use `font-display: swap`. Preload critical fonts. Subset to needed characters.\n\n**Loading Strategy:**\n\n- **Preconnect to origins.** Add `<link rel=\"preconnect\">` for third-party domains.\n- **Preload critical assets.** LCP images, fonts, and above-fold CSS.\n- **Lazy load below-fold content.** Images, iframes, and heavy components.\n- **Cache effectively.** Long cache TTLs for static assets. Immutable caching for hashed files.\n\n### Accessibility (30% of typical issues)\n\n**Perceivable:**\n\n- **Text alternatives.** Every `<img>` has meaningful `alt` text. Decorative images use `alt=\"\"`.\n- **Color contrast.** Minimum 4.5:1 for normal text, 3:1 for large text (WCAG AA).\n- **Don't rely on color alone.** Use icons, patterns, or text alongside color indicators.\n- **Captions and transcripts.** Video has captions. Audio has transcripts.\n\n**Operable:**\n\n- **Keyboard accessible.** All functionality available via keyboard. No keyboard traps.\n- **Focus visible.** Clear focus indicators on all interactive elements.\n- **Skip links.** Provide \"Skip to main content\" for keyboard users.\n- **Sufficient time.** Users can extend time limits. No auto-advancing content without controls.\n\n**Understandable:**\n\n- **Page language.** Set `lang` attribute on `<html>`.\n- **Consistent navigation.** Same navigation structure across pages.\n- **Error identification.** Form errors clearly described and associated with fields.\n- **Labels and instructions.** All form inputs have associated labels.\n\n**Robust:**\n\n- **Valid HTML.** No duplicate IDs. Properly nested elements.\n- **ARIA used correctly.** Prefer native elements. ARIA roles match behavior.\n- **Name, role, value.** Interactive elements have accessible names and correct roles.\n\n### SEO (15% of typical issues)\n\n**Crawlability:**\n\n- **Valid robots.txt.** Doesn't block important resources.\n- **XML sitemap.** Lists all important pages. Submitted to Search Console.\n- **Canonical URLs.** Prevent duplicate content issues.\n- **No noindex on important pages.** Check meta robots and headers.\n\n**On-Page SEO:**\n\n- **Unique title tags.** 50-60 characters. Primary keyword included.\n- **Meta descriptions.** 150-160 characters. Compelling and unique.\n- **Heading hierarchy.** Single `<h1>`. Logical heading structure.\n- **Descriptive link text.** Not \"click here\" or \"read more\".\n\n**Technical SEO:**\n\n- **Mobile-friendly.** Responsive design. Tap targets ≥ 48px.\n- **HTTPS.** Secure connection required.\n- **Fast loading.** Performance directly impacts ranking.\n- **Structured data.** JSON-LD for rich snippets (Article, Product, FAQ, etc.).\n\n### Best practices (15% of typical issues)\n\n**Security:**\n\n- **HTTPS everywhere.** No mixed content. HSTS enabled.\n- **No vulnerable libraries.** Keep dependencies updated.\n- **CSP headers.** Content Security Policy to prevent XSS.\n- **No exposed source maps.** In production builds.\n\n**Modern Standards:**\n\n- **No deprecated APIs.** Replace `document.write`, synchronous XHR, etc.\n- **Valid doctype.** Use `<!DOCTYPE html>`.\n- **Charset declared.** `<meta charset=\"UTF-8\">` as first element in `<head>`.\n- **No browser errors.** Clean console. No CORS issues.\n\n**UX Patterns:**\n\n- **No intrusive interstitials.** Especially on mobile.\n- **Clear permission requests.** Only ask when needed, with context.\n- **No misleading buttons.** Buttons do what they say.\n\n## Severity levels\n\n| Level        | Description                                   | Action              |\n| ------------ | --------------------------------------------- | ------------------- |\n| **Critical** | Security vulnerabilities, complete failures   | Fix immediately     |\n| **High**     | Core Web Vitals failures, major a11y barriers | Fix before launch   |\n| **Medium**   | Performance opportunities, SEO improvements   | Fix within sprint   |\n| **Low**      | Minor optimizations, code quality             | Fix when convenient |\n\n## Audit output format\n\nWhen performing an audit, structure findings as:\n\n```markdown\n## Audit results\n\n### Critical issues (X found)\n\n- **[Category]** Issue description. File: `path/to/file.js:123`\n  - **Impact:** Why this matters\n  - **Fix:** Specific code change or recommendation\n\n### High priority (X found)\n\n...\n\n### Summary\n\n- Performance: X issues (Y critical)\n- Accessibility: X issues (Y critical)\n- SEO: X issues\n- Best Practices: X issues\n\n### Recommended priority\n\n1. First fix this because...\n2. Then address...\n3. Finally optimize...\n```\n\n## Quick checklist\n\n### Before every deploy\n\n- [ ] Core Web Vitals passing\n- [ ] No accessibility errors (axe/Lighthouse)\n- [ ] No console errors\n- [ ] HTTPS working\n- [ ] Meta tags present\n\n### Weekly review\n\n- [ ] Check Search Console for issues\n- [ ] Review Core Web Vitals trends\n- [ ] Update dependencies\n- [ ] Test with screen reader\n\n### Monthly deep dive\n\n- [ ] Full Lighthouse audit\n- [ ] Performance profiling\n- [ ] Accessibility audit with real users\n- [ ] SEO keyword review\n\n## References\n\nFor detailed guidelines on specific areas:\n\n- [Performance Optimization](../performance/SKILL.md)\n- [Core Web Vitals](../core-web-vitals/SKILL.md)\n- [Accessibility](../accessibility/SKILL.md)\n- [SEO](../seo/SKILL.md)\n- [Best Practices](../best-practices/SKILL.md)",
      "metadata": {
        "hasScripts": true,
        "hasReferences": false,
        "referenceFiles": [],
        "lastModified": "2026-02-06"
      }
    }
  ],
  "categories": [
    {
      "id": "cloud",
      "name": "Cloud & Infrastructure",
      "description": "Skills for cloud management, AWS, and DevOps",
      "priority": 1
    },
    {
      "id": "creation",
      "name": "Skill & Agent Creation",
      "description": "Skills for creating new skills and subagents",
      "priority": 2
    },
    {
      "id": "design",
      "name": "Design",
      "description": "Skills for UI/UX design and design systems",
      "priority": 3
    },
    {
      "id": "development",
      "name": "Development",
      "description": "Skills for software development workflows",
      "priority": 4
    },
    {
      "id": "monitoring",
      "name": "Monitoring",
      "description": "Skills for observability, logging, and system monitoring",
      "priority": 5
    },
    {
      "id": "performance",
      "name": "Performance",
      "description": "Skills for web performance optimization, audits, and monitoring",
      "priority": 6
    },
    {
      "id": "quality",
      "name": "Quality",
      "description": "Skills for code quality, testing, and best practices",
      "priority": 7
    },
    {
      "id": "security",
      "name": "Security",
      "description": "Skills for security analysis, vulnerability detection, and secure coding",
      "priority": 8
    },
    {
      "id": "tooling",
      "name": "Tooling",
      "description": "Skills for tooling and utilities",
      "priority": 9
    },
    {
      "id": "web-automation",
      "name": "Web Automation",
      "description": "Skills for browser automation and web testing",
      "priority": 10
    },
    {
      "id": "uncategorized",
      "name": "Uncategorized",
      "description": "Skills without a specific category",
      "priority": 999
    }
  ],
  "stats": {
    "totalSkills": 37,
    "totalCategories": 11
  }
}